2025-03-06 13:11:45.612752: I external/org_tensorflow/tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
======== BEGIN Original Module =========
module {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = mhlo.constant dense_resource<__elided__> : tensor<10xf32>
    %1 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant dense_resource<__elided__> : tensor<10xf32>
    %4 = "mhlo.transpose"(%1) {permutation = dense<[1, 0]> : tensor<2xi64>} : (tensor<10x10xf32>) -> tensor<10x10xf32>
    %5 = "mhlo.dot"(%arg0, %4) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %6 = chlo.broadcast_add %5, %0 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
    %7 = "chlo.constant_like"(%6) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
    %8 = mhlo.maximum %6, %7 : tensor<?x10xf32>
    %9 = "mhlo.transpose"(%2) {permutation = dense<[1, 0]> : tensor<2xi64>} : (tensor<10x10xf32>) -> tensor<10x10xf32>
    %10 = "mhlo.dot"(%8, %9) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %11 = chlo.broadcast_add %10, %3 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
    %12 = "chlo.constant_like"(%11) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
    %13 = mhlo.maximum %11, %12 : tensor<?x10xf32>
    return %13 : tensor<?x10xf32>
  }
}

======= END Original Module ==========
[DISC] Load Input IR takes: 4.071000e-03 s.
[[ INFO ]] Running TF2XLA
// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %0 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %1 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %2 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
  %3 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
  %4 = "mhlo.dot"(%arg0, %1) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %5 = chlo.broadcast_add %4, %2 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
  %6 = "chlo.constant_like"(%5) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
  %7 = mhlo.maximum %5, %6 : tensor<?x10xf32>
  %8 = "mhlo.dot"(%7, %0) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %9 = chlo.broadcast_add %8, %3 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
  %10 = "chlo.constant_like"(%9) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
  %11 = mhlo.maximum %9, %10 : tensor<?x10xf32>
  return %11 : tensor<?x10xf32>
}

// -----// IR Dump After Inliner (inline) //----- //
module {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %1 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %3 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %4 = "mhlo.dot"(%arg0, %1) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %5 = chlo.broadcast_add %4, %2 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
    %6 = "chlo.constant_like"(%5) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
    %7 = mhlo.maximum %5, %6 : tensor<?x10xf32>
    %8 = "mhlo.dot"(%7, %0) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %9 = chlo.broadcast_add %8, %3 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
    %10 = "chlo.constant_like"(%9) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
    %11 = mhlo.maximum %9, %10 : tensor<?x10xf32>
    return %11 : tensor<?x10xf32>
  }
}


// -----// IR Dump After SCCP (sccp) //----- //
module {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %1 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %4 = "mhlo.dot"(%arg0, %2) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %5 = chlo.broadcast_add %4, %1 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
    %6 = "chlo.constant_like"(%5) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
    %7 = mhlo.maximum %5, %6 : tensor<?x10xf32>
    %8 = "mhlo.dot"(%7, %3) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %9 = chlo.broadcast_add %8, %0 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
    %10 = "chlo.constant_like"(%9) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
    %11 = mhlo.maximum %9, %10 : tensor<?x10xf32>
    return %11 : tensor<?x10xf32>
  }
}


// -----// IR Dump After SCCP (sccp) //----- //
module {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %1 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %3 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %4 = "mhlo.dot"(%arg0, %1) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %5 = chlo.broadcast_add %4, %2 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
    %6 = "chlo.constant_like"(%5) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
    %7 = mhlo.maximum %5, %6 : tensor<?x10xf32>
    %8 = "mhlo.dot"(%7, %0) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %9 = chlo.broadcast_add %8, %3 : (tensor<?x10xf32>, tensor<10xf32>) -> tensor<?x10xf32>
    %10 = "chlo.constant_like"(%9) {value = 0.000000e+00 : f32} : (tensor<?x10xf32>) -> tensor<?x10xf32>
    %11 = mhlo.maximum %9, %10 : tensor<?x10xf32>
    return %11 : tensor<?x10xf32>
  }
}


// -----// IR Dump After LegalizeTF (xla-legalize-tf) //----- //
module {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %1 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %3 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %4 = "mhlo.dot"(%arg0, %1) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %5 = shape.shape_of %4 : tensor<?x10xf32> -> tensor<2xindex>
    %6 = shape.shape_of %2 : tensor<10xf32> -> tensor<1xindex>
    %7 = shape.cstr_broadcastable %5, %6 : tensor<2xindex>, tensor<1xindex>
    %8 = shape.assuming %7 -> (tensor<?x10xf32>) {
      %22 = shape.shape_of %4 : tensor<?x10xf32> -> tensor<2xindex>
      %23 = shape.const_shape [10] : tensor<1xindex>
      %24 = shape.broadcast %22, %23 : tensor<2xindex>, tensor<1xindex> -> tensor<2xindex>
      %25 = "mhlo.dynamic_broadcast_in_dim"(%4, %24) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
      %26 = "mhlo.dynamic_broadcast_in_dim"(%2, %24) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
      %27 = mhlo.add %25, %26 : tensor<?x10xf32>
      shape.assuming_yield %27 : tensor<?x10xf32>
    }
    %9 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %10 = shape.shape_of %8 : tensor<?x10xf32> -> tensor<2xindex>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%9, %10) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
    %12 = mhlo.maximum %8, %11 : tensor<?x10xf32>
    %13 = "mhlo.dot"(%12, %0) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %14 = shape.shape_of %13 : tensor<?x10xf32> -> tensor<2xindex>
    %15 = shape.shape_of %3 : tensor<10xf32> -> tensor<1xindex>
    %16 = shape.cstr_broadcastable %14, %15 : tensor<2xindex>, tensor<1xindex>
    %17 = shape.assuming %16 -> (tensor<?x10xf32>) {
      %22 = shape.shape_of %13 : tensor<?x10xf32> -> tensor<2xindex>
      %23 = shape.const_shape [10] : tensor<1xindex>
      %24 = shape.broadcast %22, %23 : tensor<2xindex>, tensor<1xindex> -> tensor<2xindex>
      %25 = "mhlo.dynamic_broadcast_in_dim"(%13, %24) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
      %26 = "mhlo.dynamic_broadcast_in_dim"(%3, %24) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
      %27 = mhlo.add %25, %26 : tensor<?x10xf32>
      shape.assuming_yield %27 : tensor<?x10xf32>
    }
    %18 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %19 = shape.shape_of %17 : tensor<?x10xf32> -> tensor<2xindex>
    %20 = "mhlo.dynamic_broadcast_in_dim"(%18, %19) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
    %21 = mhlo.maximum %17, %20 : tensor<?x10xf32>
    return %21 : tensor<?x10xf32>
  }
}


// -----// IR Dump After DiscLowerTfPass (disc-lower-tf) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %0 = shape.const_witness true
  %1 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %2 = shape.const_shape [10] : tensor<1xindex>
  %3 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %4 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %5 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
  %6 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
  %7 = "mhlo.dot"(%arg0, %4) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %8 = shape.assuming %0 -> (tensor<?x10xf32>) {
    %17 = shape.shape_of %7 : tensor<?x10xf32> -> tensor<2xindex>
    %18 = shape.broadcast %17, %2 : tensor<2xindex>, tensor<1xindex> -> tensor<2xindex>
    %19 = "mhlo.dynamic_broadcast_in_dim"(%7, %18) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %20 = "mhlo.dynamic_broadcast_in_dim"(%5, %18) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %21 = mhlo.add %19, %20 : tensor<?x10xf32>
    shape.assuming_yield %21 : tensor<?x10xf32>
  }
  %9 = shape.shape_of %8 : tensor<?x10xf32> -> tensor<2xindex>
  %10 = "mhlo.dynamic_broadcast_in_dim"(%1, %9) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
  %11 = mhlo.maximum %8, %10 : tensor<?x10xf32>
  %12 = "mhlo.dot"(%11, %3) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %13 = shape.assuming %0 -> (tensor<?x10xf32>) {
    %17 = shape.shape_of %12 : tensor<?x10xf32> -> tensor<2xindex>
    %18 = shape.broadcast %17, %2 : tensor<2xindex>, tensor<1xindex> -> tensor<2xindex>
    %19 = "mhlo.dynamic_broadcast_in_dim"(%12, %18) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %20 = "mhlo.dynamic_broadcast_in_dim"(%6, %18) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %21 = mhlo.add %19, %20 : tensor<?x10xf32>
    shape.assuming_yield %21 : tensor<?x10xf32>
  }
  %14 = shape.shape_of %13 : tensor<?x10xf32> -> tensor<2xindex>
  %15 = "mhlo.dynamic_broadcast_in_dim"(%1, %14) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
  %16 = mhlo.maximum %13, %15 : tensor<?x10xf32>
  return %16 : tensor<?x10xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %1 = shape.const_shape [10] : tensor<1xindex>
  %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %3 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %4 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
  %5 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
  %6 = "mhlo.dot"(%arg0, %3) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %7 = shape.shape_of %6 : tensor<?x10xf32> -> tensor<2xindex>
  %8 = shape.broadcast %7, %1 : tensor<2xindex>, tensor<1xindex> -> tensor<2xindex>
  %9 = "mhlo.dynamic_broadcast_in_dim"(%6, %8) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %10 = "mhlo.dynamic_broadcast_in_dim"(%4, %8) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %11 = mhlo.add %9, %10 : tensor<?x10xf32>
  %12 = shape.shape_of %11 : tensor<?x10xf32> -> tensor<2xindex>
  %13 = "mhlo.dynamic_broadcast_in_dim"(%0, %12) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
  %14 = mhlo.maximum %11, %13 : tensor<?x10xf32>
  %15 = "mhlo.dot"(%14, %2) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %16 = shape.shape_of %15 : tensor<?x10xf32> -> tensor<2xindex>
  %17 = shape.broadcast %16, %1 : tensor<2xindex>, tensor<1xindex> -> tensor<2xindex>
  %18 = "mhlo.dynamic_broadcast_in_dim"(%15, %17) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %19 = "mhlo.dynamic_broadcast_in_dim"(%5, %17) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %20 = mhlo.add %18, %19 : tensor<?x10xf32>
  %21 = shape.shape_of %20 : tensor<?x10xf32> -> tensor<2xindex>
  %22 = "mhlo.dynamic_broadcast_in_dim"(%0, %21) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
  %23 = mhlo.maximum %20, %22 : tensor<?x10xf32>
  return %23 : tensor<?x10xf32>
}

===-------------------------------------------------------------------------===
                         ... Execution time report ...
===-------------------------------------------------------------------------===
  Total Execution Time: 0.0123 seconds

  ----Wall Time----  ----Name----
    0.0001 (  0.6%)  ReviseArgumentsForStaticRankPass
    0.0000 (  0.2%)  FunctionalControlFlowToRegionsPass
    0.0020 ( 16.3%)  Inliner
    0.0000 (  0.2%)    (A) CallGraph
    0.0010 (  8.3%)  'func.func' Pipeline
    0.0010 (  8.3%)    Canonicalizer
    0.0002 (  1.2%)  'func.func' Pipeline
    0.0000 (  0.2%)    DropWhileShapeInvariantPass
    0.0000 (  0.2%)    ReplicateTensorListInitOpsPass
    0.0001 (  0.8%)    Canonicalizer
    0.0008 (  6.7%)  SCCP
    0.0000 (  0.4%)  GuaranteeAllFuncsOneUsePass
    0.0000 (  0.0%)    (A) CallGraph
    0.0000 (  0.2%)  TensorFlowShapeInferencePass
    0.0007 (  5.5%)  SCCP
    0.0000 (  0.3%)  TensorListOpsDecompositionPass
    0.0000 (  0.2%)  StackOpsDecompositionPass
    0.0000 (  0.2%)  TensorArrayOpsDecompositionPass
    0.0001 (  0.7%)  'func.func' Pipeline
    0.0001 (  0.7%)    DecomposeResourceOpsPass
    0.0000 (  0.3%)  PromoteResourcesToArgsPass
    0.0000 (  0.3%)  SymbolDCE
    0.0000 (  0.2%)  'func.func' Pipeline
    0.0000 (  0.2%)    SinkConstantsToControlFlowPass
    0.0000 (  0.2%)  TensorFlowShapeInferencePass
    0.0003 (  2.8%)  StablehloLegalizeToHloPass
    0.0001 (  0.9%)  'func.func' Pipeline
    0.0001 (  0.5%)    DiscLowerTfPass
    0.0000 (  0.4%)    LowerQuantizedPass
    0.0000 (  0.3%)  LegalizeTfTypesPass
    0.0023 ( 18.9%)  LegalizeTF
    0.0014 ( 11.8%)  'func.func' Pipeline
    0.0014 ( 11.4%)    DiscLowerTfPass
    0.0000 (  0.4%)    InfeedOpsXlaAdjustLayout
    0.0001 (  0.6%)  LegalizeTFCollective
    0.0013 ( 10.9%)  'func.func' Pipeline
    0.0013 ( 10.8%)    Canonicalizer
    0.0000 (  0.3%)  TensorFlowShapeInferencePass
    0.0005 (  3.9%)  LegalizeTF
    0.0000 (  0.3%)  LegalizeTFCommunicationPass
    0.0001 (  0.9%)  'func.func' Pipeline
    0.0001 (  0.6%)    DiscDynamicSliceConverterPass
    0.0000 (  0.3%)    SinkConstantsToControlFlowPass
    0.0008 (  6.2%)  Rest
    0.0123 (100.0%)  Total
======== BEGIN After TF2HLO =========
module {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = shape.const_shape [10] : tensor<1xindex>
    %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %4 = mhlo.constant dense_resource<__elided__> : tensor<10xf32>
    %5 = mhlo.constant dense_resource<__elided__> : tensor<10xf32>
    %6 = "mhlo.dot"(%arg0, %3) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %7 = shape.shape_of %6 : tensor<?x10xf32> -> tensor<2xindex>
    %8 = shape.broadcast %7, %1 : tensor<2xindex>, tensor<1xindex> -> tensor<2xindex>
    %9 = "mhlo.dynamic_broadcast_in_dim"(%6, %8) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %10 = "mhlo.dynamic_broadcast_in_dim"(%4, %8) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %11 = mhlo.add %9, %10 : tensor<?x10xf32>
    %12 = shape.shape_of %11 : tensor<?x10xf32> -> tensor<2xindex>
    %13 = "mhlo.dynamic_broadcast_in_dim"(%0, %12) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
    %14 = mhlo.maximum %11, %13 : tensor<?x10xf32>
    %15 = "mhlo.dot"(%14, %2) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %16 = shape.shape_of %15 : tensor<?x10xf32> -> tensor<2xindex>
    %17 = shape.broadcast %16, %1 : tensor<2xindex>, tensor<1xindex> -> tensor<2xindex>
    %18 = "mhlo.dynamic_broadcast_in_dim"(%15, %17) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %19 = "mhlo.dynamic_broadcast_in_dim"(%5, %17) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %20 = mhlo.add %18, %19 : tensor<?x10xf32>
    %21 = shape.shape_of %20 : tensor<?x10xf32> -> tensor<2xindex>
    %22 = "mhlo.dynamic_broadcast_in_dim"(%0, %21) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
    %23 = mhlo.maximum %20, %22 : tensor<?x10xf32>
    return %23 : tensor<?x10xf32>
  }
}

======= END After TF2HLO ==========
[DISC] tf2hlo takes: 1.357800e-02 s.
2025-03-06 13:11:45.829959: I external/org_disc_compiler/mlir/disc/transforms/disc_gpu_kernel_to_blob.cc:99] Multiple GPU compute capability compilation is enabled. The AOT compiled binary is functional on sm_60, sm_70, sm_75, sm_80 and sm_86. While the optimal performance can be achived only on currently GPU generation that BladeDISC executes on.
// -----// IR Dump After ConvertShapeToStandardPass (disc-convert-shape-to-std) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %c10 = arith.constant 10 : index
  %from_elements = tensor.from_elements %c10 : tensor<1xindex>
  %cast = tensor.cast %from_elements : tensor<1xindex> to tensor<1xindex>
  %1 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %3 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
  %4 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
  %5 = "mhlo.dot"(%arg0, %2) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %5, %c0 : tensor<?x10xf32>
  %c10_0 = arith.constant 10 : index
  %from_elements_1 = tensor.from_elements %dim, %c10_0 : tensor<2xindex>
  %c0_2 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c0_3 = arith.constant 0 : index
  %extracted = tensor.extract %from_elements_1[%c0_3] : tensor<2xindex>
  %6 = arith.cmpi eq, %extracted, %c1 : index
  %7 = arith.select %6, %c1, %extracted : index
  %c1_4 = arith.constant 1 : index
  %c1_5 = arith.constant 1 : index
  %extracted_6 = tensor.extract %from_elements_1[%c1_5] : tensor<2xindex>
  %8 = arith.cmpi eq, %extracted_6, %c1_4 : index
  %9 = arith.select %8, %c1_4, %extracted_6 : index
  %c0_7 = arith.constant 0 : index
  %extracted_8 = tensor.extract %cast[%c0_7] : tensor<1xindex>
  %10 = arith.cmpi eq, %extracted_8, %c1_4 : index
  %11 = arith.select %10, %9, %extracted_8 : index
  %from_elements_9 = tensor.from_elements %7, %11 : tensor<2xindex>
  %12 = "mhlo.dynamic_broadcast_in_dim"(%5, %from_elements_9) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %13 = "mhlo.dynamic_broadcast_in_dim"(%3, %from_elements_9) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %14 = mhlo.add %12, %13 : tensor<?x10xf32>
  %c0_10 = arith.constant 0 : index
  %dim_11 = tensor.dim %14, %c0_10 : tensor<?x10xf32>
  %c10_12 = arith.constant 10 : index
  %from_elements_13 = tensor.from_elements %dim_11, %c10_12 : tensor<2xindex>
  %15 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements_13) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
  %16 = mhlo.maximum %14, %15 : tensor<?x10xf32>
  %17 = "mhlo.dot"(%16, %1) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %c0_14 = arith.constant 0 : index
  %dim_15 = tensor.dim %17, %c0_14 : tensor<?x10xf32>
  %c10_16 = arith.constant 10 : index
  %from_elements_17 = tensor.from_elements %dim_15, %c10_16 : tensor<2xindex>
  %c0_18 = arith.constant 0 : index
  %c1_19 = arith.constant 1 : index
  %c0_20 = arith.constant 0 : index
  %extracted_21 = tensor.extract %from_elements_17[%c0_20] : tensor<2xindex>
  %18 = arith.cmpi eq, %extracted_21, %c1_19 : index
  %19 = arith.select %18, %c1_19, %extracted_21 : index
  %c1_22 = arith.constant 1 : index
  %c1_23 = arith.constant 1 : index
  %extracted_24 = tensor.extract %from_elements_17[%c1_23] : tensor<2xindex>
  %20 = arith.cmpi eq, %extracted_24, %c1_22 : index
  %21 = arith.select %20, %c1_22, %extracted_24 : index
  %c0_25 = arith.constant 0 : index
  %extracted_26 = tensor.extract %cast[%c0_25] : tensor<1xindex>
  %22 = arith.cmpi eq, %extracted_26, %c1_22 : index
  %23 = arith.select %22, %21, %extracted_26 : index
  %from_elements_27 = tensor.from_elements %19, %23 : tensor<2xindex>
  %24 = "mhlo.dynamic_broadcast_in_dim"(%17, %from_elements_27) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %25 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements_27) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %26 = mhlo.add %24, %25 : tensor<?x10xf32>
  %c0_28 = arith.constant 0 : index
  %dim_29 = tensor.dim %26, %c0_28 : tensor<?x10xf32>
  %c10_30 = arith.constant 10 : index
  %from_elements_31 = tensor.from_elements %dim_29, %c10_30 : tensor<2xindex>
  %27 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements_31) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
  %28 = mhlo.maximum %26, %27 : tensor<?x10xf32>
  return %28 : tensor<?x10xf32>
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %1 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %4 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %5 = "disc_shape.tie_shape"(%arg0, %dim, %dim_0) : (tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %6 = "disc_shape.tie_shape"(%3, %c10, %c10) : (tensor<10x10xf32>, index, index) -> tensor<10x10xf32>
    %7 = "disc_shape.tie_shape"(%2, %c10, %c10) : (tensor<10x10xf32>, index, index) -> tensor<10x10xf32>
    %8 = "disc_shape.tie_shape"(%1, %c10) : (tensor<10xf32>, index) -> tensor<10xf32>
    %9 = "disc_shape.tie_shape"(%0, %c10) : (tensor<10xf32>, index) -> tensor<10xf32>
    %10 = "mhlo.dot"(%5, %7) : (tensor<?x?xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %11 = "disc_shape.tie_shape"(%10, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %from_elements = tensor.from_elements %dim, %c10 : tensor<2xindex>
    %12 = "disc_shape.tie_shape"(%from_elements, %c2) : (tensor<2xindex>, index) -> tensor<2xindex>
    %13 = "mhlo.dynamic_broadcast_in_dim"(%11, %12) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %14 = "disc_shape.tie_shape"(%13, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %15 = "mhlo.dynamic_broadcast_in_dim"(%8, %12) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %16 = "disc_shape.tie_shape"(%15, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %17 = mhlo.add %14, %16 : tensor<?x10xf32>
    %18 = "disc_shape.tie_shape"(%17, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %19 = "mhlo.dynamic_broadcast_in_dim"(%4, %12) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
    %20 = "disc_shape.tie_shape"(%19, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %21 = mhlo.maximum %18, %20 : tensor<?x10xf32>
    %22 = "disc_shape.tie_shape"(%21, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %23 = "mhlo.dot"(%22, %6) : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %24 = "disc_shape.tie_shape"(%23, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %25 = "mhlo.dynamic_broadcast_in_dim"(%24, %12) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %26 = "disc_shape.tie_shape"(%25, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %27 = "mhlo.dynamic_broadcast_in_dim"(%9, %12) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %28 = "disc_shape.tie_shape"(%27, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %29 = mhlo.add %26, %28 : tensor<?x10xf32>
    %30 = "disc_shape.tie_shape"(%29, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %31 = mhlo.maximum %30, %20 : tensor<?x10xf32>
    %32 = "disc_shape.tie_shape"(%31, %dim, %c10) : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    return %32 : tensor<?x10xf32>
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 12 us
SymbolicDimMgr::save update attributes takes: 2 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 4 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 27 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 9 us
SymbolicDimMgr::save remove symbolicDim ops takes: 2 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 4 us
SymbolicDimMgr::save replace the name takes: 12 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
SymbolicDimMgr::save walkRankedTensorValue takes: 11 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 25 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 7 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 12 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %1 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %4 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
    %5 = "mhlo.dot"(%arg0, %2) : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %from_elements = tensor.from_elements %dim, %c10 : tensor<2xindex>
    %6 = "mhlo.dynamic_broadcast_in_dim"(%5, %from_elements) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %7 = "mhlo.dynamic_broadcast_in_dim"(%1, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %8 = mhlo.add %6, %7 : tensor<?x10xf32, [@S0, @C10]>
    %9 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %10 = mhlo.maximum %8, %9 : tensor<?x10xf32, [@S0, @C10]>
    %11 = "mhlo.dot"(%10, %3) : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %12 = "mhlo.dynamic_broadcast_in_dim"(%11, %from_elements) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %13 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %14 = mhlo.add %12, %13 : tensor<?x10xf32, [@S0, @C10]>
    %15 = mhlo.maximum %14, %9 : tensor<?x10xf32, [@S0, @C10]>
    return %15 : tensor<?x10xf32, [@S0, @C10]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscAlgebraicSimplifierPass (disc-algebraic-simplifier) //----- //
func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %0 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
  %1 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
  %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %3 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %4 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
  %5 = "mhlo.dot"(%arg0, %2) : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
  %from_elements = tensor.from_elements %dim, %c10 : tensor<2xindex>
  %6 = "mhlo.dynamic_broadcast_in_dim"(%1, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
  %7 = mhlo.add %5, %6 : tensor<?x10xf32, [@S0, @C10]>
  %8 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
  %9 = mhlo.maximum %7, %8 : tensor<?x10xf32, [@S0, @C10]>
  %10 = "mhlo.dot"(%9, %3) : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
  %11 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
  %12 = mhlo.add %10, %11 : tensor<?x10xf32, [@S0, @C10]>
  %13 = mhlo.maximum %12, %8 : tensor<?x10xf32, [@S0, @C10]>
  return %13 : tensor<?x10xf32, [@S0, @C10]>
}

// -----// IR Dump After DotRewriterPass (disc-dot-rewriter) //----- //
func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %0 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
  %1 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
  %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %3 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
  %4 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
  %5 = "mhlo.dot_general"(%arg0, %2) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
  %from_elements = tensor.from_elements %dim, %c10 : tensor<2xindex>
  %6 = "mhlo.dynamic_broadcast_in_dim"(%1, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
  %7 = mhlo.add %5, %6 : tensor<?x10xf32, [@S0, @C10]>
  %8 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
  %9 = mhlo.maximum %7, %8 : tensor<?x10xf32, [@S0, @C10]>
  %10 = "mhlo.dot_general"(%9, %3) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
  %11 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
  %12 = mhlo.add %10, %11 : tensor<?x10xf32, [@S0, @C10]>
  %13 = mhlo.maximum %12, %8 : tensor<?x10xf32, [@S0, @C10]>
  return %13 : tensor<?x10xf32, [@S0, @C10]>
}

SymbolicDimMgr::save walkRankedTensorValue takes: 9 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 25 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 6 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 10 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %4 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
    %5 = "mhlo.dot_general"(%arg0, %2) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %from_elements = tensor.from_elements %dim, %c10 : tensor<2xindex>
    %6 = "mhlo.dynamic_broadcast_in_dim"(%3, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %7 = mhlo.add %5, %6 : tensor<?x10xf32, [@S0, @C10]>
    %8 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %9 = mhlo.maximum %7, %8 : tensor<?x10xf32, [@S0, @C10]>
    %10 = "mhlo.dot_general"(%9, %1) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %12 = mhlo.add %10, %11 : tensor<?x10xf32, [@S0, @C10]>
    %13 = mhlo.maximum %12, %8 : tensor<?x10xf32, [@S0, @C10]>
    return %13 : tensor<?x10xf32, [@S0, @C10]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 9 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 25 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 6 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 11 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %1 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %4 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
    %5 = "mhlo.dot_general"(%arg0, %2) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %from_elements = tensor.from_elements %dim, %c10 : tensor<2xindex>
    %6 = "mhlo.dynamic_broadcast_in_dim"(%1, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %7 = mhlo.add %5, %6 : tensor<?x10xf32, [@S0, @C10]>
    %8 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %9 = mhlo.maximum %7, %8 : tensor<?x10xf32, [@S0, @C10]>
    %10 = "mhlo.dot_general"(%9, %3) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %12 = mhlo.add %10, %11 : tensor<?x10xf32, [@S0, @C10]>
    %13 = mhlo.maximum %12, %8 : tensor<?x10xf32, [@S0, @C10]>
    return %13 : tensor<?x10xf32, [@S0, @C10]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 9 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 25 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 6 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 10 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %4 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
    %5 = "mhlo.dot_general"(%arg0, %2) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %from_elements = tensor.from_elements %dim, %c10 : tensor<2xindex>
    %6 = "mhlo.dynamic_broadcast_in_dim"(%3, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %7 = mhlo.add %5, %6 : tensor<?x10xf32, [@S0, @C10]>
    %8 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %9 = mhlo.maximum %7, %8 : tensor<?x10xf32, [@S0, @C10]>
    %10 = "mhlo.dot_general"(%9, %1) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %12 = mhlo.add %10, %11 : tensor<?x10xf32, [@S0, @C10]>
    %13 = mhlo.maximum %12, %8 : tensor<?x10xf32, [@S0, @C10]>
    return %13 : tensor<?x10xf32, [@S0, @C10]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscMarkShapeCalculationPass (disc-mhlo-mark-shape-calc) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %4 = mhlo.constant dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
    %5 = "mhlo.dot_general"(%arg0, %2) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
    %6 = "mhlo.dynamic_broadcast_in_dim"(%3, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %7 = mhlo.add %5, %6 : tensor<?x10xf32, [@S0, @C10]>
    %8 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %9 = mhlo.maximum %7, %8 : tensor<?x10xf32, [@S0, @C10]>
    %10 = "mhlo.dot_general"(%9, %1) {dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %12 = mhlo.add %10, %11 : tensor<?x10xf32, [@S0, @C10]>
    %13 = mhlo.maximum %12, %8 : tensor<?x10xf32, [@S0, @C10]>
    return %13 : tensor<?x10xf32, [@S0, @C10]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After PlaceOpsPass (mhlo-place-ops) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant {disc.device = "gpu"} dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %4 = mhlo.constant {disc.device = "gpu"} dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
    %5 = "mhlo.dot_general"(%arg0, %2) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
    %6 = "mhlo.dynamic_broadcast_in_dim"(%3, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %7 = mhlo.add %5, %6 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %8 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %9 = mhlo.maximum %7, %8 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %10 = "mhlo.dot_general"(%9, %1) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %12 = mhlo.add %10, %11 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %13 = mhlo.maximum %12, %8 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    return %13 : tensor<?x10xf32, [@S0, @C10]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 10 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 25 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 7 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 10 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %1 = mhlo.constant {disc.device = "gpu"} dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %2 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %4 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
    %5 = "mhlo.dot_general"(%arg0, %2) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
    %6 = "mhlo.dynamic_broadcast_in_dim"(%1, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %7 = mhlo.add %5, %6 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %8 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %9 = mhlo.maximum %7, %8 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %10 = "mhlo.dot_general"(%9, %3) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %12 = mhlo.add %10, %11 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %13 = mhlo.maximum %12, %8 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    return %13 : tensor<?x10xf32, [@S0, @C10]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 9 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 25 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 6 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 10 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant {disc.device = "gpu"} dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %4 = mhlo.constant {disc.device = "gpu"} dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
    %5 = "mhlo.dot_general"(%arg0, %2) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
    %6 = "mhlo.dynamic_broadcast_in_dim"(%3, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %7 = mhlo.add %5, %6 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %8 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %9 = mhlo.maximum %7, %8 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %10 = "mhlo.dot_general"(%9, %1) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %12 = mhlo.add %10, %11 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %13 = mhlo.maximum %12, %8 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    return %13 : tensor<?x10xf32, [@S0, @C10]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 10 us
SymbolicDimMgr::save update attributes takes: 2 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 25 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 7 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 11 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32, [@S0, @C10]>) -> tensor<?x10xf32, [@S0, @C10]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %1 = mhlo.constant {disc.device = "gpu"} dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %2 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %4 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32, [@S0, @C10]>
    %5 = "mhlo.dot_general"(%arg0, %2) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
    %6 = "mhlo.dynamic_broadcast_in_dim"(%1, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %7 = mhlo.add %5, %6 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %8 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %9 = mhlo.maximum %7, %8 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %10 = "mhlo.dot_general"(%9, %3) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32, [@S0, @C10]>, tensor<10x10xf32>) -> tensor<?x10xf32, [@S0, @C10]>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32, [@S0, @C10]>
    %12 = mhlo.add %10, %11 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    %13 = mhlo.maximum %12, %8 {disc.device = "gpu"} : tensor<?x10xf32, [@S0, @C10]>
    return %13 : tensor<?x10xf32, [@S0, @C10]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 9 us
SymbolicDimMgr::save update attributes takes: 2 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 25 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 6 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 2 us
SymbolicDimMgr::save replace the name takes: 11 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x10xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %2 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant {disc.device = "gpu"} dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %4 = mhlo.constant {disc.device = "gpu"} dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32>
    %5 = "disc_shape.tie_shape"(%arg0, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %6 = "disc_shape.tie_shape"(%4, %c10) : (tensor<10xf32>, index) -> tensor<10xf32>
    %7 = "disc_shape.tie_shape"(%3, %c10) : (tensor<10xf32>, index) -> tensor<10xf32>
    %8 = "disc_shape.tie_shape"(%2, %c10, %c10) : (tensor<10x10xf32>, index, index) -> tensor<10x10xf32>
    %9 = "disc_shape.tie_shape"(%1, %c10, %c10) : (tensor<10x10xf32>, index, index) -> tensor<10x10xf32>
    %10 = "mhlo.dot_general"(%5, %8) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %11 = "disc_shape.tie_shape"(%10, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
    %12 = "disc_shape.tie_shape"(%from_elements, %c2) : (tensor<2xindex>, index) -> tensor<2xindex>
    %13 = "mhlo.dynamic_broadcast_in_dim"(%7, %12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %14 = "disc_shape.tie_shape"(%13, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %15 = mhlo.add %11, %14 {disc.device = "gpu"} : tensor<?x10xf32>
    %16 = "disc_shape.tie_shape"(%15, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %17 = "mhlo.dynamic_broadcast_in_dim"(%0, %12) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
    %18 = "disc_shape.tie_shape"(%17, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %19 = mhlo.maximum %16, %18 {disc.device = "gpu"} : tensor<?x10xf32>
    %20 = "disc_shape.tie_shape"(%19, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %21 = "mhlo.dot_general"(%20, %9) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %22 = "disc_shape.tie_shape"(%21, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %23 = "mhlo.dynamic_broadcast_in_dim"(%6, %12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %24 = "disc_shape.tie_shape"(%23, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %25 = mhlo.add %22, %24 {disc.device = "gpu"} : tensor<?x10xf32>
    %26 = "disc_shape.tie_shape"(%25, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %27 = mhlo.maximum %26, %18 {disc.device = "gpu"} : tensor<?x10xf32>
    %28 = "disc_shape.tie_shape"(%27, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    return %28 : tensor<?x10xf32>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<?x10xf32>) -> tensor<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
  %1 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
  %2 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
  %3 = mhlo.constant {disc.device = "gpu"} dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
  %4 = mhlo.constant {disc.device = "gpu"} dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
  %dim = tensor.dim %arg0, %c0 : tensor<?x10xf32>
  %5 = "disc_shape.tie_shape"(%arg0, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  %6 = "mhlo.dot_general"(%5, %2) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %7 = "disc_shape.tie_shape"(%6, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
  %8 = "mhlo.dynamic_broadcast_in_dim"(%3, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %9 = "disc_shape.tie_shape"(%8, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  %10 = mhlo.add %7, %9 {disc.device = "gpu"} : tensor<?x10xf32>
  %11 = "disc_shape.tie_shape"(%10, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  %12 = "mhlo.dynamic_broadcast_in_dim"(%0, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
  %13 = "disc_shape.tie_shape"(%12, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  %14 = mhlo.maximum %11, %13 {disc.device = "gpu"} : tensor<?x10xf32>
  %15 = "disc_shape.tie_shape"(%14, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  %16 = "mhlo.dot_general"(%15, %1) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
  %17 = "disc_shape.tie_shape"(%16, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  %18 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
  %19 = "disc_shape.tie_shape"(%18, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  %20 = mhlo.add %17, %19 {disc.device = "gpu"} : tensor<?x10xf32>
  %21 = "disc_shape.tie_shape"(%20, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  %22 = mhlo.maximum %21, %13 {disc.device = "gpu"} : tensor<?x10xf32>
  %23 = "disc_shape.tie_shape"(%22, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
  return %23 : tensor<?x10xf32>
}

// -----// IR Dump After FuncBufferize (func-bufferize) //----- //
module {
  func.func @main(%arg0: memref<?x10xf32>) -> memref<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = bufferization.to_tensor %arg0 : memref<?x10xf32>
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %2 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %3 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %4 = mhlo.constant {disc.device = "gpu"} dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %5 = mhlo.constant {disc.device = "gpu"} dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %dim = tensor.dim %0, %c0 : tensor<?x10xf32>
    %6 = "disc_shape.tie_shape"(%0, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %7 = "mhlo.dot_general"(%6, %3) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %8 = "disc_shape.tie_shape"(%7, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
    %9 = "mhlo.dynamic_broadcast_in_dim"(%4, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %10 = "disc_shape.tie_shape"(%9, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %11 = mhlo.add %8, %10 {disc.device = "gpu"} : tensor<?x10xf32>
    %12 = "disc_shape.tie_shape"(%11, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %13 = "mhlo.dynamic_broadcast_in_dim"(%1, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
    %14 = "disc_shape.tie_shape"(%13, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %15 = mhlo.maximum %12, %14 {disc.device = "gpu"} : tensor<?x10xf32>
    %16 = "disc_shape.tie_shape"(%15, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %17 = "mhlo.dot_general"(%16, %2) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %18 = "disc_shape.tie_shape"(%17, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %19 = "mhlo.dynamic_broadcast_in_dim"(%5, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %20 = "disc_shape.tie_shape"(%19, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %21 = mhlo.add %18, %20 {disc.device = "gpu"} : tensor<?x10xf32>
    %22 = "disc_shape.tie_shape"(%21, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %23 = mhlo.maximum %22, %14 {disc.device = "gpu"} : tensor<?x10xf32>
    %24 = "disc_shape.tie_shape"(%23, %dim, %c10) {kDiscSymbolicDimAttr = [@S0, @C10]} : (tensor<?x10xf32>, index, index) -> tensor<?x10xf32>
    %25 = bufferization.to_memref %24 : memref<?x10xf32>
    return %25 : memref<?x10xf32>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscHloLegalizeToLhloPass (disc-hlo-legalize-to-lhlo) //----- //
module {
  func.func @main(%arg0: memref<?x10xf32>) -> memref<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = bufferization.to_tensor %arg0 : memref<?x10xf32>
    %1 = bufferization.to_memref %0 : memref<?x10xf32>
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %2 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %3 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %4 = mhlo.constant {disc.device = "gpu"} dense_resource<__elided__> : tensor<10x10xf32>
    %5 = mhlo.constant {disc.device = "gpu"} dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>
    %6 = mhlo.constant {disc.device = "gpu"} dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>
    %dim = tensor.dim %0, %c0 : tensor<?x10xf32>
    %c10_0 = arith.constant 10 : index
    %7 = arith.muli %c10_0, %dim : index
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %8 = bufferization.to_tensor %reinterpret_cast : memref<?x10xf32>
    %9 = "mhlo.dot_general"(%8, %4) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %10 = bufferization.to_memref %9 : memref<?x10xf32>
    %c10_1 = arith.constant 10 : index
    %11 = arith.muli %c10_1, %dim : index
    %reinterpret_cast_2 = memref.reinterpret_cast %10 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %12 = bufferization.to_tensor %reinterpret_cast_2 : memref<?x10xf32>
    %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
    %13 = "mhlo.dynamic_broadcast_in_dim"(%5, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %14 = bufferization.to_memref %13 : memref<?x10xf32>
    %c10_3 = arith.constant 10 : index
    %15 = arith.muli %c10_3, %dim : index
    %reinterpret_cast_4 = memref.reinterpret_cast %14 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %16 = bufferization.to_tensor %reinterpret_cast_4 : memref<?x10xf32>
    %17 = mhlo.add %12, %16 {disc.device = "gpu"} : tensor<?x10xf32>
    %18 = bufferization.to_memref %17 : memref<?x10xf32>
    %c10_5 = arith.constant 10 : index
    %19 = arith.muli %c10_5, %dim : index
    %reinterpret_cast_6 = memref.reinterpret_cast %18 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %20 = bufferization.to_tensor %reinterpret_cast_6 : memref<?x10xf32>
    %21 = "mhlo.dynamic_broadcast_in_dim"(%2, %from_elements) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (tensor<f32>, tensor<2xindex>) -> tensor<?x10xf32>
    %22 = bufferization.to_memref %21 : memref<?x10xf32>
    %c10_7 = arith.constant 10 : index
    %23 = arith.muli %c10_7, %dim : index
    %reinterpret_cast_8 = memref.reinterpret_cast %22 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %24 = bufferization.to_tensor %reinterpret_cast_8 : memref<?x10xf32>
    %25 = mhlo.maximum %20, %24 {disc.device = "gpu"} : tensor<?x10xf32>
    %26 = bufferization.to_memref %25 : memref<?x10xf32>
    %c10_9 = arith.constant 10 : index
    %27 = arith.muli %c10_9, %dim : index
    %reinterpret_cast_10 = memref.reinterpret_cast %26 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %28 = bufferization.to_tensor %reinterpret_cast_10 : memref<?x10xf32>
    %29 = "mhlo.dot_general"(%28, %3) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (tensor<?x10xf32>, tensor<10x10xf32>) -> tensor<?x10xf32>
    %30 = bufferization.to_memref %29 : memref<?x10xf32>
    %c10_11 = arith.constant 10 : index
    %31 = arith.muli %c10_11, %dim : index
    %reinterpret_cast_12 = memref.reinterpret_cast %30 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %32 = bufferization.to_tensor %reinterpret_cast_12 : memref<?x10xf32>
    %33 = "mhlo.dynamic_broadcast_in_dim"(%6, %from_elements) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (tensor<10xf32>, tensor<2xindex>) -> tensor<?x10xf32>
    %34 = bufferization.to_memref %33 : memref<?x10xf32>
    %c10_13 = arith.constant 10 : index
    %35 = arith.muli %c10_13, %dim : index
    %reinterpret_cast_14 = memref.reinterpret_cast %34 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %36 = bufferization.to_tensor %reinterpret_cast_14 : memref<?x10xf32>
    %37 = mhlo.add %32, %36 {disc.device = "gpu"} : tensor<?x10xf32>
    %38 = bufferization.to_memref %37 : memref<?x10xf32>
    %c10_15 = arith.constant 10 : index
    %39 = arith.muli %c10_15, %dim : index
    %reinterpret_cast_16 = memref.reinterpret_cast %38 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %40 = bufferization.to_tensor %reinterpret_cast_16 : memref<?x10xf32>
    %41 = mhlo.maximum %40, %24 {disc.device = "gpu"} : tensor<?x10xf32>
    %42 = bufferization.to_memref %41 : memref<?x10xf32>
    %c10_17 = arith.constant 10 : index
    %43 = arith.muli %c10_17, %dim : index
    %reinterpret_cast_18 = memref.reinterpret_cast %42 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %44 = bufferization.to_tensor %reinterpret_cast_18 : memref<?x10xf32>
    %45 = bufferization.to_memref %44 : memref<?x10xf32>
    return %45 : memref<?x10xf32>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After HloLegalizeToLhloPass (hlo-legalize-to-lhlo) //----- //
module {
  func.func @main(%arg0: memref<?x10xf32>) -> memref<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = bufferization.to_tensor %arg0 : memref<?x10xf32>
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc() : memref<f32>
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32>) -> ()
    %alloc_0 = memref.alloc() : memref<10x10xf32>
    "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
    %alloc_1 = memref.alloc() : memref<10x10xf32>
    "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
    %alloc_2 = memref.alloc() : memref<10xf32>
    "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32>) -> ()
    %alloc_3 = memref.alloc() : memref<10xf32>
    "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32>) -> ()
    %dim = tensor.dim %0, %c0 : tensor<?x10xf32>
    %c10_4 = arith.constant 10 : index
    %1 = arith.muli %c10_4, %dim : index
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %2 = bufferization.to_tensor %reinterpret_cast : memref<?x10xf32>
    %3 = bufferization.to_memref %2 : memref<?x10xf32>
    %4 = bufferization.to_tensor %3 : memref<?x10xf32>
    %5 = bufferization.to_tensor %alloc_1 : memref<10x10xf32>
    %c0_5 = arith.constant 0 : index
    %dim_6 = tensor.dim %4, %c0_5 : tensor<?x10xf32>
    %c1 = arith.constant 1 : index
    %dim_7 = tensor.dim %5, %c1 : tensor<10x10xf32>
    %from_elements = tensor.from_elements %dim_6, %dim_7 : tensor<2xindex>
    %c0_8 = arith.constant 0 : index
    %extracted = tensor.extract %from_elements[%c0_8] : tensor<2xindex>
    %alloc_9 = memref.alloc(%extracted) : memref<?x10xf32>
    "lmhlo.dot_general"(%3, %alloc_1, %alloc_9) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
    %6 = bufferization.to_tensor %alloc_9 : memref<?x10xf32>
    %7 = bufferization.to_memref %6 : memref<?x10xf32>
    %c10_10 = arith.constant 10 : index
    %8 = arith.muli %c10_10, %dim : index
    %reinterpret_cast_11 = memref.reinterpret_cast %7 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %9 = bufferization.to_tensor %reinterpret_cast_11 : memref<?x10xf32>
    %10 = bufferization.to_memref %9 : memref<?x10xf32>
    %from_elements_12 = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
    %11 = bufferization.to_memref %from_elements_12 : memref<2xindex>
    %12 = bufferization.to_tensor %alloc_2 : memref<10xf32>
    %13 = bufferization.to_tensor %11 : memref<2xindex>
    %c0_13 = arith.constant 0 : index
    %extracted_14 = tensor.extract %13[%c0_13] : tensor<2xindex>
    %alloc_15 = memref.alloc(%extracted_14) : memref<?x10xf32>
    "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %11, %alloc_15) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
    %14 = bufferization.to_tensor %alloc_15 : memref<?x10xf32>
    %15 = bufferization.to_memref %14 : memref<?x10xf32>
    %c10_16 = arith.constant 10 : index
    %16 = arith.muli %c10_16, %dim : index
    %reinterpret_cast_17 = memref.reinterpret_cast %15 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %17 = bufferization.to_tensor %reinterpret_cast_17 : memref<?x10xf32>
    %18 = bufferization.to_memref %17 : memref<?x10xf32>
    %19 = bufferization.to_tensor %10 : memref<?x10xf32>
    %20 = bufferization.to_tensor %18 : memref<?x10xf32>
    %21 = shape.shape_of %19 : tensor<?x10xf32> -> tensor<2xindex>
    %c0_18 = arith.constant 0 : index
    %extracted_19 = tensor.extract %21[%c0_18] : tensor<2xindex>
    %alloc_20 = memref.alloc(%extracted_19) : memref<?x10xf32>
    "lmhlo.add"(%10, %18, %alloc_20) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
    %22 = bufferization.to_tensor %alloc_20 : memref<?x10xf32>
    %23 = bufferization.to_memref %22 : memref<?x10xf32>
    %c10_21 = arith.constant 10 : index
    %24 = arith.muli %c10_21, %dim : index
    %reinterpret_cast_22 = memref.reinterpret_cast %23 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %25 = bufferization.to_tensor %reinterpret_cast_22 : memref<?x10xf32>
    %26 = bufferization.to_memref %25 : memref<?x10xf32>
    %27 = bufferization.to_tensor %alloc : memref<f32>
    %28 = bufferization.to_tensor %11 : memref<2xindex>
    %c0_23 = arith.constant 0 : index
    %extracted_24 = tensor.extract %28[%c0_23] : tensor<2xindex>
    %alloc_25 = memref.alloc(%extracted_24) : memref<?x10xf32>
    "lmhlo.dynamic_broadcast_in_dim"(%alloc, %11, %alloc_25) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32>, memref<2xindex>, memref<?x10xf32>) -> ()
    %29 = bufferization.to_tensor %alloc_25 : memref<?x10xf32>
    %30 = bufferization.to_memref %29 : memref<?x10xf32>
    %c10_26 = arith.constant 10 : index
    %31 = arith.muli %c10_26, %dim : index
    %reinterpret_cast_27 = memref.reinterpret_cast %30 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %32 = bufferization.to_tensor %reinterpret_cast_27 : memref<?x10xf32>
    %33 = bufferization.to_memref %32 : memref<?x10xf32>
    %34 = bufferization.to_tensor %26 : memref<?x10xf32>
    %35 = bufferization.to_tensor %33 : memref<?x10xf32>
    %36 = shape.shape_of %34 : tensor<?x10xf32> -> tensor<2xindex>
    %c0_28 = arith.constant 0 : index
    %extracted_29 = tensor.extract %36[%c0_28] : tensor<2xindex>
    %alloc_30 = memref.alloc(%extracted_29) : memref<?x10xf32>
    "lmhlo.maximum"(%26, %33, %alloc_30) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
    %37 = bufferization.to_tensor %alloc_30 : memref<?x10xf32>
    %38 = bufferization.to_memref %37 : memref<?x10xf32>
    %c10_31 = arith.constant 10 : index
    %39 = arith.muli %c10_31, %dim : index
    %reinterpret_cast_32 = memref.reinterpret_cast %38 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %40 = bufferization.to_tensor %reinterpret_cast_32 : memref<?x10xf32>
    %41 = bufferization.to_memref %40 : memref<?x10xf32>
    %42 = bufferization.to_tensor %41 : memref<?x10xf32>
    %43 = bufferization.to_tensor %alloc_0 : memref<10x10xf32>
    %c0_33 = arith.constant 0 : index
    %dim_34 = tensor.dim %42, %c0_33 : tensor<?x10xf32>
    %c1_35 = arith.constant 1 : index
    %dim_36 = tensor.dim %43, %c1_35 : tensor<10x10xf32>
    %from_elements_37 = tensor.from_elements %dim_34, %dim_36 : tensor<2xindex>
    %c0_38 = arith.constant 0 : index
    %extracted_39 = tensor.extract %from_elements_37[%c0_38] : tensor<2xindex>
    %alloc_40 = memref.alloc(%extracted_39) : memref<?x10xf32>
    "lmhlo.dot_general"(%41, %alloc_0, %alloc_40) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
    %44 = bufferization.to_tensor %alloc_40 : memref<?x10xf32>
    %45 = bufferization.to_memref %44 : memref<?x10xf32>
    %c10_41 = arith.constant 10 : index
    %46 = arith.muli %c10_41, %dim : index
    %reinterpret_cast_42 = memref.reinterpret_cast %45 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %47 = bufferization.to_tensor %reinterpret_cast_42 : memref<?x10xf32>
    %48 = bufferization.to_memref %47 : memref<?x10xf32>
    %49 = bufferization.to_tensor %alloc_3 : memref<10xf32>
    %50 = bufferization.to_tensor %11 : memref<2xindex>
    %c0_43 = arith.constant 0 : index
    %extracted_44 = tensor.extract %50[%c0_43] : tensor<2xindex>
    %alloc_45 = memref.alloc(%extracted_44) : memref<?x10xf32>
    "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %11, %alloc_45) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
    %51 = bufferization.to_tensor %alloc_45 : memref<?x10xf32>
    %52 = bufferization.to_memref %51 : memref<?x10xf32>
    %c10_46 = arith.constant 10 : index
    %53 = arith.muli %c10_46, %dim : index
    %reinterpret_cast_47 = memref.reinterpret_cast %52 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %54 = bufferization.to_tensor %reinterpret_cast_47 : memref<?x10xf32>
    %55 = bufferization.to_memref %54 : memref<?x10xf32>
    %56 = bufferization.to_tensor %48 : memref<?x10xf32>
    %57 = bufferization.to_tensor %55 : memref<?x10xf32>
    %58 = shape.shape_of %56 : tensor<?x10xf32> -> tensor<2xindex>
    %c0_48 = arith.constant 0 : index
    %extracted_49 = tensor.extract %58[%c0_48] : tensor<2xindex>
    %alloc_50 = memref.alloc(%extracted_49) : memref<?x10xf32>
    "lmhlo.add"(%48, %55, %alloc_50) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
    %59 = bufferization.to_tensor %alloc_50 : memref<?x10xf32>
    %60 = bufferization.to_memref %59 : memref<?x10xf32>
    %c10_51 = arith.constant 10 : index
    %61 = arith.muli %c10_51, %dim : index
    %reinterpret_cast_52 = memref.reinterpret_cast %60 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    %62 = bufferization.to_tensor %reinterpret_cast_52 : memref<?x10xf32>
    %63 = bufferization.to_memref %62 : memref<?x10xf32>
    %64 = bufferization.to_tensor %63 : memref<?x10xf32>
    %65 = bufferization.to_tensor %33 : memref<?x10xf32>
    %66 = shape.shape_of %64 : tensor<?x10xf32> -> tensor<2xindex>
    %c0_53 = arith.constant 0 : index
    %extracted_54 = tensor.extract %66[%c0_53] : tensor<2xindex>
    %alloc_55 = memref.alloc(%extracted_54) : memref<?x10xf32>
    "lmhlo.maximum"(%63, %33, %alloc_55) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
    %67 = bufferization.to_tensor %alloc_55 : memref<?x10xf32>
    %68 = bufferization.to_memref %67 : memref<?x10xf32>
    %c10_56 = arith.constant 10 : index
    %69 = arith.muli %c10_56, %dim : index
    %reinterpret_cast_57 = memref.reinterpret_cast %68 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
    return %reinterpret_cast_57 : memref<?x10xf32>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<?x10xf32>) -> memref<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32>) -> ()
  %alloc_0 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_1 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_2 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32>
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_4 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_1, %alloc_4) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_5 = memref.reinterpret_cast %alloc_4 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
  %0 = bufferization.to_memref %from_elements : memref<2xindex>
  %alloc_6 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %0, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_7 = memref.reinterpret_cast %alloc_6 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_8 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_5, %reinterpret_cast_7, %alloc_8) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_9 = memref.reinterpret_cast %alloc_8 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %1 = bufferization.to_tensor %0 : memref<2xindex>
  %extracted = tensor.extract %1[%c0] : tensor<2xindex>
  %alloc_10 = memref.alloc(%extracted) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc, %0, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_12 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_9, %reinterpret_cast_11, %alloc_12) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_13 = memref.reinterpret_cast %alloc_12 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_14 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast_13, %alloc_0, %alloc_14) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_15 = memref.reinterpret_cast %alloc_14 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %2 = bufferization.to_tensor %0 : memref<2xindex>
  %extracted_16 = tensor.extract %2[%c0] : tensor<2xindex>
  %alloc_17 = memref.alloc(%extracted_16) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %0, %alloc_17) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_18 = memref.reinterpret_cast %alloc_17 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_19 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_15, %reinterpret_cast_18, %alloc_19) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_20 = memref.reinterpret_cast %alloc_19 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_21 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_20, %reinterpret_cast_11, %alloc_21) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_22 = memref.reinterpret_cast %alloc_21 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  return %reinterpret_cast_22 : memref<?x10xf32>
}

// -----// IR Dump After LegalizeToTensorOpPass (lhlo-legalize-to-tensor-op) //----- //
func.func @main(%arg0: memref<?x10xf32>) -> memref<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32>) -> ()
  %alloc_0 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_1 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_2 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32>
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_4 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_1, %alloc_4) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_5 = memref.reinterpret_cast %alloc_4 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
  %0 = bufferization.to_memref %from_elements : memref<2xindex>
  %alloc_6 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %0, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_7 = memref.reinterpret_cast %alloc_6 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_8 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_5, %reinterpret_cast_7, %alloc_8) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_9 = memref.reinterpret_cast %alloc_8 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %1 = memref.load %0[%c0] : memref<2xindex>
  %alloc_10 = memref.alloc(%1) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc, %0, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_12 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_9, %reinterpret_cast_11, %alloc_12) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_13 = memref.reinterpret_cast %alloc_12 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_14 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast_13, %alloc_0, %alloc_14) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_15 = memref.reinterpret_cast %alloc_14 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %2 = memref.load %0[%c0] : memref<2xindex>
  %alloc_16 = memref.alloc(%2) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %0, %alloc_16) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_17 = memref.reinterpret_cast %alloc_16 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_18 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_15, %reinterpret_cast_17, %alloc_18) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_19 = memref.reinterpret_cast %alloc_18 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_20 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_19, %reinterpret_cast_11, %alloc_20) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_21 = memref.reinterpret_cast %alloc_20 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  return %reinterpret_cast_21 : memref<?x10xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<?x10xf32>) -> memref<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32>) -> ()
  %alloc_0 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_1 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_2 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32>
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_4 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_1, %alloc_4) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_5 = memref.reinterpret_cast %alloc_4 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %from_elements = tensor.from_elements %dim, %c10 {disc.shape_op = true} : tensor<2xindex>
  %0 = bufferization.to_memref %from_elements : memref<2xindex>
  %alloc_6 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %0, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_7 = memref.reinterpret_cast %alloc_6 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_8 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_5, %reinterpret_cast_7, %alloc_8) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_9 = memref.reinterpret_cast %alloc_8 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_10 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc, %0, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_12 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_9, %reinterpret_cast_11, %alloc_12) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_13 = memref.reinterpret_cast %alloc_12 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_14 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast_13, %alloc_0, %alloc_14) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_15 = memref.reinterpret_cast %alloc_14 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_16 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %0, %alloc_16) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_17 = memref.reinterpret_cast %alloc_16 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_18 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_15, %reinterpret_cast_17, %alloc_18) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_19 = memref.reinterpret_cast %alloc_18 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_20 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_19, %reinterpret_cast_11, %alloc_20) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_21 = memref.reinterpret_cast %alloc_20 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  return %reinterpret_cast_21 : memref<?x10xf32>
}

// -----// IR Dump After TensorBufferize (tensor-bufferize) //----- //
func.func @main(%arg0: memref<?x10xf32>) -> memref<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32>) -> ()
  %alloc_0 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_1 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_2 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32>
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_4 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_1, %alloc_4) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_5 = memref.reinterpret_cast %alloc_4 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_6 = memref.alloc() {alignment = 64 : i64} : memref<2xindex>
  %c0_7 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  memref.store %dim, %alloc_6[%c0_7] : memref<2xindex>
  memref.store %c10, %alloc_6[%c1] : memref<2xindex>
  %alloc_8 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloc_6, %alloc_8) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_9 = memref.reinterpret_cast %alloc_8 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_10 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_5, %reinterpret_cast_9, %alloc_10) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_12 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloc_6, %alloc_12) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_13 = memref.reinterpret_cast %alloc_12 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_14 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_11, %reinterpret_cast_13, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_15 = memref.reinterpret_cast %alloc_14 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_16 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast_15, %alloc_0, %alloc_16) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_17 = memref.reinterpret_cast %alloc_16 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_18 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloc_6, %alloc_18) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_19 = memref.reinterpret_cast %alloc_18 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_20 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_17, %reinterpret_cast_19, %alloc_20) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_21 = memref.reinterpret_cast %alloc_20 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_22 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_21, %reinterpret_cast_13, %alloc_22) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_23 = memref.reinterpret_cast %alloc_22 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  return %reinterpret_cast_23 : memref<?x10xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<?x10xf32>) -> memref<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c1 = arith.constant 1 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32>) -> ()
  %alloc_0 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_1 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_2 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32>
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_4 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_1, %alloc_4) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_5 = memref.reinterpret_cast %alloc_4 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_6 = memref.alloc() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloc_6[%c0] : memref<2xindex>
  memref.store %c10, %alloc_6[%c1] : memref<2xindex>
  %alloc_7 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloc_6, %alloc_7) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_8 = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_9 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_5, %reinterpret_cast_8, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_10 = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_11 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloc_6, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_12 = memref.reinterpret_cast %alloc_11 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_13 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_10, %reinterpret_cast_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_14 = memref.reinterpret_cast %alloc_13 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_15 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast_14, %alloc_0, %alloc_15) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_16 = memref.reinterpret_cast %alloc_15 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_17 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloc_6, %alloc_17) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %reinterpret_cast_18 = memref.reinterpret_cast %alloc_17 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_19 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.add"(%reinterpret_cast_16, %reinterpret_cast_18, %alloc_19) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_20 = memref.reinterpret_cast %alloc_19 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_21 = memref.alloc(%dim) : memref<?x10xf32>
  "lmhlo.maximum"(%reinterpret_cast_20, %reinterpret_cast_12, %alloc_21) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %reinterpret_cast_22 = memref.reinterpret_cast %alloc_21 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  return %reinterpret_cast_22 : memref<?x10xf32>
}

// -----// IR Dump After DiscMemrefCanonicalizer (disc-memref-canonicalize) //----- //
func.func @main(%arg0: memref<?x10xf32>) -> memref<?x10xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c1 = arith.constant 1 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32>) -> ()
  %alloc_0 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_1 = memref.alloc() : memref<10x10xf32>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32>) -> ()
  %alloc_2 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32>
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32> to memref<?x10xf32>
  %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_1, %alloc_4) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %alloc_5 = memref.alloc() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloc_5[%c0] : memref<2xindex>
  memref.store %c10, %alloc_5[%c1] : memref<2xindex>
  %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloc_5, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32>
  "lmhlo.add"(%alloc_4, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloc_5, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32>
  "lmhlo.maximum"(%alloc_7, %alloc_8, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32>
  "lmhlo.dot_general"(%alloc_9, %alloc_0, %alloc_10) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32>, memref<10x10xf32>, memref<?x10xf32>) -> ()
  %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloc_5, %alloc_11) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32>, memref<2xindex>, memref<?x10xf32>) -> ()
  %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32>
  "lmhlo.add"(%alloc_10, %alloc_11, %alloc_12) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32>
  "lmhlo.maximum"(%alloc_12, %alloc_8, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32>, memref<?x10xf32>, memref<?x10xf32>) -> ()
  return %alloc_13 : memref<?x10xf32>
}

// -----// IR Dump After DiscAssignMemorySpacePass (disc-assign-memory-space) //----- //
module {
  func.func @main(%arg0: memref<?x10xf32, #gpu.address_space<global>>) -> memref<?x10xf32, #gpu.address_space<global>> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc() : memref<f32, #gpu.address_space<global>>
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
    %alloc_0 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
    "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_1 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
    "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_2 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
    "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
    %alloc_3 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
    "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
    %dim = memref.dim %arg0, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.dot_general"(%reinterpret_cast, %alloc_1, %alloc_4) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_5 = memref.alloc() {alignment = 64 : i64} : memref<2xindex>
    memref.store %dim, %alloc_5[%c0] : memref<2xindex>
    memref.store %c10, %alloc_5[%c1] : memref<2xindex>
    %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloc_5, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.add"(%alloc_4, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloc_5, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.maximum"(%alloc_7, %alloc_8, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.dot_general"(%alloc_9, %alloc_0, %alloc_10) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloc_5, %alloc_11) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.add"(%alloc_10, %alloc_11, %alloc_12) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.maximum"(%alloc_12, %alloc_8, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return %alloc_13 : memref<?x10xf32, #gpu.address_space<global>>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscDuplicateComputationForFusionPass (disc-duplicate-computation-for-fusion) //----- //
func.func @main(%arg0: memref<?x10xf32, #gpu.address_space<global>>) -> memref<?x10xf32, #gpu.address_space<global>> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c1 = arith.constant 1 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_0) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
  %alloc_1 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_2 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %alloc_4 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_2, %alloc_5) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_6 = memref.alloc() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloc_6[%c0] : memref<2xindex>
  memref.store %c10, %alloc_6[%c1] : memref<2xindex>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloc_6, %alloc_7) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.add"(%alloc_5, %alloc_7, %alloc_8) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloc_6, %alloc_9) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloc_6, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  "lmhlo.maximum"(%alloc_8, %alloc_11, %alloc_10) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%alloc_10, %alloc_1, %alloc_12) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloc_6, %alloc_13) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.add"(%alloc_12, %alloc_13, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_15 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.maximum"(%alloc_14, %alloc_9, %alloc_15) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return %alloc_15 : memref<?x10xf32, #gpu.address_space<global>>
}

// -----// IR Dump After PromoteBuffersToStack (promote-buffers-to-stack) //----- //
func.func @main(%arg0: memref<?x10xf32, #gpu.address_space<global>>) -> memref<?x10xf32, #gpu.address_space<global>> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c1 = arith.constant 1 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_0) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
  %alloc_1 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_2 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %alloc_4 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_2, %alloc_5) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.add"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloca, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  "lmhlo.maximum"(%alloc_7, %alloc_10, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%alloc_9, %alloc_1, %alloc_11) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.add"(%alloc_11, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.maximum"(%alloc_13, %alloc_8, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return %alloc_14 : memref<?x10xf32, #gpu.address_space<global>>
}

SymbolicDimMgr::save walkRankedTensorValue takes: 2 us
SymbolicDimMgr::save update attributes takes: 9 us
SymbolicDimMgr::save updateProductEqualityMap takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 2 us
SymbolicDimMgr::save collect symbolicDim ops takes: 5 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 4 us
SymbolicDimMgr::save replace the name takes: 8 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
// -----// IR Dump After DiscFusionPass (disc-fusion) //----- //
func.func @main(%arg0: memref<?x10xf32, #gpu.address_space<global>>) -> memref<?x10xf32, #gpu.address_space<global>> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c1 = arith.constant 1 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_2 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %alloc_4 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_2, %alloc_5) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
    "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    "lmhlo.add"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloca, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    "lmhlo.maximum"(%alloc_7, %alloc_10, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop"} : () -> ()
  %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%alloc_9, %alloc_1, %alloc_11) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc_0) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
    "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    "lmhlo.add"(%alloc_11, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    "lmhlo.maximum"(%alloc_13, %alloc_8, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop"} : () -> ()
  return %alloc_14 : memref<?x10xf32, #gpu.address_space<global>>
}

SymbolicDimMgr::save walkRankedTensorValue takes: 2 us
SymbolicDimMgr::save update attributes takes: 9 us
SymbolicDimMgr::save updateProductEqualityMap takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 2 us
SymbolicDimMgr::save collect symbolicDim ops takes: 7 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 9 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
// -----// IR Dump After DiscSpecializeFusionWithSpeculationPass (disc-specialize-fusion-with-speculation) //----- //
func.func @main(%arg0: memref<?x10xf32, #gpu.address_space<global>>) -> memref<?x10xf32, #gpu.address_space<global>> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c1 = arith.constant 1 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_2 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %alloc_4 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_2, %alloc_5) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %c1_11 = arith.constant 1 : index
  %c0_12 = arith.constant 0 : index
  %dim_13 = memref.dim %alloc_9, %c0_12 : memref<?x10xf32, #gpu.address_space<global>>
  %0 = arith.muli %c1_11, %dim_13 : index
  %c1_14 = arith.constant 1 : index
  %dim_15 = memref.dim %alloc_9, %c1_14 : memref<?x10xf32, #gpu.address_space<global>>
  %1 = arith.muli %0, %dim_15 : index
  %c0_16 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %2 = arith.remui %1, %c4 : index
  %3 = arith.cmpi eq, %2, %c0_16 : index
  scf.if %3 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloca, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_7, %alloc_10, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloca, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_7, %alloc_10, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  %alloc_17 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%alloc_9, %alloc_1, %alloc_17) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_18 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_19 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_20 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %c1_21 = arith.constant 1 : index
  %c0_22 = arith.constant 0 : index
  %dim_23 = memref.dim %alloc_20, %c0_22 : memref<?x10xf32, #gpu.address_space<global>>
  %4 = arith.muli %c1_21, %dim_23 : index
  %c1_24 = arith.constant 1 : index
  %dim_25 = memref.dim %alloc_20, %c1_24 : memref<?x10xf32, #gpu.address_space<global>>
  %5 = arith.muli %4, %dim_25 : index
  %c0_26 = arith.constant 0 : index
  %c4_27 = arith.constant 4 : index
  %6 = arith.remui %5, %c4_27 : index
  %7 = arith.cmpi eq, %6, %c0_26 : index
  scf.if %7 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_18) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_17, %alloc_18, %alloc_19) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_19, %alloc_8, %alloc_20) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_18) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_17, %alloc_18, %alloc_19) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_19, %alloc_8, %alloc_20) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  return %alloc_20 : memref<?x10xf32, #gpu.address_space<global>>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<?x10xf32, #gpu.address_space<global>>) -> memref<?x10xf32, #gpu.address_space<global>> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_2 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %alloc_4 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_2, %alloc_5) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %0 = arith.muli %dim, %c10 : index
  %1 = arith.remui %0, %c4 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  scf.if %2 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloca, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_7, %alloc_10, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloca, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_7, %alloc_10, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%alloc_9, %alloc_1, %alloc_11) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %3 = arith.muli %dim, %c10 : index
  %4 = arith.remui %3, %c4 : index
  %5 = arith.cmpi eq, %4, %c0 : index
  scf.if %5 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_11, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_8, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_11, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_8, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  return %alloc_14 : memref<?x10xf32, #gpu.address_space<global>>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: memref<?x10xf32, #gpu.address_space<global>>) -> memref<?x10xf32, #gpu.address_space<global>> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_2 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_3 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %alloc_4 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_2, %alloc_5) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %0 = arith.muli %dim, %c10 : index
  %1 = arith.remui %0, %c4 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  scf.if %2 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloca, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_7, %alloc_10, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc, %alloca, %alloc_10) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_7, %alloc_10, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%alloc_9, %alloc_1, %alloc_11) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %2 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_11, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_8, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_11, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_8, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  return %alloc_14 : memref<?x10xf32, #gpu.address_space<global>>
}

// -----// IR Dump After DiscReduceBufferLiveRangePass (disc-reduce-buffer-live-range) //----- //
func.func @main(%arg0: memref<?x10xf32, #gpu.address_space<global>>) -> memref<?x10xf32, #gpu.address_space<global>> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_0 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_1 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %alloc_2 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_0, %alloc_3) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %0 = arith.muli %dim, %c10 : index
  %1 = arith.remui %0, %c4 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  %alloc_4 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %2 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_1, %alloca, %alloc_5) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_3, %alloc_5, %alloc_6) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_6, %alloc_8, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_1, %alloca, %alloc_5) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_3, %alloc_5, %alloc_6) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_6, %alloc_8, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%alloc_7, %alloc, %alloc_9) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_10 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %2 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_10) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_10, %alloca, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_9, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_11, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_10) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_10, %alloca, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_9, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_11, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  return %alloc_14 : memref<?x10xf32, #gpu.address_space<global>>
}

// -----// IR Dump After BufferDeallocation (buffer-deallocation) //----- //
func.func @main(%arg0: memref<?x10xf32, #gpu.address_space<global>>) -> memref<?x10xf32, #gpu.address_space<global>> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c10 = arith.constant 10 : index
  %c4 = arith.constant 4 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %dim = memref.dim %arg0, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_0 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_1 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %alloc_2 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%reinterpret_cast, %alloc_0, %alloc_3) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  memref.dealloc %alloc_0 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %0 = arith.muli %dim, %c10 : index
  %1 = arith.remui %0, %c4 : index
  %2 = arith.cmpi eq, %1, %c0 : index
  %alloc_4 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %2 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_1, %alloca, %alloc_5) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_3, %alloc_5, %alloc_6) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_6, %alloc_8, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_1, %alloca, %alloc_5) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_3, %alloc_5, %alloc_6) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_6, %alloc_8, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_4 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "lmhlo.dot_general"(%alloc_7, %alloc, %alloc_9) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %2 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_10) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_10, %alloca, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_9, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_11, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_10) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_10, %alloca, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_9, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_11, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_13 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_12 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_11 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_10 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<10xf32, #gpu.address_space<global>>
  return %alloc_14 : memref<?x10xf32, #gpu.address_space<global>>
}

// -----// IR Dump After RalInjectExecutionContextPass (disc-ral-inject-execution-context) //----- //
module {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.recv_input"(%arg0, %c0) : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %c10 = arith.constant 10 : index
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0_0 = arith.constant 0 : index
    %dim = memref.dim %0, %c0_0 : memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_1 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
    "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
    %alloc_2 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
    "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
    %alloc_3 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
    "lmhlo.constant"(%alloc_3) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
    %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.dot_general"(%reinterpret_cast, %alloc_1, %alloc_4) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    memref.dealloc %alloc_1 : memref<10x10xf32, #gpu.address_space<global>>
    %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
    memref.store %dim, %alloca[%c0_0] : memref<2xindex>
    memref.store %c10, %alloca[%c1] : memref<2xindex>
    %1 = arith.muli %dim, %c10 : index
    %2 = arith.remui %1, %c4 : index
    %3 = arith.cmpi eq, %2, %c0_0 : index
    %alloc_5 = memref.alloc() : memref<f32, #gpu.address_space<global>>
    %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %3 {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc_5) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.add"(%alloc_4, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_5, %alloca, %alloc_9) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.maximum"(%alloc_7, %alloc_9, %alloc_8) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc_5) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloca, %alloc_6) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.add"(%alloc_4, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_5, %alloca, %alloc_9) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.maximum"(%alloc_7, %alloc_9, %alloc_8) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_6 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_5 : memref<f32, #gpu.address_space<global>>
    memref.dealloc %alloc_4 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_2 : memref<10xf32, #gpu.address_space<global>>
    %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "lmhlo.dot_general"(%alloc_8, %alloc, %alloc_10) {disc.device = "gpu", dot_dimension_numbers = #mhlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>} : (memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_11 = memref.alloc() : memref<f32, #gpu.address_space<global>>
    %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_15 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %3 {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc_11) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_11, %alloca, %alloc_12) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_13) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.add"(%alloc_10, %alloc_13, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.maximum"(%alloc_14, %alloc_12, %alloc_15) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc_11) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_11, %alloca, %alloc_12) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_3, %alloca, %alloc_13) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.add"(%alloc_10, %alloc_13, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.maximum"(%alloc_14, %alloc_12, %alloc_15) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc_14 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_13 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_12 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_11 : memref<f32, #gpu.address_space<global>>
    memref.dealloc %alloc_10 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_3 : memref<10xf32, #gpu.address_space<global>>
    %c0_16 = arith.constant 0 : index
    "disc_ral.send_output"(%arg0, %c0_16, %alloc_15) : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscLowerToLibraryCallPass (disc-lower-to-library-call) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_0 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense_resource<__elided__> : tensor<10x10xf32>} : (memref<10x10xf32, #gpu.address_space<global>>) -> ()
  %alloc_1 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_1) {disc.device = "gpu", value = dense<[-0.0684198961, -0.0121491952, 0.127185106, -0.18503201, -0.194590867, 0.25447163, -4.787710e-02, 0.0185489878, 0.0749137476, 0.0754040703]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %alloc_2 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
  "lmhlo.constant"(%alloc_2) {disc.device = "gpu", value = dense<[0.110269576, -0.209282219, 0.023534907, -0.111158408, 0.166983217, -4.79283306E-4, -0.00845900736, -0.00818163063, 0.281652302, 0.121823721]> : tensor<10xf32>} : (memref<10xf32, #gpu.address_space<global>>) -> ()
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %2, %reinterpret_cast, %alloc_0, %alloc_3, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %3 = arith.muli %dim, %c10 : index
  %4 = arith.remui %3, %c4 : index
  %5 = arith.cmpi eq, %4, %c0 : index
  %alloc_4 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %5 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_1, %alloca, %alloc_5) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_3, %alloc_5, %alloc_6) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_6, %alloc_8, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_1, %alloca, %alloc_5) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_3, %alloc_5, %alloc_6) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_6, %alloc_8, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_4 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %6 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %6, %alloc_7, %alloc, %alloc_9, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %5 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_10) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_10, %alloca, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_9, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_11, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_10) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_10, %alloca, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_2, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_9, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_13, %alloc_11, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_13 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_12 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_11 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_10 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_14) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After DiscConstToRALPass (disc-const-to-ral) //----- //
module {
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = llvm.mlir.constant(0 : i32) : i32
    %false = arith.constant false
    %true = arith.constant true
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
    %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %4 = llvm.mlir.constant(0 : i32) : i32
    %5 = llvm.inttoptr %4 : i32 to !llvm.ptr<i8>
    %c0_i32 = arith.constant 0 : i32
    %6 = "disc_ral.dispatch"(%arg0, %5, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %alloc_0 = memref.alloc() : memref<10x10xf32, #gpu.address_space<global>>
    %7 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %8 = llvm.getelementptr %7[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %9 = llvm.mlir.constant(0 : i32) : i32
    %10 = llvm.inttoptr %9 : i32 to !llvm.ptr<i8>
    %c1_i32 = arith.constant 1 : i32
    %11 = "disc_ral.dispatch"(%arg0, %10, %8, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %alloc_1 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
    %12 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %14 = llvm.mlir.constant(0 : i32) : i32
    %15 = llvm.inttoptr %14 : i32 to !llvm.ptr<i8>
    %c2_i32 = arith.constant 2 : i32
    %16 = "disc_ral.dispatch"(%arg0, %15, %13, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %alloc_2 = memref.alloc() : memref<10xf32, #gpu.address_space<global>>
    %17 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %18 = llvm.getelementptr %17[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %19 = llvm.mlir.constant(0 : i32) : i32
    %20 = llvm.inttoptr %19 : i32 to !llvm.ptr<i8>
    %c3_i32 = arith.constant 3 : i32
    %21 = "disc_ral.dispatch"(%arg0, %20, %18, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    "disc_ral.dispatch"(%arg0, %22, %reinterpret_cast, %11, %alloc_3, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %11 : memref<10x10xf32, #gpu.address_space<global>>
    %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
    memref.store %dim, %alloca[%c0] : memref<2xindex>
    memref.store %c10, %alloca[%c1] : memref<2xindex>
    %23 = arith.muli %dim, %c10 : index
    %24 = arith.remui %23, %c4 : index
    %25 = arith.cmpi eq, %24, %c0 : index
    %alloc_4 = memref.alloc() : memref<f32, #gpu.address_space<global>>
    %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_6 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %25 {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%16, %alloca, %alloc_5) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.add"(%alloc_3, %alloc_5, %alloc_6) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.maximum"(%alloc_6, %alloc_8, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc_4) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%16, %alloca, %alloc_5) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.add"(%alloc_3, %alloc_5, %alloc_6) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_4, %alloca, %alloc_8) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.maximum"(%alloc_6, %alloc_8, %alloc_7) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_6 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_4 : memref<f32, #gpu.address_space<global>>
    memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %16 : memref<10xf32, #gpu.address_space<global>>
    %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %26 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    "disc_ral.dispatch"(%arg0, %26, %alloc_7, %6, %alloc_9, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %6 : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_10 = memref.alloc() : memref<f32, #gpu.address_space<global>>
    %alloc_11 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_12 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_13 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    %alloc_14 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %25 {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc_10) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_10, %alloca, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%21, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.add"(%alloc_9, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.maximum"(%alloc_13, %alloc_11, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc_10) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%alloc_10, %alloca, %alloc_11) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.dynamic_broadcast_in_dim"(%21, %alloca, %alloc_12) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.add"(%alloc_9, %alloc_12, %alloc_13) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.maximum"(%alloc_13, %alloc_11, %alloc_14) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc_13 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_12 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_11 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %alloc_10 : memref<f32, #gpu.address_space<global>>
    memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %21 : memref<10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %c0, %alloc_14) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscMemRefLoadStoreSimplifierPass (disc-memref-load-store-simplifier) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %9 = "disc_ral.dispatch"(%arg0, %8, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %10 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %11 = llvm.getelementptr %10[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %12 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %13 = "disc_ral.dispatch"(%arg0, %12, %11, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %14 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %15 = llvm.getelementptr %14[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %17 = "disc_ral.dispatch"(%arg0, %16, %15, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %18, %reinterpret_cast, %9, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %9 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %19 = arith.muli %dim, %c10 : index
  %20 = arith.remui %19, %c4 : index
  %21 = arith.cmpi eq, %20, %c0 : index
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%13, %alloca, %alloc_1) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc, %alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_4) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_2, %alloc_4, %alloc_3) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%13, %alloca, %alloc_1) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc, %alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_4) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_2, %alloc_4, %alloc_3) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_4 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_0 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %13 : memref<10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %22, %alloc_3, %5, %alloc_5, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_6) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_6, %alloca, %alloc_7) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%17, %alloca, %alloc_8) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_8, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_9, %alloc_7, %alloc_10) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_6) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_6, %alloca, %alloc_7) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%17, %alloca, %alloc_8) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_8, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.maximum"(%alloc_9, %alloc_7, %alloc_10) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %17 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_10) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

SymbolicDimMgr::save walkRankedTensorValue takes: 5 us
SymbolicDimMgr::save update attributes takes: 12 us
SymbolicDimMgr::save updateProductEqualityMap takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 3 us
SymbolicDimMgr::save collect symbolicDim ops takes: 11 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 4 us
SymbolicDimMgr::save replace the name takes: 13 us
SymbolicDimMgr::save updateFunctionType takes: 2 us
// -----// IR Dump After DiscLhloLegalizeRootsToParallelLoopsPass (disc-lhlo-legalize-roots-to-parallel-loops) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %9 = "disc_ral.dispatch"(%arg0, %8, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %10 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %11 = llvm.getelementptr %10[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %12 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %13 = "disc_ral.dispatch"(%arg0, %12, %11, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %14 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %15 = llvm.getelementptr %14[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %17 = "disc_ral.dispatch"(%arg0, %16, %15, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %18, %reinterpret_cast, %9, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %9 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %19 = arith.muli %dim, %c10 : index
  %20 = arith.remui %19, %c4 : index
  %21 = arith.cmpi eq, %20, %c0 : index
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%13, %alloca, %alloc_1) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc, %alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_4) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        scf.for %arg2 = %c0 to %c4 step %c1 {
          %25 = arith.muli %arg1, %c4 : index
          %26 = arith.addi %25, %arg2 : index
          %27 = arith.muli %dim, %c10 : index
          %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%27], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          %28:2 = "disc_shape.delinearize"(%26, %dim, %c10) : (index, index, index) -> (index, index)
          %29 = memref.load %alloc_2[%28#0, %28#1] : memref<?x10xf32, #gpu.address_space<global>>
          %30 = memref.load %alloc_4[%28#0, %28#1] : memref<?x10xf32, #gpu.address_space<global>>
          %31 = arith.maxf %29, %30 : f32
          memref.store %31, %reinterpret_cast_11[%26] : memref<?xf32, #gpu.address_space<global>>
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_0) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%13, %alloca, %alloc_1) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc, %alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_0, %alloca, %alloc_4) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc_2[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %alloc_4[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %28 = arith.maxf %26, %27 : f32
        memref.store %28, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_4 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_0 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %13 : memref<10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %22, %alloc_3, %5, %alloc_5, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_6) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_6, %alloca, %alloc_7) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%17, %alloca, %alloc_8) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_8, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        scf.for %arg2 = %c0 to %c4 step %c1 {
          %25 = arith.muli %arg1, %c4 : index
          %26 = arith.addi %25, %arg2 : index
          %27 = arith.muli %dim, %c10 : index
          %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%27], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          %28:2 = "disc_shape.delinearize"(%26, %dim, %c10) : (index, index, index) -> (index, index)
          %29 = memref.load %alloc_9[%28#0, %28#1] : memref<?x10xf32, #gpu.address_space<global>>
          %30 = memref.load %alloc_7[%28#0, %28#1] : memref<?x10xf32, #gpu.address_space<global>>
          %31 = arith.maxf %29, %30 : f32
          memref.store %31, %reinterpret_cast_11[%26] : memref<?xf32, #gpu.address_space<global>>
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc_6) {value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%alloc_6, %alloca, %alloc_7) {broadcast_dimensions = dense<> : tensor<0xi64>, disc.device = "gpu"} : (memref<f32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.dynamic_broadcast_in_dim"(%17, %alloca, %alloc_8) {broadcast_dimensions = dense<1> : tensor<1xi64>, disc.device = "gpu"} : (memref<10xf32, #gpu.address_space<global>>, memref<2xindex>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      "lmhlo.add"(%alloc_5, %alloc_8, %alloc_9) {disc.device = "gpu"} : (memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>) -> ()
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc_9[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %alloc_7[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %28 = arith.maxf %26, %27 : f32
        memref.store %28, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %17 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_10) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After InputInlineFusionPass (disc-input-inline-fusion) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %9 = "disc_ral.dispatch"(%arg0, %8, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %10 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %11 = llvm.getelementptr %10[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %12 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %13 = "disc_ral.dispatch"(%arg0, %12, %11, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %14 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %15 = llvm.getelementptr %14[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %17 = "disc_ral.dispatch"(%arg0, %16, %15, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %18, %reinterpret_cast, %9, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %9 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %19 = arith.muli %dim, %c10 : index
  %20 = arith.remui %19, %c4 : index
  %21 = arith.cmpi eq, %20, %c0 : index
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        scf.for %arg2 = %c0 to %c4 step %c1 {
          %25 = arith.muli %arg1, %c4 : index
          %26 = arith.addi %25, %arg2 : index
          %27 = arith.muli %dim, %c10 : index
          %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%27], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          %28:2 = "disc_shape.delinearize"(%26, %dim, %c10) : (index, index, index) -> (index, index)
          %29 = memref.load %alloc[%28#0, %28#1] : memref<?x10xf32, #gpu.address_space<global>>
          %30 = memref.load %13[%28#1] : memref<10xf32, #gpu.address_space<global>>
          %31 = arith.addf %29, %30 : f32
          %32 = arith.maxf %31, %cst : f32
          memref.store %32, %reinterpret_cast_11[%26] : memref<?xf32, #gpu.address_space<global>>
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %13[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.maxf %28, %cst : f32
        memref.store %29, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_4 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_0 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %13 : memref<10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %22, %alloc_3, %5, %alloc_5, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        scf.for %arg2 = %c0 to %c4 step %c1 {
          %25 = arith.muli %arg1, %c4 : index
          %26 = arith.addi %25, %arg2 : index
          %27 = arith.muli %dim, %c10 : index
          %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%27], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          %28:2 = "disc_shape.delinearize"(%26, %dim, %c10) : (index, index, index) -> (index, index)
          %29 = memref.load %alloc_5[%28#0, %28#1] : memref<?x10xf32, #gpu.address_space<global>>
          %30 = memref.load %17[%28#1] : memref<10xf32, #gpu.address_space<global>>
          %31 = arith.addf %29, %30 : f32
          %32 = arith.maxf %31, %cst : f32
          memref.store %32, %reinterpret_cast_11[%26] : memref<?xf32, #gpu.address_space<global>>
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc_5[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %17[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.maxf %28, %cst : f32
        memref.store %29, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %17 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_10) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After ForLoopUnrollInterleave (disc-for-loop-unroll-interleave) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %9 = "disc_ral.dispatch"(%arg0, %8, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %10 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %11 = llvm.getelementptr %10[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %12 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %13 = "disc_ral.dispatch"(%arg0, %12, %11, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %14 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %15 = llvm.getelementptr %14[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %17 = "disc_ral.dispatch"(%arg0, %16, %15, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %18, %reinterpret_cast, %9, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %9 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %19 = arith.muli %dim, %c10 : index
  %20 = arith.remui %19, %c4 : index
  %21 = arith.cmpi eq, %20, %c0 : index
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %13, 16 : memref<10xf32, #gpu.address_space<global>>
        %c4_11 = arith.constant 4 : index
        %c1_12 = arith.constant 1 : index
        %25 = arith.muli %c1, %c1_12 : index
        %26 = arith.addi %c0, %25 : index
        %c2 = arith.constant 2 : index
        %27 = arith.muli %c1, %c2 : index
        %28 = arith.addi %c0, %27 : index
        %c3 = arith.constant 3 : index
        %29 = arith.muli %c1, %c3 : index
        %30 = arith.addi %c0, %29 : index
        %31 = arith.muli %arg1, %c4 : index
        %32 = arith.muli %arg1, %c4 : index
        %33 = arith.muli %arg1, %c4 : index
        %34 = arith.muli %arg1, %c4 : index
        %35 = arith.addi %31, %c0 : index
        %36 = arith.addi %32, %26 : index
        %37 = arith.addi %33, %28 : index
        %38 = arith.addi %34, %30 : index
        %39 = arith.muli %dim, %c10 : index
        %40 = arith.muli %dim, %c10 : index
        %41 = arith.muli %dim, %c10 : index
        %42 = arith.muli %dim, %c10 : index
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%39], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%40], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_15 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%41], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_16 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%42], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_16, 16 : memref<?xf32, #gpu.address_space<global>>
        %43:2 = "disc_shape.delinearize"(%35, %dim, %c10) : (index, index, index) -> (index, index)
        %44:2 = "disc_shape.delinearize"(%36, %dim, %c10) : (index, index, index) -> (index, index)
        %45:2 = "disc_shape.delinearize"(%37, %dim, %c10) : (index, index, index) -> (index, index)
        %46:2 = "disc_shape.delinearize"(%38, %dim, %c10) : (index, index, index) -> (index, index)
        %47 = memref.load %alloc[%43#0, %43#1] : memref<?x10xf32, #gpu.address_space<global>>
        %48 = memref.load %alloc[%44#0, %44#1] : memref<?x10xf32, #gpu.address_space<global>>
        %49 = memref.load %alloc[%45#0, %45#1] : memref<?x10xf32, #gpu.address_space<global>>
        %50 = memref.load %alloc[%46#0, %46#1] : memref<?x10xf32, #gpu.address_space<global>>
        %51 = memref.load %13[%43#1] : memref<10xf32, #gpu.address_space<global>>
        %52 = memref.load %13[%44#1] : memref<10xf32, #gpu.address_space<global>>
        %53 = memref.load %13[%45#1] : memref<10xf32, #gpu.address_space<global>>
        %54 = memref.load %13[%46#1] : memref<10xf32, #gpu.address_space<global>>
        %55 = arith.addf %47, %51 : f32
        %56 = arith.addf %48, %52 : f32
        %57 = arith.addf %49, %53 : f32
        %58 = arith.addf %50, %54 : f32
        %59 = arith.maxf %55, %cst : f32
        %60 = arith.maxf %56, %cst : f32
        %61 = arith.maxf %57, %cst : f32
        %62 = arith.maxf %58, %cst : f32
        memref.store %59, %reinterpret_cast_13[%35] : memref<?xf32, #gpu.address_space<global>>
        memref.store %60, %reinterpret_cast_14[%36] : memref<?xf32, #gpu.address_space<global>>
        memref.store %61, %reinterpret_cast_15[%37] : memref<?xf32, #gpu.address_space<global>>
        memref.store %62, %reinterpret_cast_16[%38] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %13[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.maxf %28, %cst : f32
        memref.store %29, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_4 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_0 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %13 : memref<10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %22, %alloc_3, %5, %alloc_5, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %17, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %alloc_5, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %c4_11 = arith.constant 4 : index
        %c1_12 = arith.constant 1 : index
        %25 = arith.muli %c1, %c1_12 : index
        %26 = arith.addi %c0, %25 : index
        %c2 = arith.constant 2 : index
        %27 = arith.muli %c1, %c2 : index
        %28 = arith.addi %c0, %27 : index
        %c3 = arith.constant 3 : index
        %29 = arith.muli %c1, %c3 : index
        %30 = arith.addi %c0, %29 : index
        %31 = arith.muli %arg1, %c4 : index
        %32 = arith.muli %arg1, %c4 : index
        %33 = arith.muli %arg1, %c4 : index
        %34 = arith.muli %arg1, %c4 : index
        %35 = arith.addi %31, %c0 : index
        %36 = arith.addi %32, %26 : index
        %37 = arith.addi %33, %28 : index
        %38 = arith.addi %34, %30 : index
        %39 = arith.muli %dim, %c10 : index
        %40 = arith.muli %dim, %c10 : index
        %41 = arith.muli %dim, %c10 : index
        %42 = arith.muli %dim, %c10 : index
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%39], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%40], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_15 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%41], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_16 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%42], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_16, 16 : memref<?xf32, #gpu.address_space<global>>
        %43:2 = "disc_shape.delinearize"(%35, %dim, %c10) : (index, index, index) -> (index, index)
        %44:2 = "disc_shape.delinearize"(%36, %dim, %c10) : (index, index, index) -> (index, index)
        %45:2 = "disc_shape.delinearize"(%37, %dim, %c10) : (index, index, index) -> (index, index)
        %46:2 = "disc_shape.delinearize"(%38, %dim, %c10) : (index, index, index) -> (index, index)
        %47 = memref.load %alloc_5[%43#0, %43#1] : memref<?x10xf32, #gpu.address_space<global>>
        %48 = memref.load %alloc_5[%44#0, %44#1] : memref<?x10xf32, #gpu.address_space<global>>
        %49 = memref.load %alloc_5[%45#0, %45#1] : memref<?x10xf32, #gpu.address_space<global>>
        %50 = memref.load %alloc_5[%46#0, %46#1] : memref<?x10xf32, #gpu.address_space<global>>
        %51 = memref.load %17[%43#1] : memref<10xf32, #gpu.address_space<global>>
        %52 = memref.load %17[%44#1] : memref<10xf32, #gpu.address_space<global>>
        %53 = memref.load %17[%45#1] : memref<10xf32, #gpu.address_space<global>>
        %54 = memref.load %17[%46#1] : memref<10xf32, #gpu.address_space<global>>
        %55 = arith.addf %47, %51 : f32
        %56 = arith.addf %48, %52 : f32
        %57 = arith.addf %49, %53 : f32
        %58 = arith.addf %50, %54 : f32
        %59 = arith.maxf %55, %cst : f32
        %60 = arith.maxf %56, %cst : f32
        %61 = arith.maxf %57, %cst : f32
        %62 = arith.maxf %58, %cst : f32
        memref.store %59, %reinterpret_cast_13[%35] : memref<?xf32, #gpu.address_space<global>>
        memref.store %60, %reinterpret_cast_14[%36] : memref<?xf32, #gpu.address_space<global>>
        memref.store %61, %reinterpret_cast_15[%37] : memref<?xf32, #gpu.address_space<global>>
        memref.store %62, %reinterpret_cast_16[%38] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc_5[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %17[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.maxf %28, %cst : f32
        memref.store %29, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %17 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_10) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After DiscBF16ExpansionPass (disc-bf16-expansion) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %9 = "disc_ral.dispatch"(%arg0, %8, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %10 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %11 = llvm.getelementptr %10[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %12 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %13 = "disc_ral.dispatch"(%arg0, %12, %11, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %14 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %15 = llvm.getelementptr %14[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %17 = "disc_ral.dispatch"(%arg0, %16, %15, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %18, %reinterpret_cast, %9, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %9 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %19 = arith.muli %dim, %c10 : index
  %20 = arith.remui %19, %c4 : index
  %21 = arith.cmpi eq, %20, %c0 : index
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %13, 16 : memref<10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_12 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_12, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %40 = memref.load %alloc[%36#0, %36#1] : memref<?x10xf32, #gpu.address_space<global>>
        %41 = memref.load %alloc[%37#0, %37#1] : memref<?x10xf32, #gpu.address_space<global>>
        %42 = memref.load %alloc[%38#0, %38#1] : memref<?x10xf32, #gpu.address_space<global>>
        %43 = memref.load %alloc[%39#0, %39#1] : memref<?x10xf32, #gpu.address_space<global>>
        %44 = memref.load %13[%36#1] : memref<10xf32, #gpu.address_space<global>>
        %45 = memref.load %13[%37#1] : memref<10xf32, #gpu.address_space<global>>
        %46 = memref.load %13[%38#1] : memref<10xf32, #gpu.address_space<global>>
        %47 = memref.load %13[%39#1] : memref<10xf32, #gpu.address_space<global>>
        %48 = arith.addf %40, %44 : f32
        %49 = arith.addf %41, %45 : f32
        %50 = arith.addf %42, %46 : f32
        %51 = arith.addf %43, %47 : f32
        %52 = arith.maxf %48, %cst : f32
        %53 = arith.maxf %49, %cst : f32
        %54 = arith.maxf %50, %cst : f32
        %55 = arith.maxf %51, %cst : f32
        memref.store %52, %reinterpret_cast_11[%25] : memref<?xf32, #gpu.address_space<global>>
        memref.store %53, %reinterpret_cast_12[%29] : memref<?xf32, #gpu.address_space<global>>
        memref.store %54, %reinterpret_cast_13[%30] : memref<?xf32, #gpu.address_space<global>>
        memref.store %55, %reinterpret_cast_14[%31] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %13[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.maxf %28, %cst : f32
        memref.store %29, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_4 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_0 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %13 : memref<10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %22, %alloc_3, %5, %alloc_5, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %17, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %alloc_5, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_12 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_12, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %40 = memref.load %alloc_5[%36#0, %36#1] : memref<?x10xf32, #gpu.address_space<global>>
        %41 = memref.load %alloc_5[%37#0, %37#1] : memref<?x10xf32, #gpu.address_space<global>>
        %42 = memref.load %alloc_5[%38#0, %38#1] : memref<?x10xf32, #gpu.address_space<global>>
        %43 = memref.load %alloc_5[%39#0, %39#1] : memref<?x10xf32, #gpu.address_space<global>>
        %44 = memref.load %17[%36#1] : memref<10xf32, #gpu.address_space<global>>
        %45 = memref.load %17[%37#1] : memref<10xf32, #gpu.address_space<global>>
        %46 = memref.load %17[%38#1] : memref<10xf32, #gpu.address_space<global>>
        %47 = memref.load %17[%39#1] : memref<10xf32, #gpu.address_space<global>>
        %48 = arith.addf %40, %44 : f32
        %49 = arith.addf %41, %45 : f32
        %50 = arith.addf %42, %46 : f32
        %51 = arith.addf %43, %47 : f32
        %52 = arith.maxf %48, %cst : f32
        %53 = arith.maxf %49, %cst : f32
        %54 = arith.maxf %50, %cst : f32
        %55 = arith.maxf %51, %cst : f32
        memref.store %52, %reinterpret_cast_11[%25] : memref<?xf32, #gpu.address_space<global>>
        memref.store %53, %reinterpret_cast_12[%29] : memref<?xf32, #gpu.address_space<global>>
        memref.store %54, %reinterpret_cast_13[%30] : memref<?xf32, #gpu.address_space<global>>
        memref.store %55, %reinterpret_cast_14[%31] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc_5[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %17[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.maxf %28, %cst : f32
        memref.store %29, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %17 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_10) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After ArithExpandOps (arith-expand) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %9 = "disc_ral.dispatch"(%arg0, %8, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %10 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %11 = llvm.getelementptr %10[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %12 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %13 = "disc_ral.dispatch"(%arg0, %12, %11, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %14 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %15 = llvm.getelementptr %14[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %17 = "disc_ral.dispatch"(%arg0, %16, %15, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %18, %reinterpret_cast, %9, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %9 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %19 = arith.muli %dim, %c10 : index
  %20 = arith.remui %19, %c4 : index
  %21 = arith.cmpi eq, %20, %c0 : index
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %13, 16 : memref<10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_12 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_12, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %40 = memref.load %alloc[%36#0, %36#1] : memref<?x10xf32, #gpu.address_space<global>>
        %41 = memref.load %alloc[%37#0, %37#1] : memref<?x10xf32, #gpu.address_space<global>>
        %42 = memref.load %alloc[%38#0, %38#1] : memref<?x10xf32, #gpu.address_space<global>>
        %43 = memref.load %alloc[%39#0, %39#1] : memref<?x10xf32, #gpu.address_space<global>>
        %44 = memref.load %13[%36#1] : memref<10xf32, #gpu.address_space<global>>
        %45 = memref.load %13[%37#1] : memref<10xf32, #gpu.address_space<global>>
        %46 = memref.load %13[%38#1] : memref<10xf32, #gpu.address_space<global>>
        %47 = memref.load %13[%39#1] : memref<10xf32, #gpu.address_space<global>>
        %48 = arith.addf %40, %44 : f32
        %49 = arith.addf %41, %45 : f32
        %50 = arith.addf %42, %46 : f32
        %51 = arith.addf %43, %47 : f32
        %52 = arith.cmpf ugt, %48, %cst : f32
        %53 = arith.select %52, %48, %cst : f32
        %54 = arith.cmpf uno, %cst, %cst : f32
        %55 = arith.select %54, %cst, %53 : f32
        %56 = arith.cmpf ugt, %49, %cst : f32
        %57 = arith.select %56, %49, %cst : f32
        %58 = arith.cmpf uno, %cst, %cst : f32
        %59 = arith.select %58, %cst, %57 : f32
        %60 = arith.cmpf ugt, %50, %cst : f32
        %61 = arith.select %60, %50, %cst : f32
        %62 = arith.cmpf uno, %cst, %cst : f32
        %63 = arith.select %62, %cst, %61 : f32
        %64 = arith.cmpf ugt, %51, %cst : f32
        %65 = arith.select %64, %51, %cst : f32
        %66 = arith.cmpf uno, %cst, %cst : f32
        %67 = arith.select %66, %cst, %65 : f32
        memref.store %55, %reinterpret_cast_11[%25] : memref<?xf32, #gpu.address_space<global>>
        memref.store %59, %reinterpret_cast_12[%29] : memref<?xf32, #gpu.address_space<global>>
        memref.store %63, %reinterpret_cast_13[%30] : memref<?xf32, #gpu.address_space<global>>
        memref.store %67, %reinterpret_cast_14[%31] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %13[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.cmpf ugt, %28, %cst : f32
        %30 = arith.select %29, %28, %cst : f32
        %31 = arith.cmpf uno, %cst, %cst : f32
        %32 = arith.select %31, %cst, %30 : f32
        memref.store %32, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_4 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_0 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %13 : memref<10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %22, %alloc_3, %5, %alloc_5, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %17, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %alloc_5, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_12 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_12, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %40 = memref.load %alloc_5[%36#0, %36#1] : memref<?x10xf32, #gpu.address_space<global>>
        %41 = memref.load %alloc_5[%37#0, %37#1] : memref<?x10xf32, #gpu.address_space<global>>
        %42 = memref.load %alloc_5[%38#0, %38#1] : memref<?x10xf32, #gpu.address_space<global>>
        %43 = memref.load %alloc_5[%39#0, %39#1] : memref<?x10xf32, #gpu.address_space<global>>
        %44 = memref.load %17[%36#1] : memref<10xf32, #gpu.address_space<global>>
        %45 = memref.load %17[%37#1] : memref<10xf32, #gpu.address_space<global>>
        %46 = memref.load %17[%38#1] : memref<10xf32, #gpu.address_space<global>>
        %47 = memref.load %17[%39#1] : memref<10xf32, #gpu.address_space<global>>
        %48 = arith.addf %40, %44 : f32
        %49 = arith.addf %41, %45 : f32
        %50 = arith.addf %42, %46 : f32
        %51 = arith.addf %43, %47 : f32
        %52 = arith.cmpf ugt, %48, %cst : f32
        %53 = arith.select %52, %48, %cst : f32
        %54 = arith.cmpf uno, %cst, %cst : f32
        %55 = arith.select %54, %cst, %53 : f32
        %56 = arith.cmpf ugt, %49, %cst : f32
        %57 = arith.select %56, %49, %cst : f32
        %58 = arith.cmpf uno, %cst, %cst : f32
        %59 = arith.select %58, %cst, %57 : f32
        %60 = arith.cmpf ugt, %50, %cst : f32
        %61 = arith.select %60, %50, %cst : f32
        %62 = arith.cmpf uno, %cst, %cst : f32
        %63 = arith.select %62, %cst, %61 : f32
        %64 = arith.cmpf ugt, %51, %cst : f32
        %65 = arith.select %64, %51, %cst : f32
        %66 = arith.cmpf uno, %cst, %cst : f32
        %67 = arith.select %66, %cst, %65 : f32
        memref.store %55, %reinterpret_cast_11[%25] : memref<?xf32, #gpu.address_space<global>>
        memref.store %59, %reinterpret_cast_12[%29] : memref<?xf32, #gpu.address_space<global>>
        memref.store %63, %reinterpret_cast_13[%30] : memref<?xf32, #gpu.address_space<global>>
        memref.store %67, %reinterpret_cast_14[%31] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc_5[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %17[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.cmpf ugt, %28, %cst : f32
        %30 = arith.select %29, %28, %cst : f32
        %31 = arith.cmpf uno, %cst, %cst : f32
        %32 = arith.select %31, %cst, %30 : f32
        memref.store %32, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %17 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_10) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %9 = "disc_ral.dispatch"(%arg0, %8, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %10 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %11 = llvm.getelementptr %10[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %12 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %13 = "disc_ral.dispatch"(%arg0, %12, %11, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %14 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %15 = llvm.getelementptr %14[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %17 = "disc_ral.dispatch"(%arg0, %16, %15, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %18, %reinterpret_cast, %9, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %9 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %19 = arith.muli %dim, %c10 : index
  %20 = arith.remui %19, %c4 : index
  %21 = arith.cmpi eq, %20, %c0 : index
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %13, 16 : memref<10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_12 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_12, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %40 = memref.load %alloc[%36#0, %36#1] : memref<?x10xf32, #gpu.address_space<global>>
        %41 = memref.load %alloc[%37#0, %37#1] : memref<?x10xf32, #gpu.address_space<global>>
        %42 = memref.load %alloc[%38#0, %38#1] : memref<?x10xf32, #gpu.address_space<global>>
        %43 = memref.load %alloc[%39#0, %39#1] : memref<?x10xf32, #gpu.address_space<global>>
        %44 = memref.load %13[%36#1] : memref<10xf32, #gpu.address_space<global>>
        %45 = memref.load %13[%37#1] : memref<10xf32, #gpu.address_space<global>>
        %46 = memref.load %13[%38#1] : memref<10xf32, #gpu.address_space<global>>
        %47 = memref.load %13[%39#1] : memref<10xf32, #gpu.address_space<global>>
        %48 = arith.addf %40, %44 : f32
        %49 = arith.addf %41, %45 : f32
        %50 = arith.addf %42, %46 : f32
        %51 = arith.addf %43, %47 : f32
        %52 = arith.cmpf ugt, %48, %cst : f32
        %53 = arith.select %52, %48, %cst : f32
        %54 = arith.cmpf ugt, %49, %cst : f32
        %55 = arith.select %54, %49, %cst : f32
        %56 = arith.cmpf ugt, %50, %cst : f32
        %57 = arith.select %56, %50, %cst : f32
        %58 = arith.cmpf ugt, %51, %cst : f32
        %59 = arith.select %58, %51, %cst : f32
        memref.store %53, %reinterpret_cast_11[%25] : memref<?xf32, #gpu.address_space<global>>
        memref.store %55, %reinterpret_cast_12[%29] : memref<?xf32, #gpu.address_space<global>>
        memref.store %57, %reinterpret_cast_13[%30] : memref<?xf32, #gpu.address_space<global>>
        memref.store %59, %reinterpret_cast_14[%31] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %13[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.cmpf ugt, %28, %cst : f32
        %30 = arith.select %29, %28, %cst : f32
        memref.store %30, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_4 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_0 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %13 : memref<10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %22, %alloc_3, %5, %alloc_5, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %17, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %alloc_5, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_12 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_12, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %40 = memref.load %alloc_5[%36#0, %36#1] : memref<?x10xf32, #gpu.address_space<global>>
        %41 = memref.load %alloc_5[%37#0, %37#1] : memref<?x10xf32, #gpu.address_space<global>>
        %42 = memref.load %alloc_5[%38#0, %38#1] : memref<?x10xf32, #gpu.address_space<global>>
        %43 = memref.load %alloc_5[%39#0, %39#1] : memref<?x10xf32, #gpu.address_space<global>>
        %44 = memref.load %17[%36#1] : memref<10xf32, #gpu.address_space<global>>
        %45 = memref.load %17[%37#1] : memref<10xf32, #gpu.address_space<global>>
        %46 = memref.load %17[%38#1] : memref<10xf32, #gpu.address_space<global>>
        %47 = memref.load %17[%39#1] : memref<10xf32, #gpu.address_space<global>>
        %48 = arith.addf %40, %44 : f32
        %49 = arith.addf %41, %45 : f32
        %50 = arith.addf %42, %46 : f32
        %51 = arith.addf %43, %47 : f32
        %52 = arith.cmpf ugt, %48, %cst : f32
        %53 = arith.select %52, %48, %cst : f32
        %54 = arith.cmpf ugt, %49, %cst : f32
        %55 = arith.select %54, %49, %cst : f32
        %56 = arith.cmpf ugt, %50, %cst : f32
        %57 = arith.select %56, %50, %cst : f32
        %58 = arith.cmpf ugt, %51, %cst : f32
        %59 = arith.select %58, %51, %cst : f32
        memref.store %53, %reinterpret_cast_11[%25] : memref<?xf32, #gpu.address_space<global>>
        memref.store %55, %reinterpret_cast_12[%29] : memref<?xf32, #gpu.address_space<global>>
        memref.store %57, %reinterpret_cast_13[%30] : memref<?xf32, #gpu.address_space<global>>
        memref.store %59, %reinterpret_cast_14[%31] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = memref.load %alloc_5[%25#0, %25#1] : memref<?x10xf32, #gpu.address_space<global>>
        %27 = memref.load %17[%25#1] : memref<10xf32, #gpu.address_space<global>>
        %28 = arith.addf %26, %27 : f32
        %29 = arith.cmpf ugt, %28, %cst : f32
        %30 = arith.select %29, %28, %cst : f32
        memref.store %30, %reinterpret_cast_11[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %17 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_10) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After DiscFlattenMemrefAccessPass (disc-flatten-memref-access) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %9 = "disc_ral.dispatch"(%arg0, %8, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %10 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %11 = llvm.getelementptr %10[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %12 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %13 = "disc_ral.dispatch"(%arg0, %12, %11, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %14 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %15 = llvm.getelementptr %14[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %17 = "disc_ral.dispatch"(%arg0, %16, %15, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %18, %reinterpret_cast, %9, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %9 : memref<10x10xf32, #gpu.address_space<global>>
  %alloca = memref.alloca() {alignment = 64 : i64} : memref<2xindex>
  memref.store %dim, %alloca[%c0] : memref<2xindex>
  memref.store %c10, %alloca[%c1] : memref<2xindex>
  %19 = arith.muli %dim, %c10 : index
  %20 = arith.remui %19, %c4 : index
  %21 = arith.cmpi eq, %20, %c0 : index
  %alloc_0 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_3 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_4 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %13, 16 : memref<10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_12 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_12, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %c0_15 = arith.constant 0 : index
        %dim_16 = memref.dim %alloc, %c0_15 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_17 = arith.constant 10 : index
        %40 = "disc_shape.linearize"(%36#0, %36#1, %dim_16, %c10_17) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_18 = arith.constant 1 : index
        %c0_19 = arith.constant 0 : index
        %dim_20 = memref.dim %alloc, %c0_19 : memref<?x10xf32, #gpu.address_space<global>>
        %41 = arith.muli %c1_18, %dim_20 : index
        %c1_21 = arith.constant 1 : index
        %dim_22 = memref.dim %alloc, %c1_21 : memref<?x10xf32, #gpu.address_space<global>>
        %42 = arith.muli %41, %dim_22 : index
        %c1_23 = arith.constant 1 : index
        %c0_24 = arith.constant 0 : index
        %reinterpret_cast_25 = memref.reinterpret_cast %alloc to offset: [%c0_24], sizes: [%42], strides: [%c1_23] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_25, 16 : memref<?xf32, #gpu.address_space<global>>
        %43 = memref.load %reinterpret_cast_25[%40] : memref<?xf32, #gpu.address_space<global>>
        %c0_26 = arith.constant 0 : index
        %dim_27 = memref.dim %alloc, %c0_26 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_28 = arith.constant 10 : index
        %44 = "disc_shape.linearize"(%37#0, %37#1, %dim_27, %c10_28) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_29 = arith.constant 1 : index
        %c0_30 = arith.constant 0 : index
        %dim_31 = memref.dim %alloc, %c0_30 : memref<?x10xf32, #gpu.address_space<global>>
        %45 = arith.muli %c1_29, %dim_31 : index
        %c1_32 = arith.constant 1 : index
        %dim_33 = memref.dim %alloc, %c1_32 : memref<?x10xf32, #gpu.address_space<global>>
        %46 = arith.muli %45, %dim_33 : index
        %c1_34 = arith.constant 1 : index
        %c0_35 = arith.constant 0 : index
        %reinterpret_cast_36 = memref.reinterpret_cast %alloc to offset: [%c0_35], sizes: [%46], strides: [%c1_34] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_36, 16 : memref<?xf32, #gpu.address_space<global>>
        %47 = memref.load %reinterpret_cast_36[%44] : memref<?xf32, #gpu.address_space<global>>
        %c0_37 = arith.constant 0 : index
        %dim_38 = memref.dim %alloc, %c0_37 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_39 = arith.constant 10 : index
        %48 = "disc_shape.linearize"(%38#0, %38#1, %dim_38, %c10_39) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_40 = arith.constant 1 : index
        %c0_41 = arith.constant 0 : index
        %dim_42 = memref.dim %alloc, %c0_41 : memref<?x10xf32, #gpu.address_space<global>>
        %49 = arith.muli %c1_40, %dim_42 : index
        %c1_43 = arith.constant 1 : index
        %dim_44 = memref.dim %alloc, %c1_43 : memref<?x10xf32, #gpu.address_space<global>>
        %50 = arith.muli %49, %dim_44 : index
        %c1_45 = arith.constant 1 : index
        %c0_46 = arith.constant 0 : index
        %reinterpret_cast_47 = memref.reinterpret_cast %alloc to offset: [%c0_46], sizes: [%50], strides: [%c1_45] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_47, 16 : memref<?xf32, #gpu.address_space<global>>
        %51 = memref.load %reinterpret_cast_47[%48] : memref<?xf32, #gpu.address_space<global>>
        %c0_48 = arith.constant 0 : index
        %dim_49 = memref.dim %alloc, %c0_48 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_50 = arith.constant 10 : index
        %52 = "disc_shape.linearize"(%39#0, %39#1, %dim_49, %c10_50) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_51 = arith.constant 1 : index
        %c0_52 = arith.constant 0 : index
        %dim_53 = memref.dim %alloc, %c0_52 : memref<?x10xf32, #gpu.address_space<global>>
        %53 = arith.muli %c1_51, %dim_53 : index
        %c1_54 = arith.constant 1 : index
        %dim_55 = memref.dim %alloc, %c1_54 : memref<?x10xf32, #gpu.address_space<global>>
        %54 = arith.muli %53, %dim_55 : index
        %c1_56 = arith.constant 1 : index
        %c0_57 = arith.constant 0 : index
        %reinterpret_cast_58 = memref.reinterpret_cast %alloc to offset: [%c0_57], sizes: [%54], strides: [%c1_56] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_58, 16 : memref<?xf32, #gpu.address_space<global>>
        %55 = memref.load %reinterpret_cast_58[%52] : memref<?xf32, #gpu.address_space<global>>
        %c10_59 = arith.constant 10 : index
        %56 = "disc_shape.linearize"(%36#1, %c10_59) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_60 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %57 = memref.load %reinterpret_cast_60[%56] : memref<10xf32, #gpu.address_space<global>>
        %c10_61 = arith.constant 10 : index
        %58 = "disc_shape.linearize"(%37#1, %c10_61) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_62 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %59 = memref.load %reinterpret_cast_62[%58] : memref<10xf32, #gpu.address_space<global>>
        %c10_63 = arith.constant 10 : index
        %60 = "disc_shape.linearize"(%38#1, %c10_63) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_64 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %61 = memref.load %reinterpret_cast_64[%60] : memref<10xf32, #gpu.address_space<global>>
        %c10_65 = arith.constant 10 : index
        %62 = "disc_shape.linearize"(%39#1, %c10_65) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_66 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %63 = memref.load %reinterpret_cast_66[%62] : memref<10xf32, #gpu.address_space<global>>
        %64 = arith.addf %43, %57 : f32
        %65 = arith.addf %47, %59 : f32
        %66 = arith.addf %51, %61 : f32
        %67 = arith.addf %55, %63 : f32
        %68 = arith.cmpf ugt, %64, %cst : f32
        %69 = arith.select %68, %64, %cst : f32
        %70 = arith.cmpf ugt, %65, %cst : f32
        %71 = arith.select %70, %65, %cst : f32
        %72 = arith.cmpf ugt, %66, %cst : f32
        %73 = arith.select %72, %66, %cst : f32
        %74 = arith.cmpf ugt, %67, %cst : f32
        %75 = arith.select %74, %67, %cst : f32
        %c0_67 = arith.constant 0 : index
        %dim_68 = memref.dim %reinterpret_cast_11, %c0_67 : memref<?xf32, #gpu.address_space<global>>
        %76 = "disc_shape.linearize"(%25, %dim_68) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_69 = arith.constant 1 : index
        %c0_70 = arith.constant 0 : index
        %dim_71 = memref.dim %reinterpret_cast_11, %c0_70 : memref<?xf32, #gpu.address_space<global>>
        %77 = arith.muli %c1_69, %dim_71 : index
        %c1_72 = arith.constant 1 : index
        %c0_73 = arith.constant 0 : index
        %reinterpret_cast_74 = memref.reinterpret_cast %reinterpret_cast_11 to offset: [%c0_73], sizes: [%77], strides: [%c1_72] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_74, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %69, %reinterpret_cast_74[%76] : memref<?xf32, #gpu.address_space<global>>
        %c0_75 = arith.constant 0 : index
        %dim_76 = memref.dim %reinterpret_cast_12, %c0_75 : memref<?xf32, #gpu.address_space<global>>
        %78 = "disc_shape.linearize"(%29, %dim_76) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_77 = arith.constant 1 : index
        %c0_78 = arith.constant 0 : index
        %dim_79 = memref.dim %reinterpret_cast_12, %c0_78 : memref<?xf32, #gpu.address_space<global>>
        %79 = arith.muli %c1_77, %dim_79 : index
        %c1_80 = arith.constant 1 : index
        %c0_81 = arith.constant 0 : index
        %reinterpret_cast_82 = memref.reinterpret_cast %reinterpret_cast_12 to offset: [%c0_81], sizes: [%79], strides: [%c1_80] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_82, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %71, %reinterpret_cast_82[%78] : memref<?xf32, #gpu.address_space<global>>
        %c0_83 = arith.constant 0 : index
        %dim_84 = memref.dim %reinterpret_cast_13, %c0_83 : memref<?xf32, #gpu.address_space<global>>
        %80 = "disc_shape.linearize"(%30, %dim_84) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_85 = arith.constant 1 : index
        %c0_86 = arith.constant 0 : index
        %dim_87 = memref.dim %reinterpret_cast_13, %c0_86 : memref<?xf32, #gpu.address_space<global>>
        %81 = arith.muli %c1_85, %dim_87 : index
        %c1_88 = arith.constant 1 : index
        %c0_89 = arith.constant 0 : index
        %reinterpret_cast_90 = memref.reinterpret_cast %reinterpret_cast_13 to offset: [%c0_89], sizes: [%81], strides: [%c1_88] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_90, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %73, %reinterpret_cast_90[%80] : memref<?xf32, #gpu.address_space<global>>
        %c0_91 = arith.constant 0 : index
        %dim_92 = memref.dim %reinterpret_cast_14, %c0_91 : memref<?xf32, #gpu.address_space<global>>
        %82 = "disc_shape.linearize"(%31, %dim_92) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_93 = arith.constant 1 : index
        %c0_94 = arith.constant 0 : index
        %dim_95 = memref.dim %reinterpret_cast_14, %c0_94 : memref<?xf32, #gpu.address_space<global>>
        %83 = arith.muli %c1_93, %dim_95 : index
        %c1_96 = arith.constant 1 : index
        %c0_97 = arith.constant 0 : index
        %reinterpret_cast_98 = memref.reinterpret_cast %reinterpret_cast_14 to offset: [%c0_97], sizes: [%83], strides: [%c1_96] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_98, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %75, %reinterpret_cast_98[%82] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_3 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %c0_12 = arith.constant 0 : index
        %dim_13 = memref.dim %alloc, %c0_12 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_14 = arith.constant 10 : index
        %26 = "disc_shape.linearize"(%25#0, %25#1, %dim_13, %c10_14) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_15 = arith.constant 1 : index
        %c0_16 = arith.constant 0 : index
        %dim_17 = memref.dim %alloc, %c0_16 : memref<?x10xf32, #gpu.address_space<global>>
        %27 = arith.muli %c1_15, %dim_17 : index
        %c1_18 = arith.constant 1 : index
        %dim_19 = memref.dim %alloc, %c1_18 : memref<?x10xf32, #gpu.address_space<global>>
        %28 = arith.muli %27, %dim_19 : index
        %c1_20 = arith.constant 1 : index
        %c0_21 = arith.constant 0 : index
        %reinterpret_cast_22 = memref.reinterpret_cast %alloc to offset: [%c0_21], sizes: [%28], strides: [%c1_20] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_22, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_22[%26] : memref<?xf32, #gpu.address_space<global>>
        %c10_23 = arith.constant 10 : index
        %30 = "disc_shape.linearize"(%25#1, %c10_23) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_24 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_24[%30] : memref<10xf32, #gpu.address_space<global>>
        %32 = arith.addf %29, %31 : f32
        %33 = arith.cmpf ugt, %32, %cst : f32
        %34 = arith.select %33, %32, %cst : f32
        %c0_25 = arith.constant 0 : index
        %dim_26 = memref.dim %reinterpret_cast_11, %c0_25 : memref<?xf32, #gpu.address_space<global>>
        %35 = "disc_shape.linearize"(%arg1, %dim_26) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_27 = arith.constant 1 : index
        %c0_28 = arith.constant 0 : index
        %dim_29 = memref.dim %reinterpret_cast_11, %c0_28 : memref<?xf32, #gpu.address_space<global>>
        %36 = arith.muli %c1_27, %dim_29 : index
        %c1_30 = arith.constant 1 : index
        %c0_31 = arith.constant 0 : index
        %reinterpret_cast_32 = memref.reinterpret_cast %reinterpret_cast_11 to offset: [%c0_31], sizes: [%36], strides: [%c1_30] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %34, %reinterpret_cast_32[%35] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_4 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_0 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %13 : memref<10xf32, #gpu.address_space<global>>
  %alloc_5 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %22, %alloc_3, %5, %alloc_5, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_3 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_6 = memref.alloc() : memref<f32, #gpu.address_space<global>>
  %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_9 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %alloc_10 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %17, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %alloc_5, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_12 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_14 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_12, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_13, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %c0_15 = arith.constant 0 : index
        %dim_16 = memref.dim %alloc_5, %c0_15 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_17 = arith.constant 10 : index
        %40 = "disc_shape.linearize"(%36#0, %36#1, %dim_16, %c10_17) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_18 = arith.constant 1 : index
        %c0_19 = arith.constant 0 : index
        %dim_20 = memref.dim %alloc_5, %c0_19 : memref<?x10xf32, #gpu.address_space<global>>
        %41 = arith.muli %c1_18, %dim_20 : index
        %c1_21 = arith.constant 1 : index
        %dim_22 = memref.dim %alloc_5, %c1_21 : memref<?x10xf32, #gpu.address_space<global>>
        %42 = arith.muli %41, %dim_22 : index
        %c1_23 = arith.constant 1 : index
        %c0_24 = arith.constant 0 : index
        %reinterpret_cast_25 = memref.reinterpret_cast %alloc_5 to offset: [%c0_24], sizes: [%42], strides: [%c1_23] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_25, 16 : memref<?xf32, #gpu.address_space<global>>
        %43 = memref.load %reinterpret_cast_25[%40] : memref<?xf32, #gpu.address_space<global>>
        %c0_26 = arith.constant 0 : index
        %dim_27 = memref.dim %alloc_5, %c0_26 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_28 = arith.constant 10 : index
        %44 = "disc_shape.linearize"(%37#0, %37#1, %dim_27, %c10_28) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_29 = arith.constant 1 : index
        %c0_30 = arith.constant 0 : index
        %dim_31 = memref.dim %alloc_5, %c0_30 : memref<?x10xf32, #gpu.address_space<global>>
        %45 = arith.muli %c1_29, %dim_31 : index
        %c1_32 = arith.constant 1 : index
        %dim_33 = memref.dim %alloc_5, %c1_32 : memref<?x10xf32, #gpu.address_space<global>>
        %46 = arith.muli %45, %dim_33 : index
        %c1_34 = arith.constant 1 : index
        %c0_35 = arith.constant 0 : index
        %reinterpret_cast_36 = memref.reinterpret_cast %alloc_5 to offset: [%c0_35], sizes: [%46], strides: [%c1_34] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_36, 16 : memref<?xf32, #gpu.address_space<global>>
        %47 = memref.load %reinterpret_cast_36[%44] : memref<?xf32, #gpu.address_space<global>>
        %c0_37 = arith.constant 0 : index
        %dim_38 = memref.dim %alloc_5, %c0_37 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_39 = arith.constant 10 : index
        %48 = "disc_shape.linearize"(%38#0, %38#1, %dim_38, %c10_39) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_40 = arith.constant 1 : index
        %c0_41 = arith.constant 0 : index
        %dim_42 = memref.dim %alloc_5, %c0_41 : memref<?x10xf32, #gpu.address_space<global>>
        %49 = arith.muli %c1_40, %dim_42 : index
        %c1_43 = arith.constant 1 : index
        %dim_44 = memref.dim %alloc_5, %c1_43 : memref<?x10xf32, #gpu.address_space<global>>
        %50 = arith.muli %49, %dim_44 : index
        %c1_45 = arith.constant 1 : index
        %c0_46 = arith.constant 0 : index
        %reinterpret_cast_47 = memref.reinterpret_cast %alloc_5 to offset: [%c0_46], sizes: [%50], strides: [%c1_45] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_47, 16 : memref<?xf32, #gpu.address_space<global>>
        %51 = memref.load %reinterpret_cast_47[%48] : memref<?xf32, #gpu.address_space<global>>
        %c0_48 = arith.constant 0 : index
        %dim_49 = memref.dim %alloc_5, %c0_48 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_50 = arith.constant 10 : index
        %52 = "disc_shape.linearize"(%39#0, %39#1, %dim_49, %c10_50) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_51 = arith.constant 1 : index
        %c0_52 = arith.constant 0 : index
        %dim_53 = memref.dim %alloc_5, %c0_52 : memref<?x10xf32, #gpu.address_space<global>>
        %53 = arith.muli %c1_51, %dim_53 : index
        %c1_54 = arith.constant 1 : index
        %dim_55 = memref.dim %alloc_5, %c1_54 : memref<?x10xf32, #gpu.address_space<global>>
        %54 = arith.muli %53, %dim_55 : index
        %c1_56 = arith.constant 1 : index
        %c0_57 = arith.constant 0 : index
        %reinterpret_cast_58 = memref.reinterpret_cast %alloc_5 to offset: [%c0_57], sizes: [%54], strides: [%c1_56] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_58, 16 : memref<?xf32, #gpu.address_space<global>>
        %55 = memref.load %reinterpret_cast_58[%52] : memref<?xf32, #gpu.address_space<global>>
        %c10_59 = arith.constant 10 : index
        %56 = "disc_shape.linearize"(%36#1, %c10_59) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_60 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %57 = memref.load %reinterpret_cast_60[%56] : memref<10xf32, #gpu.address_space<global>>
        %c10_61 = arith.constant 10 : index
        %58 = "disc_shape.linearize"(%37#1, %c10_61) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_62 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %59 = memref.load %reinterpret_cast_62[%58] : memref<10xf32, #gpu.address_space<global>>
        %c10_63 = arith.constant 10 : index
        %60 = "disc_shape.linearize"(%38#1, %c10_63) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_64 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %61 = memref.load %reinterpret_cast_64[%60] : memref<10xf32, #gpu.address_space<global>>
        %c10_65 = arith.constant 10 : index
        %62 = "disc_shape.linearize"(%39#1, %c10_65) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_66 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %63 = memref.load %reinterpret_cast_66[%62] : memref<10xf32, #gpu.address_space<global>>
        %64 = arith.addf %43, %57 : f32
        %65 = arith.addf %47, %59 : f32
        %66 = arith.addf %51, %61 : f32
        %67 = arith.addf %55, %63 : f32
        %68 = arith.cmpf ugt, %64, %cst : f32
        %69 = arith.select %68, %64, %cst : f32
        %70 = arith.cmpf ugt, %65, %cst : f32
        %71 = arith.select %70, %65, %cst : f32
        %72 = arith.cmpf ugt, %66, %cst : f32
        %73 = arith.select %72, %66, %cst : f32
        %74 = arith.cmpf ugt, %67, %cst : f32
        %75 = arith.select %74, %67, %cst : f32
        %c0_67 = arith.constant 0 : index
        %dim_68 = memref.dim %reinterpret_cast_11, %c0_67 : memref<?xf32, #gpu.address_space<global>>
        %76 = "disc_shape.linearize"(%25, %dim_68) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_69 = arith.constant 1 : index
        %c0_70 = arith.constant 0 : index
        %dim_71 = memref.dim %reinterpret_cast_11, %c0_70 : memref<?xf32, #gpu.address_space<global>>
        %77 = arith.muli %c1_69, %dim_71 : index
        %c1_72 = arith.constant 1 : index
        %c0_73 = arith.constant 0 : index
        %reinterpret_cast_74 = memref.reinterpret_cast %reinterpret_cast_11 to offset: [%c0_73], sizes: [%77], strides: [%c1_72] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_74, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %69, %reinterpret_cast_74[%76] : memref<?xf32, #gpu.address_space<global>>
        %c0_75 = arith.constant 0 : index
        %dim_76 = memref.dim %reinterpret_cast_12, %c0_75 : memref<?xf32, #gpu.address_space<global>>
        %78 = "disc_shape.linearize"(%29, %dim_76) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_77 = arith.constant 1 : index
        %c0_78 = arith.constant 0 : index
        %dim_79 = memref.dim %reinterpret_cast_12, %c0_78 : memref<?xf32, #gpu.address_space<global>>
        %79 = arith.muli %c1_77, %dim_79 : index
        %c1_80 = arith.constant 1 : index
        %c0_81 = arith.constant 0 : index
        %reinterpret_cast_82 = memref.reinterpret_cast %reinterpret_cast_12 to offset: [%c0_81], sizes: [%79], strides: [%c1_80] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_82, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %71, %reinterpret_cast_82[%78] : memref<?xf32, #gpu.address_space<global>>
        %c0_83 = arith.constant 0 : index
        %dim_84 = memref.dim %reinterpret_cast_13, %c0_83 : memref<?xf32, #gpu.address_space<global>>
        %80 = "disc_shape.linearize"(%30, %dim_84) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_85 = arith.constant 1 : index
        %c0_86 = arith.constant 0 : index
        %dim_87 = memref.dim %reinterpret_cast_13, %c0_86 : memref<?xf32, #gpu.address_space<global>>
        %81 = arith.muli %c1_85, %dim_87 : index
        %c1_88 = arith.constant 1 : index
        %c0_89 = arith.constant 0 : index
        %reinterpret_cast_90 = memref.reinterpret_cast %reinterpret_cast_13 to offset: [%c0_89], sizes: [%81], strides: [%c1_88] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_90, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %73, %reinterpret_cast_90[%80] : memref<?xf32, #gpu.address_space<global>>
        %c0_91 = arith.constant 0 : index
        %dim_92 = memref.dim %reinterpret_cast_14, %c0_91 : memref<?xf32, #gpu.address_space<global>>
        %82 = "disc_shape.linearize"(%31, %dim_92) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_93 = arith.constant 1 : index
        %c0_94 = arith.constant 0 : index
        %dim_95 = memref.dim %reinterpret_cast_14, %c0_94 : memref<?xf32, #gpu.address_space<global>>
        %83 = arith.muli %c1_93, %dim_95 : index
        %c1_96 = arith.constant 1 : index
        %c0_97 = arith.constant 0 : index
        %reinterpret_cast_98 = memref.reinterpret_cast %reinterpret_cast_14 to offset: [%c0_97], sizes: [%83], strides: [%c1_96] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_98, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %75, %reinterpret_cast_98[%82] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %c0_12 = arith.constant 0 : index
        %dim_13 = memref.dim %alloc_5, %c0_12 : memref<?x10xf32, #gpu.address_space<global>>
        %c10_14 = arith.constant 10 : index
        %26 = "disc_shape.linearize"(%25#0, %25#1, %dim_13, %c10_14) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %c1_15 = arith.constant 1 : index
        %c0_16 = arith.constant 0 : index
        %dim_17 = memref.dim %alloc_5, %c0_16 : memref<?x10xf32, #gpu.address_space<global>>
        %27 = arith.muli %c1_15, %dim_17 : index
        %c1_18 = arith.constant 1 : index
        %dim_19 = memref.dim %alloc_5, %c1_18 : memref<?x10xf32, #gpu.address_space<global>>
        %28 = arith.muli %27, %dim_19 : index
        %c1_20 = arith.constant 1 : index
        %c0_21 = arith.constant 0 : index
        %reinterpret_cast_22 = memref.reinterpret_cast %alloc_5 to offset: [%c0_21], sizes: [%28], strides: [%c1_20] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_22, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_22[%26] : memref<?xf32, #gpu.address_space<global>>
        %c10_23 = arith.constant 10 : index
        %30 = "disc_shape.linearize"(%25#1, %c10_23) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_24 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_24[%30] : memref<10xf32, #gpu.address_space<global>>
        %32 = arith.addf %29, %31 : f32
        %33 = arith.cmpf ugt, %32, %cst : f32
        %34 = arith.select %33, %32, %cst : f32
        %c0_25 = arith.constant 0 : index
        %dim_26 = memref.dim %reinterpret_cast_11, %c0_25 : memref<?xf32, #gpu.address_space<global>>
        %35 = "disc_shape.linearize"(%arg1, %dim_26) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_27 = arith.constant 1 : index
        %c0_28 = arith.constant 0 : index
        %dim_29 = memref.dim %reinterpret_cast_11, %c0_28 : memref<?xf32, #gpu.address_space<global>>
        %36 = arith.muli %c1_27, %dim_29 : index
        %c1_30 = arith.constant 1 : index
        %c0_31 = arith.constant 0 : index
        %reinterpret_cast_32 = memref.reinterpret_cast %reinterpret_cast_11 to offset: [%c0_31], sizes: [%36], strides: [%c1_30] : memref<?xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %34, %reinterpret_cast_32[%35] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_9 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %alloc_6 : memref<f32, #gpu.address_space<global>>
  memref.dealloc %alloc_5 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %17 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_10) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %9 = "disc_ral.dispatch"(%arg0, %8, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %10 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %11 = llvm.getelementptr %10[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %12 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %13 = "disc_ral.dispatch"(%arg0, %12, %11, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %14 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %15 = llvm.getelementptr %14[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %17 = "disc_ral.dispatch"(%arg0, %16, %15, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %18, %reinterpret_cast, %9, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %9 : memref<10x10xf32, #gpu.address_space<global>>
  %19 = arith.muli %dim, %c10 : index
  %20 = arith.remui %19, %c4 : index
  %21 = arith.cmpi eq, %20, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %13, 16 : memref<10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_4 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_5 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_6 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %40 = arith.muli %dim, %c10 : index
        %reinterpret_cast_7 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%40], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
        %41 = memref.load %reinterpret_cast_7[%25] : memref<?xf32, #gpu.address_space<global>>
        %42 = arith.muli %dim, %c10 : index
        %reinterpret_cast_8 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%42], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_8, 16 : memref<?xf32, #gpu.address_space<global>>
        %43 = memref.load %reinterpret_cast_8[%29] : memref<?xf32, #gpu.address_space<global>>
        %44 = arith.muli %dim, %c10 : index
        %reinterpret_cast_9 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%44], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_9, 16 : memref<?xf32, #gpu.address_space<global>>
        %45 = memref.load %reinterpret_cast_9[%30] : memref<?xf32, #gpu.address_space<global>>
        %46 = arith.muli %dim, %c10 : index
        %reinterpret_cast_10 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_10, 16 : memref<?xf32, #gpu.address_space<global>>
        %47 = memref.load %reinterpret_cast_10[%31] : memref<?xf32, #gpu.address_space<global>>
        %48 = "disc_shape.linearize"(%36#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_11 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %49 = memref.load %reinterpret_cast_11[%48] : memref<10xf32, #gpu.address_space<global>>
        %50 = "disc_shape.linearize"(%37#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_12 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %51 = memref.load %reinterpret_cast_12[%50] : memref<10xf32, #gpu.address_space<global>>
        %52 = "disc_shape.linearize"(%38#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_13 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %53 = memref.load %reinterpret_cast_13[%52] : memref<10xf32, #gpu.address_space<global>>
        %54 = "disc_shape.linearize"(%39#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_14 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %55 = memref.load %reinterpret_cast_14[%54] : memref<10xf32, #gpu.address_space<global>>
        %56 = arith.addf %41, %49 : f32
        %57 = arith.addf %43, %51 : f32
        %58 = arith.addf %45, %53 : f32
        %59 = arith.addf %47, %55 : f32
        %60 = arith.cmpf ugt, %56, %cst : f32
        %61 = arith.select %60, %56, %cst : f32
        %62 = arith.cmpf ugt, %57, %cst : f32
        %63 = arith.select %62, %57, %cst : f32
        %64 = arith.cmpf ugt, %58, %cst : f32
        %65 = arith.select %64, %58, %cst : f32
        %66 = arith.cmpf ugt, %59, %cst : f32
        %67 = arith.select %66, %59, %cst : f32
        %68 = "disc_shape.linearize"(%25, %32) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_15 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %61, %reinterpret_cast_15[%68] : memref<?xf32, #gpu.address_space<global>>
        %69 = "disc_shape.linearize"(%29, %33) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_16 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_16, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %63, %reinterpret_cast_16[%69] : memref<?xf32, #gpu.address_space<global>>
        %70 = "disc_shape.linearize"(%30, %34) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_17 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_17, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %65, %reinterpret_cast_17[%70] : memref<?xf32, #gpu.address_space<global>>
        %71 = "disc_shape.linearize"(%31, %35) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_18 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_18, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %67, %reinterpret_cast_18[%71] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = arith.muli %dim, %c10 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%26], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_3[%arg1] : memref<?xf32, #gpu.address_space<global>>
        %28 = "disc_shape.linearize"(%25#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_4 = memref.reinterpret_cast %13 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_4[%28] : memref<10xf32, #gpu.address_space<global>>
        %30 = arith.addf %27, %29 : f32
        %31 = arith.cmpf ugt, %30, %cst : f32
        %32 = arith.select %31, %30, %cst : f32
        %33 = "disc_shape.linearize"(%arg1, %24) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_5 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %32, %reinterpret_cast_5[%33] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %13 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  %22 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  "disc_ral.dispatch"(%arg0, %22, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %21 {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      %24 = arith.divui %23, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%24) step (%c1) {
        memref.assume_alignment %17, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %alloc_1, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %25 = arith.muli %arg1, %c4 : index
        %26 = arith.muli %arg1, %c4 : index
        %27 = arith.muli %arg1, %c4 : index
        %28 = arith.muli %arg1, %c4 : index
        %29 = arith.addi %26, %c1 : index
        %30 = arith.addi %27, %c2 : index
        %31 = arith.addi %28, %c3 : index
        %32 = arith.muli %dim, %c10 : index
        %33 = arith.muli %dim, %c10 : index
        %34 = arith.muli %dim, %c10 : index
        %35 = arith.muli %dim, %c10 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_4 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_5 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_6 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
        %36:2 = "disc_shape.delinearize"(%25, %dim, %c10) : (index, index, index) -> (index, index)
        %37:2 = "disc_shape.delinearize"(%29, %dim, %c10) : (index, index, index) -> (index, index)
        %38:2 = "disc_shape.delinearize"(%30, %dim, %c10) : (index, index, index) -> (index, index)
        %39:2 = "disc_shape.delinearize"(%31, %dim, %c10) : (index, index, index) -> (index, index)
        %40 = arith.muli %dim, %c10 : index
        %reinterpret_cast_7 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%40], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
        %41 = memref.load %reinterpret_cast_7[%25] : memref<?xf32, #gpu.address_space<global>>
        %42 = arith.muli %dim, %c10 : index
        %reinterpret_cast_8 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%42], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_8, 16 : memref<?xf32, #gpu.address_space<global>>
        %43 = memref.load %reinterpret_cast_8[%29] : memref<?xf32, #gpu.address_space<global>>
        %44 = arith.muli %dim, %c10 : index
        %reinterpret_cast_9 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%44], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_9, 16 : memref<?xf32, #gpu.address_space<global>>
        %45 = memref.load %reinterpret_cast_9[%30] : memref<?xf32, #gpu.address_space<global>>
        %46 = arith.muli %dim, %c10 : index
        %reinterpret_cast_10 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_10, 16 : memref<?xf32, #gpu.address_space<global>>
        %47 = memref.load %reinterpret_cast_10[%31] : memref<?xf32, #gpu.address_space<global>>
        %48 = "disc_shape.linearize"(%36#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_11 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %49 = memref.load %reinterpret_cast_11[%48] : memref<10xf32, #gpu.address_space<global>>
        %50 = "disc_shape.linearize"(%37#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_12 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %51 = memref.load %reinterpret_cast_12[%50] : memref<10xf32, #gpu.address_space<global>>
        %52 = "disc_shape.linearize"(%38#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_13 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %53 = memref.load %reinterpret_cast_13[%52] : memref<10xf32, #gpu.address_space<global>>
        %54 = "disc_shape.linearize"(%39#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_14 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %55 = memref.load %reinterpret_cast_14[%54] : memref<10xf32, #gpu.address_space<global>>
        %56 = arith.addf %41, %49 : f32
        %57 = arith.addf %43, %51 : f32
        %58 = arith.addf %45, %53 : f32
        %59 = arith.addf %47, %55 : f32
        %60 = arith.cmpf ugt, %56, %cst : f32
        %61 = arith.select %60, %56, %cst : f32
        %62 = arith.cmpf ugt, %57, %cst : f32
        %63 = arith.select %62, %57, %cst : f32
        %64 = arith.cmpf ugt, %58, %cst : f32
        %65 = arith.select %64, %58, %cst : f32
        %66 = arith.cmpf ugt, %59, %cst : f32
        %67 = arith.select %66, %59, %cst : f32
        %68 = "disc_shape.linearize"(%25, %32) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_15 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%32], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %61, %reinterpret_cast_15[%68] : memref<?xf32, #gpu.address_space<global>>
        %69 = "disc_shape.linearize"(%29, %33) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_16 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%33], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_16, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %63, %reinterpret_cast_16[%69] : memref<?xf32, #gpu.address_space<global>>
        %70 = "disc_shape.linearize"(%30, %34) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_17 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%34], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_17, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %65, %reinterpret_cast_17[%70] : memref<?xf32, #gpu.address_space<global>>
        %71 = "disc_shape.linearize"(%31, %35) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_18 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%35], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_18, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %67, %reinterpret_cast_18[%71] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %23 = arith.muli %dim, %c10 : index
      scf.parallel (%arg1) = (%c0) to (%23) step (%c1) {
        %24 = arith.muli %dim, %c10 : index
        %25:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %26 = arith.muli %dim, %c10 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%26], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_3[%arg1] : memref<?xf32, #gpu.address_space<global>>
        %28 = "disc_shape.linearize"(%25#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_4 = memref.reinterpret_cast %17 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_4[%28] : memref<10xf32, #gpu.address_space<global>>
        %30 = arith.addf %27, %29 : f32
        %31 = arith.cmpf ugt, %30, %cst : f32
        %32 = arith.select %31, %30, %cst : f32
        %33 = "disc_shape.linearize"(%arg1, %24) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_5 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %32, %reinterpret_cast_5[%33] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %17 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
  %15 = arith.muli %dim, %c10 : index
  %16 = arith.remui %15, %c4 : index
  %17 = arith.cmpi eq, %16, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%c1) {
        memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %11, 16 : memref<10xf32, #gpu.address_space<global>>
        %19 = arith.muli %arg1, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %23:2 = "disc_shape.delinearize"(%19, %dim, %c10) : (index, index, index) -> (index, index)
        %24:2 = "disc_shape.delinearize"(%20, %dim, %c10) : (index, index, index) -> (index, index)
        %25:2 = "disc_shape.delinearize"(%21, %dim, %c10) : (index, index, index) -> (index, index)
        %26:2 = "disc_shape.delinearize"(%22, %dim, %c10) : (index, index, index) -> (index, index)
        %reinterpret_cast_4 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_4[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %28 = memref.load %reinterpret_cast_4[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_4[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %30 = memref.load %reinterpret_cast_4[%22] : memref<?xf32, #gpu.address_space<global>>
        %31 = "disc_shape.linearize"(%23#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_5 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_5[%31] : memref<10xf32, #gpu.address_space<global>>
        %33 = "disc_shape.linearize"(%24#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %34 = memref.load %reinterpret_cast_5[%33] : memref<10xf32, #gpu.address_space<global>>
        %35 = "disc_shape.linearize"(%25#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %36 = memref.load %reinterpret_cast_5[%35] : memref<10xf32, #gpu.address_space<global>>
        %37 = "disc_shape.linearize"(%26#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %38 = memref.load %reinterpret_cast_5[%37] : memref<10xf32, #gpu.address_space<global>>
        %39 = arith.addf %27, %32 : f32
        %40 = arith.addf %28, %34 : f32
        %41 = arith.addf %29, %36 : f32
        %42 = arith.addf %30, %38 : f32
        %43 = arith.cmpf ugt, %39, %cst : f32
        %44 = arith.select %43, %39, %cst : f32
        %45 = arith.cmpf ugt, %40, %cst : f32
        %46 = arith.select %45, %40, %cst : f32
        %47 = arith.cmpf ugt, %41, %cst : f32
        %48 = arith.select %47, %41, %cst : f32
        %49 = arith.cmpf ugt, %42, %cst : f32
        %50 = arith.select %49, %42, %cst : f32
        %51 = "disc_shape.linearize"(%19, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast_3[%51] : memref<?xf32, #gpu.address_space<global>>
        %52 = "disc_shape.linearize"(%20, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast_3[%52] : memref<?xf32, #gpu.address_space<global>>
        %53 = "disc_shape.linearize"(%21, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %48, %reinterpret_cast_3[%53] : memref<?xf32, #gpu.address_space<global>>
        %54 = "disc_shape.linearize"(%22, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %50, %reinterpret_cast_3[%54] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%15) step (%c1) {
        %18:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %19 = memref.load %reinterpret_cast_3[%arg1] : memref<?xf32, #gpu.address_space<global>>
        %20 = "disc_shape.linearize"(%18#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_4 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_4[%20] : memref<10xf32, #gpu.address_space<global>>
        %22 = arith.addf %19, %21 : f32
        %23 = arith.cmpf ugt, %22, %cst : f32
        %24 = arith.select %23, %22, %cst : f32
        %25 = "disc_shape.linearize"(%arg1, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_5 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %24, %reinterpret_cast_5[%25] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%c1) {
        memref.assume_alignment %14, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %alloc_1, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %19 = arith.muli %arg1, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %23:2 = "disc_shape.delinearize"(%19, %dim, %c10) : (index, index, index) -> (index, index)
        %24:2 = "disc_shape.delinearize"(%20, %dim, %c10) : (index, index, index) -> (index, index)
        %25:2 = "disc_shape.delinearize"(%21, %dim, %c10) : (index, index, index) -> (index, index)
        %26:2 = "disc_shape.delinearize"(%22, %dim, %c10) : (index, index, index) -> (index, index)
        %reinterpret_cast_4 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_4[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %28 = memref.load %reinterpret_cast_4[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_4[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %30 = memref.load %reinterpret_cast_4[%22] : memref<?xf32, #gpu.address_space<global>>
        %31 = "disc_shape.linearize"(%23#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_5 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_5[%31] : memref<10xf32, #gpu.address_space<global>>
        %33 = "disc_shape.linearize"(%24#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %34 = memref.load %reinterpret_cast_5[%33] : memref<10xf32, #gpu.address_space<global>>
        %35 = "disc_shape.linearize"(%25#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %36 = memref.load %reinterpret_cast_5[%35] : memref<10xf32, #gpu.address_space<global>>
        %37 = "disc_shape.linearize"(%26#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %38 = memref.load %reinterpret_cast_5[%37] : memref<10xf32, #gpu.address_space<global>>
        %39 = arith.addf %27, %32 : f32
        %40 = arith.addf %28, %34 : f32
        %41 = arith.addf %29, %36 : f32
        %42 = arith.addf %30, %38 : f32
        %43 = arith.cmpf ugt, %39, %cst : f32
        %44 = arith.select %43, %39, %cst : f32
        %45 = arith.cmpf ugt, %40, %cst : f32
        %46 = arith.select %45, %40, %cst : f32
        %47 = arith.cmpf ugt, %41, %cst : f32
        %48 = arith.select %47, %41, %cst : f32
        %49 = arith.cmpf ugt, %42, %cst : f32
        %50 = arith.select %49, %42, %cst : f32
        %51 = "disc_shape.linearize"(%19, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast_3[%51] : memref<?xf32, #gpu.address_space<global>>
        %52 = "disc_shape.linearize"(%20, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast_3[%52] : memref<?xf32, #gpu.address_space<global>>
        %53 = "disc_shape.linearize"(%21, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %48, %reinterpret_cast_3[%53] : memref<?xf32, #gpu.address_space<global>>
        %54 = "disc_shape.linearize"(%22, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %50, %reinterpret_cast_3[%54] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%15) step (%c1) {
        %18:2 = "disc_shape.delinearize"(%arg1, %dim, %c10) : (index, index, index) -> (index, index)
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %19 = memref.load %reinterpret_cast_3[%arg1] : memref<?xf32, #gpu.address_space<global>>
        %20 = "disc_shape.linearize"(%18#1, %c10) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_4 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_4[%20] : memref<10xf32, #gpu.address_space<global>>
        %22 = arith.addf %19, %21 : f32
        %23 = arith.cmpf ugt, %22, %cst : f32
        %24 = arith.select %23, %22, %cst : f32
        %25 = "disc_shape.linearize"(%arg1, %15) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_5 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %24, %reinterpret_cast_5[%25] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After ConvertShapeToStandardPass (disc-convert-shape-to-std) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
  %15 = arith.muli %dim, %c10 : index
  %16 = arith.remui %15, %c4 : index
  %17 = arith.cmpi eq, %16, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%c1) {
        memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %11, 16 : memref<10xf32, #gpu.address_space<global>>
        %19 = arith.muli %arg1, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %23 = arith.remui %19, %c10 : index
        %24 = arith.divui %19, %c10 : index
        %25 = arith.remui %20, %c10 : index
        %26 = arith.divui %20, %c10 : index
        %27 = arith.remui %21, %c10 : index
        %28 = arith.divui %21, %c10 : index
        %29 = arith.remui %22, %c10 : index
        %30 = arith.divui %22, %c10 : index
        %reinterpret_cast_4 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_4[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_4[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %33 = memref.load %reinterpret_cast_4[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %34 = memref.load %reinterpret_cast_4[%22] : memref<?xf32, #gpu.address_space<global>>
        %c0_5 = arith.constant 0 : index
        %reinterpret_cast_6 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %35 = memref.load %reinterpret_cast_6[%23] : memref<10xf32, #gpu.address_space<global>>
        %c0_7 = arith.constant 0 : index
        %36 = memref.load %reinterpret_cast_6[%25] : memref<10xf32, #gpu.address_space<global>>
        %c0_8 = arith.constant 0 : index
        %37 = memref.load %reinterpret_cast_6[%27] : memref<10xf32, #gpu.address_space<global>>
        %c0_9 = arith.constant 0 : index
        %38 = memref.load %reinterpret_cast_6[%29] : memref<10xf32, #gpu.address_space<global>>
        %39 = arith.addf %31, %35 : f32
        %40 = arith.addf %32, %36 : f32
        %41 = arith.addf %33, %37 : f32
        %42 = arith.addf %34, %38 : f32
        %43 = arith.cmpf ugt, %39, %cst : f32
        %44 = arith.select %43, %39, %cst : f32
        %45 = arith.cmpf ugt, %40, %cst : f32
        %46 = arith.select %45, %40, %cst : f32
        %47 = arith.cmpf ugt, %41, %cst : f32
        %48 = arith.select %47, %41, %cst : f32
        %49 = arith.cmpf ugt, %42, %cst : f32
        %50 = arith.select %49, %42, %cst : f32
        %c0_10 = arith.constant 0 : index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast_3[%19] : memref<?xf32, #gpu.address_space<global>>
        %c0_11 = arith.constant 0 : index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast_3[%20] : memref<?xf32, #gpu.address_space<global>>
        %c0_12 = arith.constant 0 : index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %48, %reinterpret_cast_3[%21] : memref<?xf32, #gpu.address_space<global>>
        %c0_13 = arith.constant 0 : index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %50, %reinterpret_cast_3[%22] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%15) step (%c1) {
        %18 = arith.remui %arg1, %c10 : index
        %19 = arith.divui %arg1, %c10 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast_3[%arg1] : memref<?xf32, #gpu.address_space<global>>
        %c0_4 = arith.constant 0 : index
        %reinterpret_cast_5 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_5[%18] : memref<10xf32, #gpu.address_space<global>>
        %22 = arith.addf %20, %21 : f32
        %23 = arith.cmpf ugt, %22, %cst : f32
        %24 = arith.select %23, %22, %cst : f32
        %c0_6 = arith.constant 0 : index
        %reinterpret_cast_7 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %24, %reinterpret_cast_7[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%c1) {
        memref.assume_alignment %14, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %alloc_1, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %19 = arith.muli %arg1, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %23 = arith.remui %19, %c10 : index
        %24 = arith.divui %19, %c10 : index
        %25 = arith.remui %20, %c10 : index
        %26 = arith.divui %20, %c10 : index
        %27 = arith.remui %21, %c10 : index
        %28 = arith.divui %21, %c10 : index
        %29 = arith.remui %22, %c10 : index
        %30 = arith.divui %22, %c10 : index
        %reinterpret_cast_4 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_4[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_4[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %33 = memref.load %reinterpret_cast_4[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %34 = memref.load %reinterpret_cast_4[%22] : memref<?xf32, #gpu.address_space<global>>
        %c0_5 = arith.constant 0 : index
        %reinterpret_cast_6 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %35 = memref.load %reinterpret_cast_6[%23] : memref<10xf32, #gpu.address_space<global>>
        %c0_7 = arith.constant 0 : index
        %36 = memref.load %reinterpret_cast_6[%25] : memref<10xf32, #gpu.address_space<global>>
        %c0_8 = arith.constant 0 : index
        %37 = memref.load %reinterpret_cast_6[%27] : memref<10xf32, #gpu.address_space<global>>
        %c0_9 = arith.constant 0 : index
        %38 = memref.load %reinterpret_cast_6[%29] : memref<10xf32, #gpu.address_space<global>>
        %39 = arith.addf %31, %35 : f32
        %40 = arith.addf %32, %36 : f32
        %41 = arith.addf %33, %37 : f32
        %42 = arith.addf %34, %38 : f32
        %43 = arith.cmpf ugt, %39, %cst : f32
        %44 = arith.select %43, %39, %cst : f32
        %45 = arith.cmpf ugt, %40, %cst : f32
        %46 = arith.select %45, %40, %cst : f32
        %47 = arith.cmpf ugt, %41, %cst : f32
        %48 = arith.select %47, %41, %cst : f32
        %49 = arith.cmpf ugt, %42, %cst : f32
        %50 = arith.select %49, %42, %cst : f32
        %c0_10 = arith.constant 0 : index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast_3[%19] : memref<?xf32, #gpu.address_space<global>>
        %c0_11 = arith.constant 0 : index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast_3[%20] : memref<?xf32, #gpu.address_space<global>>
        %c0_12 = arith.constant 0 : index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %48, %reinterpret_cast_3[%21] : memref<?xf32, #gpu.address_space<global>>
        %c0_13 = arith.constant 0 : index
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %50, %reinterpret_cast_3[%22] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%15) step (%c1) {
        %18 = arith.remui %arg1, %c10 : index
        %19 = arith.divui %arg1, %c10 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast_3[%arg1] : memref<?xf32, #gpu.address_space<global>>
        %c0_4 = arith.constant 0 : index
        %reinterpret_cast_5 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_5[%18] : memref<10xf32, #gpu.address_space<global>>
        %22 = arith.addf %20, %21 : f32
        %23 = arith.cmpf ugt, %22, %cst : f32
        %24 = arith.select %23, %22, %cst : f32
        %c0_6 = arith.constant 0 : index
        %reinterpret_cast_7 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %24, %reinterpret_cast_7[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
  %15 = arith.muli %dim, %c10 : index
  %16 = arith.remui %15, %c4 : index
  %17 = arith.cmpi eq, %16, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%c1) {
        memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %11, 16 : memref<10xf32, #gpu.address_space<global>>
        %19 = arith.muli %arg1, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %23 = arith.remui %19, %c10 : index
        %24 = arith.remui %20, %c10 : index
        %25 = arith.remui %21, %c10 : index
        %26 = arith.remui %22, %c10 : index
        %reinterpret_cast_4 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_4[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %28 = memref.load %reinterpret_cast_4[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_4[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %30 = memref.load %reinterpret_cast_4[%22] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_5 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_5[%23] : memref<10xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_5[%24] : memref<10xf32, #gpu.address_space<global>>
        %33 = memref.load %reinterpret_cast_5[%25] : memref<10xf32, #gpu.address_space<global>>
        %34 = memref.load %reinterpret_cast_5[%26] : memref<10xf32, #gpu.address_space<global>>
        %35 = arith.addf %27, %31 : f32
        %36 = arith.addf %28, %32 : f32
        %37 = arith.addf %29, %33 : f32
        %38 = arith.addf %30, %34 : f32
        %39 = arith.cmpf ugt, %35, %cst : f32
        %40 = arith.select %39, %35, %cst : f32
        %41 = arith.cmpf ugt, %36, %cst : f32
        %42 = arith.select %41, %36, %cst : f32
        %43 = arith.cmpf ugt, %37, %cst : f32
        %44 = arith.select %43, %37, %cst : f32
        %45 = arith.cmpf ugt, %38, %cst : f32
        %46 = arith.select %45, %38, %cst : f32
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %40, %reinterpret_cast_3[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %42, %reinterpret_cast_3[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast_3[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast_3[%22] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%15) step (%c1) {
        %18 = arith.remui %arg1, %c10 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %19 = memref.load %reinterpret_cast_3[%arg1] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_4 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast_4[%18] : memref<10xf32, #gpu.address_space<global>>
        %21 = arith.addf %19, %20 : f32
        %22 = arith.cmpf ugt, %21, %cst : f32
        %23 = arith.select %22, %21, %cst : f32
        %reinterpret_cast_5 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %23, %reinterpret_cast_5[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%c1) {
        memref.assume_alignment %14, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %alloc_1, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %19 = arith.muli %arg1, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %23 = arith.remui %19, %c10 : index
        %24 = arith.remui %20, %c10 : index
        %25 = arith.remui %21, %c10 : index
        %26 = arith.remui %22, %c10 : index
        %reinterpret_cast_4 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_4[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %28 = memref.load %reinterpret_cast_4[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_4[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_4, 16 : memref<?xf32, #gpu.address_space<global>>
        %30 = memref.load %reinterpret_cast_4[%22] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_5 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_5[%23] : memref<10xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_5[%24] : memref<10xf32, #gpu.address_space<global>>
        %33 = memref.load %reinterpret_cast_5[%25] : memref<10xf32, #gpu.address_space<global>>
        %34 = memref.load %reinterpret_cast_5[%26] : memref<10xf32, #gpu.address_space<global>>
        %35 = arith.addf %27, %31 : f32
        %36 = arith.addf %28, %32 : f32
        %37 = arith.addf %29, %33 : f32
        %38 = arith.addf %30, %34 : f32
        %39 = arith.cmpf ugt, %35, %cst : f32
        %40 = arith.select %39, %35, %cst : f32
        %41 = arith.cmpf ugt, %36, %cst : f32
        %42 = arith.select %41, %36, %cst : f32
        %43 = arith.cmpf ugt, %37, %cst : f32
        %44 = arith.select %43, %37, %cst : f32
        %45 = arith.cmpf ugt, %38, %cst : f32
        %46 = arith.select %45, %38, %cst : f32
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %40, %reinterpret_cast_3[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %42, %reinterpret_cast_3[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast_3[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast_3[%22] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%15) step (%c1) {
        %18 = arith.remui %arg1, %c10 : index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_3, 16 : memref<?xf32, #gpu.address_space<global>>
        %19 = memref.load %reinterpret_cast_3[%arg1] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_4 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast_4[%18] : memref<10xf32, #gpu.address_space<global>>
        %21 = arith.addf %19, %20 : f32
        %22 = arith.cmpf ugt, %21, %cst : f32
        %23 = arith.select %22, %21, %cst : f32
        %reinterpret_cast_5 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %23, %reinterpret_cast_5[%arg1] : memref<?xf32, #gpu.address_space<global>>
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After SCFParallelLoopTiling (disc-parallel-loop-tiling) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
  %15 = arith.muli %dim, %c10 : index
  %16 = arith.remui %15, %c4 : index
  %17 = arith.cmpi eq, %16, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %19 = arith.muli %c1, %c256 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%19) {
        scf.parallel (%arg2) = (%c0_3) to (%19) step (%c1) {
          %20 = arith.addi %arg2, %arg1 : index
          %true_4 = arith.constant true
          %21 = arith.muli %arg2, %c1 : index
          %22 = arith.addi %21, %arg1 : index
          %23 = arith.cmpi ult, %22, %18 : index
          %24 = arith.andi %true_4, %23 : i1
          scf.if %24 {
            memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
            memref.assume_alignment %11, 16 : memref<10xf32, #gpu.address_space<global>>
            %25 = arith.muli %20, %c4 : index
            %26 = arith.addi %25, %c1 : index
            %27 = arith.addi %25, %c2 : index
            %28 = arith.addi %25, %c3 : index
            %reinterpret_cast_5 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            %29 = arith.remui %25, %c10 : index
            %30 = arith.remui %26, %c10 : index
            %31 = arith.remui %27, %c10 : index
            %32 = arith.remui %28, %c10 : index
            %reinterpret_cast_6 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %33 = memref.load %reinterpret_cast_6[%25] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %34 = memref.load %reinterpret_cast_6[%26] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %35 = memref.load %reinterpret_cast_6[%27] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %36 = memref.load %reinterpret_cast_6[%28] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_7 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %37 = memref.load %reinterpret_cast_7[%29] : memref<10xf32, #gpu.address_space<global>>
            %38 = memref.load %reinterpret_cast_7[%30] : memref<10xf32, #gpu.address_space<global>>
            %39 = memref.load %reinterpret_cast_7[%31] : memref<10xf32, #gpu.address_space<global>>
            %40 = memref.load %reinterpret_cast_7[%32] : memref<10xf32, #gpu.address_space<global>>
            %41 = arith.addf %33, %37 : f32
            %42 = arith.addf %34, %38 : f32
            %43 = arith.addf %35, %39 : f32
            %44 = arith.addf %36, %40 : f32
            %45 = arith.cmpf ugt, %41, %cst : f32
            %46 = arith.select %45, %41, %cst : f32
            %47 = arith.cmpf ugt, %42, %cst : f32
            %48 = arith.select %47, %42, %cst : f32
            %49 = arith.cmpf ugt, %43, %cst : f32
            %50 = arith.select %49, %43, %cst : f32
            %51 = arith.cmpf ugt, %44, %cst : f32
            %52 = arith.select %51, %44, %cst : f32
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %46, %reinterpret_cast_5[%25] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %48, %reinterpret_cast_5[%26] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %50, %reinterpret_cast_5[%27] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %52, %reinterpret_cast_5[%28] : memref<?xf32, #gpu.address_space<global>>
          }
          scf.yield
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %18 = arith.muli %c1, %c256 : index
      scf.parallel (%arg1) = (%c0) to (%15) step (%18) {
        scf.parallel (%arg2) = (%c0_3) to (%18) step (%c1) {
          %19 = arith.addi %arg2, %arg1 : index
          %true_4 = arith.constant true
          %20 = arith.muli %arg2, %c1 : index
          %21 = arith.addi %20, %arg1 : index
          %22 = arith.cmpi ult, %21, %15 : index
          %23 = arith.andi %true_4, %22 : i1
          scf.if %23 {
            %24 = arith.remui %19, %c10 : index
            %reinterpret_cast_5 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            %25 = memref.load %reinterpret_cast_5[%19] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_6 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %26 = memref.load %reinterpret_cast_6[%24] : memref<10xf32, #gpu.address_space<global>>
            %27 = arith.addf %25, %26 : f32
            %28 = arith.cmpf ugt, %27, %cst : f32
            %29 = arith.select %28, %27, %cst : f32
            %reinterpret_cast_7 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.store %29, %reinterpret_cast_7[%19] : memref<?xf32, #gpu.address_space<global>>
          }
          scf.yield
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %19 = arith.muli %c1, %c256 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%19) {
        scf.parallel (%arg2) = (%c0_3) to (%19) step (%c1) {
          %20 = arith.addi %arg2, %arg1 : index
          %true_4 = arith.constant true
          %21 = arith.muli %arg2, %c1 : index
          %22 = arith.addi %21, %arg1 : index
          %23 = arith.cmpi ult, %22, %18 : index
          %24 = arith.andi %true_4, %23 : i1
          scf.if %24 {
            memref.assume_alignment %14, 16 : memref<10xf32, #gpu.address_space<global>>
            memref.assume_alignment %alloc_1, 16 : memref<?x10xf32, #gpu.address_space<global>>
            %25 = arith.muli %20, %c4 : index
            %26 = arith.addi %25, %c1 : index
            %27 = arith.addi %25, %c2 : index
            %28 = arith.addi %25, %c3 : index
            %reinterpret_cast_5 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            %29 = arith.remui %25, %c10 : index
            %30 = arith.remui %26, %c10 : index
            %31 = arith.remui %27, %c10 : index
            %32 = arith.remui %28, %c10 : index
            %reinterpret_cast_6 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %33 = memref.load %reinterpret_cast_6[%25] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %34 = memref.load %reinterpret_cast_6[%26] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %35 = memref.load %reinterpret_cast_6[%27] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %36 = memref.load %reinterpret_cast_6[%28] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_7 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %37 = memref.load %reinterpret_cast_7[%29] : memref<10xf32, #gpu.address_space<global>>
            %38 = memref.load %reinterpret_cast_7[%30] : memref<10xf32, #gpu.address_space<global>>
            %39 = memref.load %reinterpret_cast_7[%31] : memref<10xf32, #gpu.address_space<global>>
            %40 = memref.load %reinterpret_cast_7[%32] : memref<10xf32, #gpu.address_space<global>>
            %41 = arith.addf %33, %37 : f32
            %42 = arith.addf %34, %38 : f32
            %43 = arith.addf %35, %39 : f32
            %44 = arith.addf %36, %40 : f32
            %45 = arith.cmpf ugt, %41, %cst : f32
            %46 = arith.select %45, %41, %cst : f32
            %47 = arith.cmpf ugt, %42, %cst : f32
            %48 = arith.select %47, %42, %cst : f32
            %49 = arith.cmpf ugt, %43, %cst : f32
            %50 = arith.select %49, %43, %cst : f32
            %51 = arith.cmpf ugt, %44, %cst : f32
            %52 = arith.select %51, %44, %cst : f32
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %46, %reinterpret_cast_5[%25] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %48, %reinterpret_cast_5[%26] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %50, %reinterpret_cast_5[%27] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %52, %reinterpret_cast_5[%28] : memref<?xf32, #gpu.address_space<global>>
          }
          scf.yield
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %18 = arith.muli %c1, %c256 : index
      scf.parallel (%arg1) = (%c0) to (%15) step (%18) {
        scf.parallel (%arg2) = (%c0_3) to (%18) step (%c1) {
          %19 = arith.addi %arg2, %arg1 : index
          %true_4 = arith.constant true
          %20 = arith.muli %arg2, %c1 : index
          %21 = arith.addi %20, %arg1 : index
          %22 = arith.cmpi ult, %21, %15 : index
          %23 = arith.andi %true_4, %22 : i1
          scf.if %23 {
            %24 = arith.remui %19, %c10 : index
            %reinterpret_cast_5 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            %25 = memref.load %reinterpret_cast_5[%19] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_6 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %26 = memref.load %reinterpret_cast_6[%24] : memref<10xf32, #gpu.address_space<global>>
            %27 = arith.addf %25, %26 : f32
            %28 = arith.cmpf ugt, %27, %cst : f32
            %29 = arith.select %28, %27, %cst : f32
            %reinterpret_cast_7 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.store %29, %reinterpret_cast_7[%19] : memref<?xf32, #gpu.address_space<global>>
          }
          scf.yield
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After GpuMapParallelLoopsPass (gpu-map-parallel-loops) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
  %15 = arith.muli %dim, %c10 : index
  %16 = arith.remui %15, %c4 : index
  %17 = arith.cmpi eq, %16, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %19 = arith.muli %c1, %c256 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%19) {
        scf.parallel (%arg2) = (%c0_3) to (%19) step (%c1) {
          %20 = arith.addi %arg2, %arg1 : index
          %true_4 = arith.constant true
          %21 = arith.muli %arg2, %c1 : index
          %22 = arith.addi %21, %arg1 : index
          %23 = arith.cmpi ult, %22, %18 : index
          %24 = arith.andi %true_4, %23 : i1
          scf.if %24 {
            memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
            memref.assume_alignment %11, 16 : memref<10xf32, #gpu.address_space<global>>
            %25 = arith.muli %20, %c4 : index
            %26 = arith.addi %25, %c1 : index
            %27 = arith.addi %25, %c2 : index
            %28 = arith.addi %25, %c3 : index
            %reinterpret_cast_5 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            %29 = arith.remui %25, %c10 : index
            %30 = arith.remui %26, %c10 : index
            %31 = arith.remui %27, %c10 : index
            %32 = arith.remui %28, %c10 : index
            %reinterpret_cast_6 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %33 = memref.load %reinterpret_cast_6[%25] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %34 = memref.load %reinterpret_cast_6[%26] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %35 = memref.load %reinterpret_cast_6[%27] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %36 = memref.load %reinterpret_cast_6[%28] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_7 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %37 = memref.load %reinterpret_cast_7[%29] : memref<10xf32, #gpu.address_space<global>>
            %38 = memref.load %reinterpret_cast_7[%30] : memref<10xf32, #gpu.address_space<global>>
            %39 = memref.load %reinterpret_cast_7[%31] : memref<10xf32, #gpu.address_space<global>>
            %40 = memref.load %reinterpret_cast_7[%32] : memref<10xf32, #gpu.address_space<global>>
            %41 = arith.addf %33, %37 : f32
            %42 = arith.addf %34, %38 : f32
            %43 = arith.addf %35, %39 : f32
            %44 = arith.addf %36, %40 : f32
            %45 = arith.cmpf ugt, %41, %cst : f32
            %46 = arith.select %45, %41, %cst : f32
            %47 = arith.cmpf ugt, %42, %cst : f32
            %48 = arith.select %47, %42, %cst : f32
            %49 = arith.cmpf ugt, %43, %cst : f32
            %50 = arith.select %49, %43, %cst : f32
            %51 = arith.cmpf ugt, %44, %cst : f32
            %52 = arith.select %51, %44, %cst : f32
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %46, %reinterpret_cast_5[%25] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %48, %reinterpret_cast_5[%26] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %50, %reinterpret_cast_5[%27] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %52, %reinterpret_cast_5[%28] : memref<?xf32, #gpu.address_space<global>>
          }
          scf.yield
        } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %18 = arith.muli %c1, %c256 : index
      scf.parallel (%arg1) = (%c0) to (%15) step (%18) {
        scf.parallel (%arg2) = (%c0_3) to (%18) step (%c1) {
          %19 = arith.addi %arg2, %arg1 : index
          %true_4 = arith.constant true
          %20 = arith.muli %arg2, %c1 : index
          %21 = arith.addi %20, %arg1 : index
          %22 = arith.cmpi ult, %21, %15 : index
          %23 = arith.andi %true_4, %22 : i1
          scf.if %23 {
            %24 = arith.remui %19, %c10 : index
            %reinterpret_cast_5 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            %25 = memref.load %reinterpret_cast_5[%19] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_6 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %26 = memref.load %reinterpret_cast_6[%24] : memref<10xf32, #gpu.address_space<global>>
            %27 = arith.addf %25, %26 : f32
            %28 = arith.cmpf ugt, %27, %cst : f32
            %29 = arith.select %28, %27, %cst : f32
            %reinterpret_cast_7 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.store %29, %reinterpret_cast_7[%19] : memref<?xf32, #gpu.address_space<global>>
          }
          scf.yield
        } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %19 = arith.muli %c1, %c256 : index
      scf.parallel (%arg1) = (%c0) to (%18) step (%19) {
        scf.parallel (%arg2) = (%c0_3) to (%19) step (%c1) {
          %20 = arith.addi %arg2, %arg1 : index
          %true_4 = arith.constant true
          %21 = arith.muli %arg2, %c1 : index
          %22 = arith.addi %21, %arg1 : index
          %23 = arith.cmpi ult, %22, %18 : index
          %24 = arith.andi %true_4, %23 : i1
          scf.if %24 {
            memref.assume_alignment %14, 16 : memref<10xf32, #gpu.address_space<global>>
            memref.assume_alignment %alloc_1, 16 : memref<?x10xf32, #gpu.address_space<global>>
            %25 = arith.muli %20, %c4 : index
            %26 = arith.addi %25, %c1 : index
            %27 = arith.addi %25, %c2 : index
            %28 = arith.addi %25, %c3 : index
            %reinterpret_cast_5 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            %29 = arith.remui %25, %c10 : index
            %30 = arith.remui %26, %c10 : index
            %31 = arith.remui %27, %c10 : index
            %32 = arith.remui %28, %c10 : index
            %reinterpret_cast_6 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %33 = memref.load %reinterpret_cast_6[%25] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %34 = memref.load %reinterpret_cast_6[%26] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %35 = memref.load %reinterpret_cast_6[%27] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
            %36 = memref.load %reinterpret_cast_6[%28] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_7 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %37 = memref.load %reinterpret_cast_7[%29] : memref<10xf32, #gpu.address_space<global>>
            %38 = memref.load %reinterpret_cast_7[%30] : memref<10xf32, #gpu.address_space<global>>
            %39 = memref.load %reinterpret_cast_7[%31] : memref<10xf32, #gpu.address_space<global>>
            %40 = memref.load %reinterpret_cast_7[%32] : memref<10xf32, #gpu.address_space<global>>
            %41 = arith.addf %33, %37 : f32
            %42 = arith.addf %34, %38 : f32
            %43 = arith.addf %35, %39 : f32
            %44 = arith.addf %36, %40 : f32
            %45 = arith.cmpf ugt, %41, %cst : f32
            %46 = arith.select %45, %41, %cst : f32
            %47 = arith.cmpf ugt, %42, %cst : f32
            %48 = arith.select %47, %42, %cst : f32
            %49 = arith.cmpf ugt, %43, %cst : f32
            %50 = arith.select %49, %43, %cst : f32
            %51 = arith.cmpf ugt, %44, %cst : f32
            %52 = arith.select %51, %44, %cst : f32
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %46, %reinterpret_cast_5[%25] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %48, %reinterpret_cast_5[%26] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %50, %reinterpret_cast_5[%27] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %52, %reinterpret_cast_5[%28] : memref<?xf32, #gpu.address_space<global>>
          }
          scf.yield
        } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %18 = arith.muli %c1, %c256 : index
      scf.parallel (%arg1) = (%c0) to (%15) step (%18) {
        scf.parallel (%arg2) = (%c0_3) to (%18) step (%c1) {
          %19 = arith.addi %arg2, %arg1 : index
          %true_4 = arith.constant true
          %20 = arith.muli %arg2, %c1 : index
          %21 = arith.addi %20, %arg1 : index
          %22 = arith.cmpi ult, %21, %15 : index
          %23 = arith.andi %true_4, %22 : i1
          scf.if %23 {
            %24 = arith.remui %19, %c10 : index
            %reinterpret_cast_5 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_5, 16 : memref<?xf32, #gpu.address_space<global>>
            %25 = memref.load %reinterpret_cast_5[%19] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_6 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %26 = memref.load %reinterpret_cast_6[%24] : memref<10xf32, #gpu.address_space<global>>
            %27 = arith.addf %25, %26 : f32
            %28 = arith.cmpf ugt, %27, %cst : f32
            %29 = arith.select %28, %27, %cst : f32
            %reinterpret_cast_7 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.store %29, %reinterpret_cast_7[%19] : memref<?xf32, #gpu.address_space<global>>
          }
          scf.yield
        } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After ConvertParallelLoopToGpu (convert-parallel-loops-to-gpu) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
  %15 = arith.muli %dim, %c10 : index
  %16 = arith.remui %15, %c4 : index
  %17 = arith.cmpi eq, %16, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %19 = arith.muli %c1, %c256 : index
      %c1_4 = arith.constant 1 : index
      %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0, %19]
      %21 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%19)[%c0_3, %c1]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %20, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %21, %arg11 = %c1_4, %arg12 = %c1_4) {
        %22 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%19, %c0]
        %23 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1, %c0_3]
        %24 = arith.addi %23, %22 : index
        %true_5 = arith.constant true
        %25 = arith.muli %23, %c1 : index
        %26 = arith.addi %25, %22 : index
        %27 = arith.cmpi ult, %26, %18 : index
        %28 = arith.andi %true_5, %27 : i1
        scf.if %28 {
          memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
          memref.assume_alignment %11, 16 : memref<10xf32, #gpu.address_space<global>>
          %29 = arith.muli %24, %c4 : index
          %30 = arith.addi %29, %c1 : index
          %31 = arith.addi %29, %c2 : index
          %32 = arith.addi %29, %c3 : index
          %reinterpret_cast_6 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          %33 = arith.remui %29, %c10 : index
          %34 = arith.remui %30, %c10 : index
          %35 = arith.remui %31, %c10 : index
          %36 = arith.remui %32, %c10 : index
          %reinterpret_cast_7 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
          %37 = memref.load %reinterpret_cast_7[%29] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
          %38 = memref.load %reinterpret_cast_7[%30] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
          %39 = memref.load %reinterpret_cast_7[%31] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
          %40 = memref.load %reinterpret_cast_7[%32] : memref<?xf32, #gpu.address_space<global>>
          %reinterpret_cast_8 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
          %41 = memref.load %reinterpret_cast_8[%33] : memref<10xf32, #gpu.address_space<global>>
          %42 = memref.load %reinterpret_cast_8[%34] : memref<10xf32, #gpu.address_space<global>>
          %43 = memref.load %reinterpret_cast_8[%35] : memref<10xf32, #gpu.address_space<global>>
          %44 = memref.load %reinterpret_cast_8[%36] : memref<10xf32, #gpu.address_space<global>>
          %45 = arith.addf %37, %41 : f32
          %46 = arith.addf %38, %42 : f32
          %47 = arith.addf %39, %43 : f32
          %48 = arith.addf %40, %44 : f32
          %49 = arith.cmpf ugt, %45, %cst : f32
          %50 = arith.select %49, %45, %cst : f32
          %51 = arith.cmpf ugt, %46, %cst : f32
          %52 = arith.select %51, %46, %cst : f32
          %53 = arith.cmpf ugt, %47, %cst : f32
          %54 = arith.select %53, %47, %cst : f32
          %55 = arith.cmpf ugt, %48, %cst : f32
          %56 = arith.select %55, %48, %cst : f32
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.store %50, %reinterpret_cast_6[%29] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.store %52, %reinterpret_cast_6[%30] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.store %54, %reinterpret_cast_6[%31] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.store %56, %reinterpret_cast_6[%32] : memref<?xf32, #gpu.address_space<global>>
        }
        gpu.terminator
      } {SCFToGPU_visited}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %18 = arith.muli %c1, %c256 : index
      %c1_4 = arith.constant 1 : index
      %19 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%15)[%c0, %18]
      %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0_3, %c1]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %19, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %20, %arg11 = %c1_4, %arg12 = %c1_4) {
        %21 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%18, %c0]
        %22 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1, %c0_3]
        %23 = arith.addi %22, %21 : index
        %true_5 = arith.constant true
        %24 = arith.muli %22, %c1 : index
        %25 = arith.addi %24, %21 : index
        %26 = arith.cmpi ult, %25, %15 : index
        %27 = arith.andi %true_5, %26 : i1
        scf.if %27 {
          %28 = arith.remui %23, %c10 : index
          %reinterpret_cast_6 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          %29 = memref.load %reinterpret_cast_6[%23] : memref<?xf32, #gpu.address_space<global>>
          %reinterpret_cast_7 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
          %30 = memref.load %reinterpret_cast_7[%28] : memref<10xf32, #gpu.address_space<global>>
          %31 = arith.addf %29, %30 : f32
          %32 = arith.cmpf ugt, %31, %cst : f32
          %33 = arith.select %32, %31, %cst : f32
          %reinterpret_cast_8 = memref.reinterpret_cast %alloc_0 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          memref.store %33, %reinterpret_cast_8[%23] : memref<?xf32, #gpu.address_space<global>>
        }
        gpu.terminator
      } {SCFToGPU_visited}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    "lmhlo.fusion"() ({
      %18 = arith.divui %15, %c4 : index
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %19 = arith.muli %c1, %c256 : index
      %c1_4 = arith.constant 1 : index
      %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0, %19]
      %21 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%19)[%c0_3, %c1]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %20, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %21, %arg11 = %c1_4, %arg12 = %c1_4) {
        %22 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%19, %c0]
        %23 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1, %c0_3]
        %24 = arith.addi %23, %22 : index
        %true_5 = arith.constant true
        %25 = arith.muli %23, %c1 : index
        %26 = arith.addi %25, %22 : index
        %27 = arith.cmpi ult, %26, %18 : index
        %28 = arith.andi %true_5, %27 : i1
        scf.if %28 {
          memref.assume_alignment %14, 16 : memref<10xf32, #gpu.address_space<global>>
          memref.assume_alignment %alloc_1, 16 : memref<?x10xf32, #gpu.address_space<global>>
          %29 = arith.muli %24, %c4 : index
          %30 = arith.addi %29, %c1 : index
          %31 = arith.addi %29, %c2 : index
          %32 = arith.addi %29, %c3 : index
          %reinterpret_cast_6 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          %33 = arith.remui %29, %c10 : index
          %34 = arith.remui %30, %c10 : index
          %35 = arith.remui %31, %c10 : index
          %36 = arith.remui %32, %c10 : index
          %reinterpret_cast_7 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
          %37 = memref.load %reinterpret_cast_7[%29] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
          %38 = memref.load %reinterpret_cast_7[%30] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
          %39 = memref.load %reinterpret_cast_7[%31] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_7, 16 : memref<?xf32, #gpu.address_space<global>>
          %40 = memref.load %reinterpret_cast_7[%32] : memref<?xf32, #gpu.address_space<global>>
          %reinterpret_cast_8 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
          %41 = memref.load %reinterpret_cast_8[%33] : memref<10xf32, #gpu.address_space<global>>
          %42 = memref.load %reinterpret_cast_8[%34] : memref<10xf32, #gpu.address_space<global>>
          %43 = memref.load %reinterpret_cast_8[%35] : memref<10xf32, #gpu.address_space<global>>
          %44 = memref.load %reinterpret_cast_8[%36] : memref<10xf32, #gpu.address_space<global>>
          %45 = arith.addf %37, %41 : f32
          %46 = arith.addf %38, %42 : f32
          %47 = arith.addf %39, %43 : f32
          %48 = arith.addf %40, %44 : f32
          %49 = arith.cmpf ugt, %45, %cst : f32
          %50 = arith.select %49, %45, %cst : f32
          %51 = arith.cmpf ugt, %46, %cst : f32
          %52 = arith.select %51, %46, %cst : f32
          %53 = arith.cmpf ugt, %47, %cst : f32
          %54 = arith.select %53, %47, %cst : f32
          %55 = arith.cmpf ugt, %48, %cst : f32
          %56 = arith.select %55, %48, %cst : f32
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.store %50, %reinterpret_cast_6[%29] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.store %52, %reinterpret_cast_6[%30] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.store %54, %reinterpret_cast_6[%31] : memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          memref.store %56, %reinterpret_cast_6[%32] : memref<?xf32, #gpu.address_space<global>>
        }
        gpu.terminator
      } {SCFToGPU_visited}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %c0_3 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %18 = arith.muli %c1, %c256 : index
      %c1_4 = arith.constant 1 : index
      %19 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%15)[%c0, %18]
      %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0_3, %c1]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %19, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %20, %arg11 = %c1_4, %arg12 = %c1_4) {
        %21 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%18, %c0]
        %22 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1, %c0_3]
        %23 = arith.addi %22, %21 : index
        %true_5 = arith.constant true
        %24 = arith.muli %22, %c1 : index
        %25 = arith.addi %24, %21 : index
        %26 = arith.cmpi ult, %25, %15 : index
        %27 = arith.andi %true_5, %26 : i1
        scf.if %27 {
          %28 = arith.remui %23, %c10 : index
          %reinterpret_cast_6 = memref.reinterpret_cast %alloc_1 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          memref.assume_alignment %reinterpret_cast_6, 16 : memref<?xf32, #gpu.address_space<global>>
          %29 = memref.load %reinterpret_cast_6[%23] : memref<?xf32, #gpu.address_space<global>>
          %reinterpret_cast_7 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
          %30 = memref.load %reinterpret_cast_7[%28] : memref<10xf32, #gpu.address_space<global>>
          %31 = arith.addf %29, %30 : f32
          %32 = arith.cmpf ugt, %31, %cst : f32
          %33 = arith.select %32, %31, %cst : f32
          %reinterpret_cast_8 = memref.reinterpret_cast %alloc_2 to offset: [%c0], sizes: [%15], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
          memref.store %33, %reinterpret_cast_8[%23] : memref<?xf32, #gpu.address_space<global>>
        }
        gpu.terminator
      } {SCFToGPU_visited}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
  }
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After GpuLaunchSinkIndexComputations (gpu-launch-sink-index-computations) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module {
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c3_i32 = arith.constant 3 : i32
    %c2_i32 = arith.constant 2 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %0 = llvm.mlir.constant(0 : i32) : i32
    %false = arith.constant false
    %true = arith.constant true
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
    %15 = arith.muli %dim, %c10 : index
    %16 = arith.remui %15, %c4 : index
    %17 = arith.cmpi eq, %16, %c0 : index
    %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %17 {
      "lmhlo.fusion"() ({
        %18 = arith.divui %15, %c4 : index
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %19 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %20 = affine.apply #map(%18)[%c0, %19]
        %21 = affine.apply #map(%19)[%c0_3, %c1]
        gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %20, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %21, %arg11 = %c1_4, %arg12 = %c1_4) {
          %c0_5 = arith.constant 0 : index
          %c1_6 = arith.constant 1 : index
          %c0_7 = arith.constant 0 : index
          %c4_8 = arith.constant 4 : index
          %c2_9 = arith.constant 2 : index
          %c3_10 = arith.constant 3 : index
          %c10_11 = arith.constant 10 : index
          %cst_12 = arith.constant 0.000000e+00 : f32
          %22 = affine.apply #map1(%arg1)[%19, %c0_5]
          %23 = affine.apply #map1(%arg4)[%c1_6, %c0_7]
          %24 = arith.addi %23, %22 : index
          %true_13 = arith.constant true
          %25 = arith.muli %23, %c1_6 : index
          %26 = arith.addi %25, %22 : index
          %27 = arith.cmpi ult, %26, %18 : index
          %28 = arith.andi %true_13, %27 : i1
          scf.if %28 {
            memref.assume_alignment %alloc, 16 : memref<?x10xf32, #gpu.address_space<global>>
            memref.assume_alignment %11, 16 : memref<10xf32, #gpu.address_space<global>>
            %29 = arith.muli %24, %c4_8 : index
            %30 = arith.addi %29, %c1_6 : index
            %31 = arith.addi %29, %c2_9 : index
            %32 = arith.addi %29, %c3_10 : index
            %reinterpret_cast_14 = memref.reinterpret_cast %alloc_0 to offset: [%c0_5], sizes: [%15], strides: [%c1_6] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            %33 = arith.remui %29, %c10_11 : index
            %34 = arith.remui %30, %c10_11 : index
            %35 = arith.remui %31, %c10_11 : index
            %36 = arith.remui %32, %c10_11 : index
            %reinterpret_cast_15 = memref.reinterpret_cast %alloc to offset: [%c0_5], sizes: [%15], strides: [%c1_6] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
            %37 = memref.load %reinterpret_cast_15[%29] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
            %38 = memref.load %reinterpret_cast_15[%30] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
            %39 = memref.load %reinterpret_cast_15[%31] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
            %40 = memref.load %reinterpret_cast_15[%32] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_16 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %41 = memref.load %reinterpret_cast_16[%33] : memref<10xf32, #gpu.address_space<global>>
            %42 = memref.load %reinterpret_cast_16[%34] : memref<10xf32, #gpu.address_space<global>>
            %43 = memref.load %reinterpret_cast_16[%35] : memref<10xf32, #gpu.address_space<global>>
            %44 = memref.load %reinterpret_cast_16[%36] : memref<10xf32, #gpu.address_space<global>>
            %45 = arith.addf %37, %41 : f32
            %46 = arith.addf %38, %42 : f32
            %47 = arith.addf %39, %43 : f32
            %48 = arith.addf %40, %44 : f32
            %49 = arith.cmpf ugt, %45, %cst_12 : f32
            %50 = arith.select %49, %45, %cst_12 : f32
            %51 = arith.cmpf ugt, %46, %cst_12 : f32
            %52 = arith.select %51, %46, %cst_12 : f32
            %53 = arith.cmpf ugt, %47, %cst_12 : f32
            %54 = arith.select %53, %47, %cst_12 : f32
            %55 = arith.cmpf ugt, %48, %cst_12 : f32
            %56 = arith.select %55, %48, %cst_12 : f32
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %50, %reinterpret_cast_14[%29] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %52, %reinterpret_cast_14[%30] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %54, %reinterpret_cast_14[%31] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %56, %reinterpret_cast_14[%32] : memref<?xf32, #gpu.address_space<global>>
          }
          gpu.terminator
        } {SCFToGPU_visited}
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %18 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%15)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_3, %c1]
        gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %19, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %20, %arg11 = %c1_4, %arg12 = %c1_4) {
          %c0_5 = arith.constant 0 : index
          %c1_6 = arith.constant 1 : index
          %c0_7 = arith.constant 0 : index
          %c10_8 = arith.constant 10 : index
          %cst_9 = arith.constant 0.000000e+00 : f32
          %21 = affine.apply #map1(%arg1)[%18, %c0_5]
          %22 = affine.apply #map1(%arg4)[%c1_6, %c0_7]
          %23 = arith.addi %22, %21 : index
          %true_10 = arith.constant true
          %24 = arith.muli %22, %c1_6 : index
          %25 = arith.addi %24, %21 : index
          %26 = arith.cmpi ult, %25, %15 : index
          %27 = arith.andi %true_10, %26 : i1
          scf.if %27 {
            %28 = arith.remui %23, %c10_8 : index
            %reinterpret_cast_11 = memref.reinterpret_cast %alloc to offset: [%c0_5], sizes: [%15], strides: [%c1_6] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
            %29 = memref.load %reinterpret_cast_11[%23] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_12 = memref.reinterpret_cast %11 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %30 = memref.load %reinterpret_cast_12[%28] : memref<10xf32, #gpu.address_space<global>>
            %31 = arith.addf %29, %30 : f32
            %32 = arith.cmpf ugt, %31, %cst_9 : f32
            %33 = arith.select %32, %31, %cst_9 : f32
            %reinterpret_cast_13 = memref.reinterpret_cast %alloc_0 to offset: [%c0_5], sizes: [%15], strides: [%c1_6] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.store %33, %reinterpret_cast_13[%23] : memref<?xf32, #gpu.address_space<global>>
          }
          gpu.terminator
        } {SCFToGPU_visited}
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
    %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %17 {
      "lmhlo.fusion"() ({
        %18 = arith.divui %15, %c4 : index
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %19 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %20 = affine.apply #map(%18)[%c0, %19]
        %21 = affine.apply #map(%19)[%c0_3, %c1]
        gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %20, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %21, %arg11 = %c1_4, %arg12 = %c1_4) {
          %c0_5 = arith.constant 0 : index
          %c1_6 = arith.constant 1 : index
          %c0_7 = arith.constant 0 : index
          %c4_8 = arith.constant 4 : index
          %c2_9 = arith.constant 2 : index
          %c3_10 = arith.constant 3 : index
          %c10_11 = arith.constant 10 : index
          %cst_12 = arith.constant 0.000000e+00 : f32
          %22 = affine.apply #map1(%arg1)[%19, %c0_5]
          %23 = affine.apply #map1(%arg4)[%c1_6, %c0_7]
          %24 = arith.addi %23, %22 : index
          %true_13 = arith.constant true
          %25 = arith.muli %23, %c1_6 : index
          %26 = arith.addi %25, %22 : index
          %27 = arith.cmpi ult, %26, %18 : index
          %28 = arith.andi %true_13, %27 : i1
          scf.if %28 {
            memref.assume_alignment %14, 16 : memref<10xf32, #gpu.address_space<global>>
            memref.assume_alignment %alloc_1, 16 : memref<?x10xf32, #gpu.address_space<global>>
            %29 = arith.muli %24, %c4_8 : index
            %30 = arith.addi %29, %c1_6 : index
            %31 = arith.addi %29, %c2_9 : index
            %32 = arith.addi %29, %c3_10 : index
            %reinterpret_cast_14 = memref.reinterpret_cast %alloc_2 to offset: [%c0_5], sizes: [%15], strides: [%c1_6] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            %33 = arith.remui %29, %c10_11 : index
            %34 = arith.remui %30, %c10_11 : index
            %35 = arith.remui %31, %c10_11 : index
            %36 = arith.remui %32, %c10_11 : index
            %reinterpret_cast_15 = memref.reinterpret_cast %alloc_1 to offset: [%c0_5], sizes: [%15], strides: [%c1_6] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
            %37 = memref.load %reinterpret_cast_15[%29] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
            %38 = memref.load %reinterpret_cast_15[%30] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
            %39 = memref.load %reinterpret_cast_15[%31] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_15, 16 : memref<?xf32, #gpu.address_space<global>>
            %40 = memref.load %reinterpret_cast_15[%32] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_16 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %41 = memref.load %reinterpret_cast_16[%33] : memref<10xf32, #gpu.address_space<global>>
            %42 = memref.load %reinterpret_cast_16[%34] : memref<10xf32, #gpu.address_space<global>>
            %43 = memref.load %reinterpret_cast_16[%35] : memref<10xf32, #gpu.address_space<global>>
            %44 = memref.load %reinterpret_cast_16[%36] : memref<10xf32, #gpu.address_space<global>>
            %45 = arith.addf %37, %41 : f32
            %46 = arith.addf %38, %42 : f32
            %47 = arith.addf %39, %43 : f32
            %48 = arith.addf %40, %44 : f32
            %49 = arith.cmpf ugt, %45, %cst_12 : f32
            %50 = arith.select %49, %45, %cst_12 : f32
            %51 = arith.cmpf ugt, %46, %cst_12 : f32
            %52 = arith.select %51, %46, %cst_12 : f32
            %53 = arith.cmpf ugt, %47, %cst_12 : f32
            %54 = arith.select %53, %47, %cst_12 : f32
            %55 = arith.cmpf ugt, %48, %cst_12 : f32
            %56 = arith.select %55, %48, %cst_12 : f32
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %50, %reinterpret_cast_14[%29] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %52, %reinterpret_cast_14[%30] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %54, %reinterpret_cast_14[%31] : memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_14, 16 : memref<?xf32, #gpu.address_space<global>>
            memref.store %56, %reinterpret_cast_14[%32] : memref<?xf32, #gpu.address_space<global>>
          }
          gpu.terminator
        } {SCFToGPU_visited}
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %18 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%15)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_3, %c1]
        gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %19, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %20, %arg11 = %c1_4, %arg12 = %c1_4) {
          %c0_5 = arith.constant 0 : index
          %c1_6 = arith.constant 1 : index
          %c0_7 = arith.constant 0 : index
          %c10_8 = arith.constant 10 : index
          %cst_9 = arith.constant 0.000000e+00 : f32
          %21 = affine.apply #map1(%arg1)[%18, %c0_5]
          %22 = affine.apply #map1(%arg4)[%c1_6, %c0_7]
          %23 = arith.addi %22, %21 : index
          %true_10 = arith.constant true
          %24 = arith.muli %22, %c1_6 : index
          %25 = arith.addi %24, %21 : index
          %26 = arith.cmpi ult, %25, %15 : index
          %27 = arith.andi %true_10, %26 : i1
          scf.if %27 {
            %28 = arith.remui %23, %c10_8 : index
            %reinterpret_cast_11 = memref.reinterpret_cast %alloc_1 to offset: [%c0_5], sizes: [%15], strides: [%c1_6] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.assume_alignment %reinterpret_cast_11, 16 : memref<?xf32, #gpu.address_space<global>>
            %29 = memref.load %reinterpret_cast_11[%23] : memref<?xf32, #gpu.address_space<global>>
            %reinterpret_cast_12 = memref.reinterpret_cast %14 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
            %30 = memref.load %reinterpret_cast_12[%28] : memref<10xf32, #gpu.address_space<global>>
            %31 = arith.addf %29, %30 : f32
            %32 = arith.cmpf ugt, %31, %cst_9 : f32
            %33 = arith.select %32, %31, %cst_9 : f32
            %reinterpret_cast_13 = memref.reinterpret_cast %alloc_2 to offset: [%c0_5], sizes: [%15], strides: [%c1_6] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
            memref.store %33, %reinterpret_cast_13[%23] : memref<?xf32, #gpu.address_space<global>>
          }
          gpu.terminator
        } {SCFToGPU_visited}
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After GpuKernelOutlining (gpu-kernel-outlining) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c3_i32 = arith.constant 3 : i32
    %c2_i32 = arith.constant 2 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %0 = llvm.mlir.constant(0 : i32) : i32
    %false = arith.constant false
    %true = arith.constant true
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
    %15 = arith.muli %dim, %c10 : index
    %16 = arith.remui %15, %c4 : index
    %17 = arith.cmpi eq, %16, %c0 : index
    %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %17 {
      "lmhlo.fusion"() ({
        %18 = arith.divui %15, %c4 : index
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %19 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %20 = affine.apply #map(%18)[%c0, %19]
        %21 = affine.apply #map(%19)[%c0_3, %c1]
        gpu.launch_func  @main_kernel::@main_kernel blocks in (%20, %c1_4, %c1_4) threads in (%21, %c1_4, %c1_4) args(%19 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %18 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%15)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_3, %c1]
        gpu.launch_func  @main_kernel_0::@main_kernel blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
    %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %17 {
      "lmhlo.fusion"() ({
        %18 = arith.divui %15, %c4 : index
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %19 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %20 = affine.apply #map(%18)[%c0, %19]
        %21 = affine.apply #map(%19)[%c0_3, %c1]
        gpu.launch_func  @main_kernel_1::@main_kernel blocks in (%20, %c1_4, %c1_4) threads in (%21, %c1_4, %c1_4) args(%19 : index, %18 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %18 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%15)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_3, %c1]
        gpu.launch_func  @main_kernel_2::@main_kernel blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %15 : index, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kernel(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c4 = arith.constant 4 : index
      %c2 = arith.constant 2 : index
      %c3 = arith.constant 3 : index
      %c10 = arith.constant 10 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        memref.assume_alignment %arg2, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %arg3, 16 : memref<10xf32, #gpu.address_space<global>>
        %19 = arith.muli %14, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %23 = arith.remui %19, %c10 : index
        %24 = arith.remui %20, %c10 : index
        %25 = arith.remui %21, %c10 : index
        %26 = arith.remui %22, %c10 : index
        %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_1[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %28 = memref.load %reinterpret_cast_1[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_1[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %30 = memref.load %reinterpret_cast_1[%22] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_2 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_2[%23] : memref<10xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_2[%24] : memref<10xf32, #gpu.address_space<global>>
        %33 = memref.load %reinterpret_cast_2[%25] : memref<10xf32, #gpu.address_space<global>>
        %34 = memref.load %reinterpret_cast_2[%26] : memref<10xf32, #gpu.address_space<global>>
        %35 = arith.addf %27, %31 : f32
        %36 = arith.addf %28, %32 : f32
        %37 = arith.addf %29, %33 : f32
        %38 = arith.addf %30, %34 : f32
        %39 = arith.cmpf ugt, %35, %cst : f32
        %40 = arith.select %39, %35, %cst : f32
        %41 = arith.cmpf ugt, %36, %cst : f32
        %42 = arith.select %41, %36, %cst : f32
        %43 = arith.cmpf ugt, %37, %cst : f32
        %44 = arith.select %43, %37, %cst : f32
        %45 = arith.cmpf ugt, %38, %cst : f32
        %46 = arith.select %45, %38, %cst : f32
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %40, %reinterpret_cast[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %42, %reinterpret_cast[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast[%22] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kernel(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c10 = arith.constant 10 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remui %14, %c10 : index
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast[%14] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_1[%19] : memref<10xf32, #gpu.address_space<global>>
        %22 = arith.addf %20, %21 : f32
        %23 = arith.cmpf ugt, %22, %cst : f32
        %24 = arith.select %23, %22, %cst : f32
        %reinterpret_cast_2 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %24, %reinterpret_cast_2[%14] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_1 {
    gpu.func @main_kernel(%arg0: index, %arg1: index, %arg2: memref<10xf32, #gpu.address_space<global>>, %arg3: memref<?x10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c4 = arith.constant 4 : index
      %c2 = arith.constant 2 : index
      %c3 = arith.constant 3 : index
      %c10 = arith.constant 10 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        memref.assume_alignment %arg2, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %arg3, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %19 = arith.muli %14, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %23 = arith.remui %19, %c10 : index
        %24 = arith.remui %20, %c10 : index
        %25 = arith.remui %21, %c10 : index
        %26 = arith.remui %22, %c10 : index
        %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_1[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %28 = memref.load %reinterpret_cast_1[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_1[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %30 = memref.load %reinterpret_cast_1[%22] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_2 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_2[%23] : memref<10xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_2[%24] : memref<10xf32, #gpu.address_space<global>>
        %33 = memref.load %reinterpret_cast_2[%25] : memref<10xf32, #gpu.address_space<global>>
        %34 = memref.load %reinterpret_cast_2[%26] : memref<10xf32, #gpu.address_space<global>>
        %35 = arith.addf %27, %31 : f32
        %36 = arith.addf %28, %32 : f32
        %37 = arith.addf %29, %33 : f32
        %38 = arith.addf %30, %34 : f32
        %39 = arith.cmpf ugt, %35, %cst : f32
        %40 = arith.select %39, %35, %cst : f32
        %41 = arith.cmpf ugt, %36, %cst : f32
        %42 = arith.select %41, %36, %cst : f32
        %43 = arith.cmpf ugt, %37, %cst : f32
        %44 = arith.select %43, %37, %cst : f32
        %45 = arith.cmpf ugt, %38, %cst : f32
        %46 = arith.select %45, %38, %cst : f32
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %40, %reinterpret_cast[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %42, %reinterpret_cast[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast[%22] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_2 {
    gpu.func @main_kernel(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c10 = arith.constant 10 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remui %14, %c10 : index
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast[%14] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_1[%19] : memref<10xf32, #gpu.address_space<global>>
        %22 = arith.addf %20, %21 : f32
        %23 = arith.cmpf ugt, %22, %cst : f32
        %24 = arith.select %23, %22, %cst : f32
        %reinterpret_cast_2 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %24, %reinterpret_cast_2[%14] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After AssignKernelNamePass (disc-assign-kernel-name) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c3_i32 = arith.constant 3 : i32
    %c2_i32 = arith.constant 2 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %0 = llvm.mlir.constant(0 : i32) : i32
    %false = arith.constant false
    %true = arith.constant true
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
    %15 = arith.muli %dim, %c10 : index
    %16 = arith.remui %15, %c4 : index
    %17 = arith.cmpi eq, %16, %c0 : index
    %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %17 {
      "lmhlo.fusion"() ({
        %18 = arith.divui %15, %c4 : index
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %19 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %20 = affine.apply #map(%18)[%c0, %19]
        %21 = affine.apply #map(%19)[%c0_3, %c1]
        gpu.launch_func  @main_kernel::@main_kLoop_maximum__5_1_0___Vec4 blocks in (%20, %c1_4, %c1_4) threads in (%21, %c1_4, %c1_4) args(%19 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %18 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%15)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_3, %c1]
        gpu.launch_func  @main_kernel_0::@main_kLoop_maximum__5_1_0 blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_0", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
    %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %17 {
      "lmhlo.fusion"() ({
        %18 = arith.divui %15, %c4 : index
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %19 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %20 = affine.apply #map(%18)[%c0, %19]
        %21 = affine.apply #map(%19)[%c0_3, %c1]
        gpu.launch_func  @main_kernel_1::@main_kLoop_maximum__5_1_1___Vec4 blocks in (%20, %c1_4, %c1_4) threads in (%21, %c1_4, %c1_4) args(%19 : index, %18 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion.tag = "Vec4", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 4 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        %c0_3 = arith.constant 0 : index
        %c256 = arith.constant 256 : index
        %18 = arith.muli %c1, %c256 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%15)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_3, %c1]
        gpu.launch_func  @main_kernel_2::@main_kLoop_maximum__5_1_1 blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %15 : index, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kLoop_maximum__5_1_1", disc.fusion_type = "kLoop", disc_vectorize_or_tile_hint = 1 : i32} : () -> ()
    }
    memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c4 = arith.constant 4 : index
      %c2 = arith.constant 2 : index
      %c3 = arith.constant 3 : index
      %c10 = arith.constant 10 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        memref.assume_alignment %arg2, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %arg3, 16 : memref<10xf32, #gpu.address_space<global>>
        %19 = arith.muli %14, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %23 = arith.remui %19, %c10 : index
        %24 = arith.remui %20, %c10 : index
        %25 = arith.remui %21, %c10 : index
        %26 = arith.remui %22, %c10 : index
        %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_1[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %28 = memref.load %reinterpret_cast_1[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_1[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %30 = memref.load %reinterpret_cast_1[%22] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_2 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_2[%23] : memref<10xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_2[%24] : memref<10xf32, #gpu.address_space<global>>
        %33 = memref.load %reinterpret_cast_2[%25] : memref<10xf32, #gpu.address_space<global>>
        %34 = memref.load %reinterpret_cast_2[%26] : memref<10xf32, #gpu.address_space<global>>
        %35 = arith.addf %27, %31 : f32
        %36 = arith.addf %28, %32 : f32
        %37 = arith.addf %29, %33 : f32
        %38 = arith.addf %30, %34 : f32
        %39 = arith.cmpf ugt, %35, %cst : f32
        %40 = arith.select %39, %35, %cst : f32
        %41 = arith.cmpf ugt, %36, %cst : f32
        %42 = arith.select %41, %36, %cst : f32
        %43 = arith.cmpf ugt, %37, %cst : f32
        %44 = arith.select %43, %37, %cst : f32
        %45 = arith.cmpf ugt, %38, %cst : f32
        %46 = arith.select %45, %38, %cst : f32
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %40, %reinterpret_cast[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %42, %reinterpret_cast[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast[%22] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kLoop_maximum__5_1_0(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c10 = arith.constant 10 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remui %14, %c10 : index
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast[%14] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_1[%19] : memref<10xf32, #gpu.address_space<global>>
        %22 = arith.addf %20, %21 : f32
        %23 = arith.cmpf ugt, %22, %cst : f32
        %24 = arith.select %23, %22, %cst : f32
        %reinterpret_cast_2 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %24, %reinterpret_cast_2[%14] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_1 {
    gpu.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: index, %arg1: index, %arg2: memref<10xf32, #gpu.address_space<global>>, %arg3: memref<?x10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c4 = arith.constant 4 : index
      %c2 = arith.constant 2 : index
      %c3 = arith.constant 3 : index
      %c10 = arith.constant 10 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        memref.assume_alignment %arg2, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %arg3, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %19 = arith.muli %14, %c4 : index
        %20 = arith.addi %19, %c1 : index
        %21 = arith.addi %19, %c2 : index
        %22 = arith.addi %19, %c3 : index
        %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %23 = arith.remui %19, %c10 : index
        %24 = arith.remui %20, %c10 : index
        %25 = arith.remui %21, %c10 : index
        %26 = arith.remui %22, %c10 : index
        %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %27 = memref.load %reinterpret_cast_1[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %28 = memref.load %reinterpret_cast_1[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %29 = memref.load %reinterpret_cast_1[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_1, 16 : memref<?xf32, #gpu.address_space<global>>
        %30 = memref.load %reinterpret_cast_1[%22] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_2 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %31 = memref.load %reinterpret_cast_2[%23] : memref<10xf32, #gpu.address_space<global>>
        %32 = memref.load %reinterpret_cast_2[%24] : memref<10xf32, #gpu.address_space<global>>
        %33 = memref.load %reinterpret_cast_2[%25] : memref<10xf32, #gpu.address_space<global>>
        %34 = memref.load %reinterpret_cast_2[%26] : memref<10xf32, #gpu.address_space<global>>
        %35 = arith.addf %27, %31 : f32
        %36 = arith.addf %28, %32 : f32
        %37 = arith.addf %29, %33 : f32
        %38 = arith.addf %30, %34 : f32
        %39 = arith.cmpf ugt, %35, %cst : f32
        %40 = arith.select %39, %35, %cst : f32
        %41 = arith.cmpf ugt, %36, %cst : f32
        %42 = arith.select %41, %36, %cst : f32
        %43 = arith.cmpf ugt, %37, %cst : f32
        %44 = arith.select %43, %37, %cst : f32
        %45 = arith.cmpf ugt, %38, %cst : f32
        %46 = arith.select %45, %38, %cst : f32
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %40, %reinterpret_cast[%19] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %42, %reinterpret_cast[%20] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %44, %reinterpret_cast[%21] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %46, %reinterpret_cast[%22] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_2 {
    gpu.func @main_kLoop_maximum__5_1_1(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c10 = arith.constant 10 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remui %14, %c10 : index
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast[%14] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_1[%19] : memref<10xf32, #gpu.address_space<global>>
        %22 = arith.addf %20, %21 : f32
        %23 = arith.cmpf ugt, %22, %cst : f32
        %24 = arith.select %23, %22, %cst : f32
        %reinterpret_cast_2 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %24, %reinterpret_cast_2[%14] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After LhloFusionInlinerPass (lhlo-fusion-inliner) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
  %15 = arith.muli %dim, %c10 : index
  %16 = arith.remui %15, %c4 : index
  %17 = arith.cmpi eq, %16, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    %18 = arith.divui %15, %c4 : index
    %c0_3 = arith.constant 0 : index
    %c256 = arith.constant 256 : index
    %19 = arith.muli %c1, %c256 : index
    %c1_4 = arith.constant 1 : index
    %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0, %19]
    %21 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%19)[%c0_3, %c1]
    gpu.launch_func  @main_kernel::@main_kLoop_maximum__5_1_0___Vec4 blocks in (%20, %c1_4, %c1_4) threads in (%21, %c1_4, %c1_4) args(%19 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
  } else {
    %c0_3 = arith.constant 0 : index
    %c256 = arith.constant 256 : index
    %18 = arith.muli %c1, %c256 : index
    %c1_4 = arith.constant 1 : index
    %19 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%15)[%c0, %18]
    %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0_3, %c1]
    gpu.launch_func  @main_kernel_0::@main_kLoop_maximum__5_1_0 blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
  }
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    %18 = arith.divui %15, %c4 : index
    %c0_3 = arith.constant 0 : index
    %c256 = arith.constant 256 : index
    %19 = arith.muli %c1, %c256 : index
    %c1_4 = arith.constant 1 : index
    %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0, %19]
    %21 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%19)[%c0_3, %c1]
    gpu.launch_func  @main_kernel_1::@main_kLoop_maximum__5_1_1___Vec4 blocks in (%20, %c1_4, %c1_4) threads in (%21, %c1_4, %c1_4) args(%19 : index, %18 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
  } else {
    %c0_3 = arith.constant 0 : index
    %c256 = arith.constant 256 : index
    %18 = arith.muli %c1, %c256 : index
    %c1_4 = arith.constant 1 : index
    %19 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%15)[%c0, %18]
    %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0_3, %c1]
    gpu.launch_func  @main_kernel_2::@main_kLoop_maximum__5_1_1 blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %15 : index, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>)
  }
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After DiscArgsMutationExpandPass (disc-argsmutation-expand) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c256 = arith.constant 256 : index
    %c3_i32 = arith.constant 3 : i32
    %c2_i32 = arith.constant 2 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %0 = llvm.mlir.constant(0 : i32) : i32
    %false = arith.constant false
    %true = arith.constant true
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
    %15 = arith.muli %dim, %c10 : index
    %16 = arith.remui %15, %c4 : index
    %17 = arith.cmpi eq, %16, %c0 : index
    %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %17 {
      %18 = arith.divui %15, %c4 : index
      %19 = affine.apply #map(%18)[%c0, %c256]
      gpu.launch_func  @main_kernel::@main_kLoop_maximum__5_1_0___Vec4 blocks in (%19, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    } else {
      %18 = affine.apply #map(%15)[%c0, %c256]
      gpu.launch_func  @main_kernel_0::@main_kLoop_maximum__5_1_0 blocks in (%18, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
    }
    memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
    %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    scf.if %17 {
      %18 = arith.divui %15, %c4 : index
      %19 = affine.apply #map(%18)[%c0, %c256]
      gpu.launch_func  @main_kernel_1::@main_kLoop_maximum__5_1_1___Vec4 blocks in (%19, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %18 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    } else {
      %18 = affine.apply #map(%15)[%c0, %c256]
      gpu.launch_func  @main_kernel_2::@main_kLoop_maximum__5_1_1 blocks in (%18, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>)
    }
    memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
      %cst = arith.constant 0.000000e+00 : f32
      %c10 = arith.constant 10 : index
      %c3 = arith.constant 3 : index
      %c2 = arith.constant 2 : index
      %c4 = arith.constant 4 : index
      %c1 = arith.constant 1 : index
      %c0 = arith.constant 0 : index
      %0 = gpu.block_id  x
      %1 = gpu.thread_id  x
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %2 = affine.apply #map1(%0)[%arg0, %c0]
      %3 = affine.apply #map1(%1)[%c1, %c0]
      %4 = arith.addi %3, %2 : index
      %5 = arith.addi %3, %2 : index
      %6 = arith.cmpi ult, %5, %arg1 : index
      scf.if %6 {
        memref.assume_alignment %arg2, 16 : memref<?x10xf32, #gpu.address_space<global>>
        memref.assume_alignment %arg3, 16 : memref<10xf32, #gpu.address_space<global>>
        %7 = arith.muli %4, %c4 : index
        %8 = arith.addi %7, %c1 : index
        %9 = arith.addi %7, %c2 : index
        %10 = arith.addi %7, %c3 : index
        %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %11 = arith.remui %7, %c10 : index
        %12 = arith.remui %8, %c10 : index
        %13 = arith.remui %9, %c10 : index
        %14 = arith.remui %10, %c10 : index
        %reinterpret_cast_0 = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
        %15 = memref.load %reinterpret_cast_0[%7] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
        %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
        %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
        %18 = memref.load %reinterpret_cast_0[%10] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %19 = memref.load %reinterpret_cast_1[%11] : memref<10xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
        %22 = memref.load %reinterpret_cast_1[%14] : memref<10xf32, #gpu.address_space<global>>
        %23 = arith.addf %15, %19 : f32
        %24 = arith.addf %16, %20 : f32
        %25 = arith.addf %17, %21 : f32
        %26 = arith.addf %18, %22 : f32
        %27 = arith.cmpf ugt, %23, %cst : f32
        %28 = arith.select %27, %23, %cst : f32
        %29 = arith.cmpf ugt, %24, %cst : f32
        %30 = arith.select %29, %24, %cst : f32
        %31 = arith.cmpf ugt, %25, %cst : f32
        %32 = arith.select %31, %25, %cst : f32
        %33 = arith.cmpf ugt, %26, %cst : f32
        %34 = arith.select %33, %26, %cst : f32
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %28, %reinterpret_cast[%7] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %30, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %32, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %34, %reinterpret_cast[%10] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kLoop_maximum__5_1_0(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
      %cst = arith.constant 0.000000e+00 : f32
      %c10 = arith.constant 10 : index
      %c1 = arith.constant 1 : index
      %c0 = arith.constant 0 : index
      %0 = gpu.block_id  x
      %1 = gpu.thread_id  x
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %2 = affine.apply #map1(%0)[%arg0, %c0]
      %3 = affine.apply #map1(%1)[%c1, %c0]
      %4 = arith.addi %3, %2 : index
      %5 = arith.addi %3, %2 : index
      %6 = arith.cmpi ult, %5, %arg1 : index
      scf.if %6 {
        %7 = arith.remui %4, %c10 : index
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %8 = memref.load %reinterpret_cast[%4] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %9 = memref.load %reinterpret_cast_0[%7] : memref<10xf32, #gpu.address_space<global>>
        %10 = arith.addf %8, %9 : f32
        %11 = arith.cmpf ugt, %10, %cst : f32
        %12 = arith.select %11, %10, %cst : f32
        %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %12, %reinterpret_cast_1[%4] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_1 {
    gpu.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: index, %arg1: index, %arg2: memref<10xf32, #gpu.address_space<global>>, %arg3: memref<?x10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
      %cst = arith.constant 0.000000e+00 : f32
      %c10 = arith.constant 10 : index
      %c3 = arith.constant 3 : index
      %c2 = arith.constant 2 : index
      %c4 = arith.constant 4 : index
      %c1 = arith.constant 1 : index
      %c0 = arith.constant 0 : index
      %0 = gpu.block_id  x
      %1 = gpu.thread_id  x
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %2 = affine.apply #map1(%0)[%arg0, %c0]
      %3 = affine.apply #map1(%1)[%c1, %c0]
      %4 = arith.addi %3, %2 : index
      %5 = arith.addi %3, %2 : index
      %6 = arith.cmpi ult, %5, %arg1 : index
      scf.if %6 {
        memref.assume_alignment %arg2, 16 : memref<10xf32, #gpu.address_space<global>>
        memref.assume_alignment %arg3, 16 : memref<?x10xf32, #gpu.address_space<global>>
        %7 = arith.muli %4, %c4 : index
        %8 = arith.addi %7, %c1 : index
        %9 = arith.addi %7, %c2 : index
        %10 = arith.addi %7, %c3 : index
        %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %11 = arith.remui %7, %c10 : index
        %12 = arith.remui %8, %c10 : index
        %13 = arith.remui %9, %c10 : index
        %14 = arith.remui %10, %c10 : index
        %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
        %15 = memref.load %reinterpret_cast_0[%7] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
        %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
        %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
        %18 = memref.load %reinterpret_cast_0[%10] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %19 = memref.load %reinterpret_cast_1[%11] : memref<10xf32, #gpu.address_space<global>>
        %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
        %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
        %22 = memref.load %reinterpret_cast_1[%14] : memref<10xf32, #gpu.address_space<global>>
        %23 = arith.addf %15, %19 : f32
        %24 = arith.addf %16, %20 : f32
        %25 = arith.addf %17, %21 : f32
        %26 = arith.addf %18, %22 : f32
        %27 = arith.cmpf ugt, %23, %cst : f32
        %28 = arith.select %27, %23, %cst : f32
        %29 = arith.cmpf ugt, %24, %cst : f32
        %30 = arith.select %29, %24, %cst : f32
        %31 = arith.cmpf ugt, %25, %cst : f32
        %32 = arith.select %31, %25, %cst : f32
        %33 = arith.cmpf ugt, %26, %cst : f32
        %34 = arith.select %33, %26, %cst : f32
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %28, %reinterpret_cast[%7] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %30, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %32, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        memref.store %34, %reinterpret_cast[%10] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_2 {
    gpu.func @main_kLoop_maximum__5_1_1(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
      %cst = arith.constant 0.000000e+00 : f32
      %c10 = arith.constant 10 : index
      %c1 = arith.constant 1 : index
      %c0 = arith.constant 0 : index
      %0 = gpu.block_id  x
      %1 = gpu.thread_id  x
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %2 = affine.apply #map1(%0)[%arg0, %c0]
      %3 = affine.apply #map1(%1)[%c1, %c0]
      %4 = arith.addi %3, %2 : index
      %5 = arith.addi %3, %2 : index
      %6 = arith.cmpi ult, %5, %arg1 : index
      scf.if %6 {
        %7 = arith.remui %4, %c10 : index
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
        %8 = memref.load %reinterpret_cast[%4] : memref<?xf32, #gpu.address_space<global>>
        %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
        %9 = memref.load %reinterpret_cast_0[%7] : memref<10xf32, #gpu.address_space<global>>
        %10 = arith.addf %8, %9 : f32
        %11 = arith.cmpf ugt, %10, %cst : f32
        %12 = arith.select %11, %10, %cst : f32
        %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
        memref.store %12, %reinterpret_cast_1[%4] : memref<?xf32, #gpu.address_space<global>>
      }
      gpu.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel {
  gpu.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    scf.if %5 {
      memref.assume_alignment %arg2, 16 : memref<?x10xf32, #gpu.address_space<global>>
      memref.assume_alignment %arg3, 16 : memref<10xf32, #gpu.address_space<global>>
      %6 = arith.muli %4, %c4 : index
      %7 = arith.addi %6, %c1 : index
      %8 = arith.addi %6, %c2 : index
      %9 = arith.addi %6, %c3 : index
      %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      %10 = arith.remui %6, %c10 : index
      %11 = arith.remui %7, %c10 : index
      %12 = arith.remui %8, %c10 : index
      %13 = arith.remui %9, %c10 : index
      %reinterpret_cast_0 = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
      %14 = memref.load %reinterpret_cast_0[%6] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
      %15 = memref.load %reinterpret_cast_0[%7] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
      %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
      %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
      %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
      %18 = memref.load %reinterpret_cast_1[%10] : memref<10xf32, #gpu.address_space<global>>
      %19 = memref.load %reinterpret_cast_1[%11] : memref<10xf32, #gpu.address_space<global>>
      %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
      %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
      %22 = arith.addf %14, %18 : f32
      %23 = arith.addf %15, %19 : f32
      %24 = arith.addf %16, %20 : f32
      %25 = arith.addf %17, %21 : f32
      %26 = arith.cmpf ugt, %22, %cst : f32
      %27 = arith.select %26, %22, %cst : f32
      %28 = arith.cmpf ugt, %23, %cst : f32
      %29 = arith.select %28, %23, %cst : f32
      %30 = arith.cmpf ugt, %24, %cst : f32
      %31 = arith.select %30, %24, %cst : f32
      %32 = arith.cmpf ugt, %25, %cst : f32
      %33 = arith.select %32, %25, %cst : f32
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.store %27, %reinterpret_cast[%6] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.store %29, %reinterpret_cast[%7] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.store %31, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.store %33, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel {
  gpu.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.assume_alignment %arg2, 16 : memref<?x10xf32, #gpu.address_space<global>>
    memref.assume_alignment %arg3, 16 : memref<10xf32, #gpu.address_space<global>>
    %6 = arith.muli %4, %c4 : index
    %7 = arith.addi %6, %c1 : index
    %8 = arith.addi %6, %c2 : index
    %9 = arith.addi %6, %c3 : index
    %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %10 = arith.remui %6, %c10 : index
    %11 = arith.remui %7, %c10 : index
    %12 = arith.remui %8, %c10 : index
    %13 = arith.remui %9, %c10 : index
    %reinterpret_cast_0 = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %14 = memref.load %reinterpret_cast_0[%6] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %15 = memref.load %reinterpret_cast_0[%7] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %18 = memref.load %reinterpret_cast_1[%10] : memref<10xf32, #gpu.address_space<global>>
    %19 = memref.load %reinterpret_cast_1[%11] : memref<10xf32, #gpu.address_space<global>>
    %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
    %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
    %22 = arith.addf %14, %18 : f32
    %23 = arith.addf %15, %19 : f32
    %24 = arith.addf %16, %20 : f32
    %25 = arith.addf %17, %21 : f32
    %26 = arith.cmpf ugt, %22, %cst : f32
    %27 = arith.select %26, %22, %cst : f32
    %28 = arith.cmpf ugt, %23, %cst : f32
    %29 = arith.select %28, %23, %cst : f32
    %30 = arith.cmpf ugt, %24, %cst : f32
    %31 = arith.select %30, %24, %cst : f32
    %32 = arith.cmpf ugt, %25, %cst : f32
    %33 = arith.select %32, %25, %cst : f32
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %27, %reinterpret_cast[%6] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %29, %reinterpret_cast[%7] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %31, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %33, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel {
  gpu.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.assume_alignment %arg2, 16 : memref<?x10xf32, #gpu.address_space<global>>
    memref.assume_alignment %arg3, 16 : memref<10xf32, #gpu.address_space<global>>
    %8 = arith.muli %6, %c4 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.addi %8, %c2 : index
    %11 = arith.addi %8, %c3 : index
    %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %12 = arith.remui %8, %c10 : index
    %13 = arith.remui %9, %c10 : index
    %14 = arith.remui %10, %c10 : index
    %15 = arith.remui %11, %c10 : index
    %reinterpret_cast_0 = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %18 = memref.load %reinterpret_cast_0[%10] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %19 = memref.load %reinterpret_cast_0[%11] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
    %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
    %22 = memref.load %reinterpret_cast_1[%14] : memref<10xf32, #gpu.address_space<global>>
    %23 = memref.load %reinterpret_cast_1[%15] : memref<10xf32, #gpu.address_space<global>>
    %24 = arith.addf %16, %20 : f32
    %25 = arith.addf %17, %21 : f32
    %26 = arith.addf %18, %22 : f32
    %27 = arith.addf %19, %23 : f32
    %28 = arith.cmpf ugt, %24, %cst : f32
    %29 = arith.select %28, %24, %cst : f32
    %30 = arith.cmpf ugt, %25, %cst : f32
    %31 = arith.select %30, %25, %cst : f32
    %32 = arith.cmpf ugt, %26, %cst : f32
    %33 = arith.select %32, %26, %cst : f32
    %34 = arith.cmpf ugt, %27, %cst : f32
    %35 = arith.select %34, %27, %cst : f32
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %29, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %31, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %33, %reinterpret_cast[%10] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %35, %reinterpret_cast[%11] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel {
  gpu.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.assume_alignment %arg2, 16 : memref<?x10xf32, #gpu.address_space<global>>
    memref.assume_alignment %arg3, 16 : memref<10xf32, #gpu.address_space<global>>
    %8 = arith.muli %6, %c4 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.addi %8, %c2 : index
    %11 = arith.addi %8, %c3 : index
    %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %12 = arith.remui %8, %c10 : index
    %13 = arith.remui %9, %c10 : index
    %14 = arith.remui %10, %c10 : index
    %15 = arith.remui %11, %c10 : index
    %reinterpret_cast_0 = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %18 = memref.load %reinterpret_cast_0[%10] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %19 = memref.load %reinterpret_cast_0[%11] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
    %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
    %22 = memref.load %reinterpret_cast_1[%14] : memref<10xf32, #gpu.address_space<global>>
    %23 = memref.load %reinterpret_cast_1[%15] : memref<10xf32, #gpu.address_space<global>>
    %24 = arith.addf %16, %20 : f32
    %25 = arith.addf %17, %21 : f32
    %26 = arith.addf %18, %22 : f32
    %27 = arith.addf %19, %23 : f32
    %28 = arith.cmpf ugt, %24, %cst : f32
    %29 = arith.select %28, %24, %cst : f32
    %30 = arith.cmpf ugt, %25, %cst : f32
    %31 = arith.select %30, %25, %cst : f32
    %32 = arith.cmpf ugt, %26, %cst : f32
    %33 = arith.select %32, %26, %cst : f32
    %34 = arith.cmpf ugt, %27, %cst : f32
    %35 = arith.select %34, %27, %cst : f32
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %29, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %31, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %33, %reinterpret_cast[%10] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %35, %reinterpret_cast[%11] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel {
  llvm.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<1>, %arg10: !llvm.ptr<1>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: !llvm.ptr<1>, %arg15: !llvm.ptr<1>, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32, %arg21: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)>
    %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %5 = llvm.insertvalue %arg7, %4[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %6 = llvm.insertvalue %arg6, %5[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %7 = llvm.insertvalue %arg8, %6[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %8 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %9 = llvm.insertvalue %arg9, %8[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %10 = llvm.insertvalue %arg10, %9[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %11 = llvm.insertvalue %arg11, %10[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %12 = llvm.insertvalue %arg12, %11[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %13 = llvm.insertvalue %arg13, %12[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %14 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)>
    %15 = llvm.insertvalue %arg14, %14[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %16 = llvm.insertvalue %arg15, %15[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %17 = llvm.insertvalue %arg16, %16[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %18 = llvm.insertvalue %arg17, %17[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %19 = llvm.insertvalue %arg19, %18[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %20 = llvm.insertvalue %arg18, %19[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %21 = llvm.insertvalue %arg20, %20[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %22 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %23 = llvm.mlir.constant(10 : index) : i32
    %24 = llvm.mlir.constant(3 : index) : i32
    %25 = llvm.mlir.constant(2 : index) : i32
    %26 = llvm.mlir.constant(4 : index) : i32
    %27 = llvm.mlir.constant(1 : index) : i32
    %28 = llvm.mlir.constant(0 : index) : i32
    %29 = nvvm.read.ptx.sreg.ctaid.x : i32
    %30 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %31 = llvm.mul %29, %arg0  : i32
    %32 = llvm.add %30, %31  : i32
    %33 = llvm.icmp "ult" %32, %arg1 : i32
    llvm.cond_br %33, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %34 = llvm.extractvalue %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %35 = llvm.mlir.constant(0 : index) : i64
    %36 = llvm.mlir.constant(15 : index) : i64
    %37 = llvm.ptrtoint %34 : !llvm.ptr<1> to i64
    %38 = llvm.and %37, %36  : i64
    %39 = llvm.icmp "eq" %38, %35 : i64
    "llvm.intr.assume"(%39) : (i1) -> ()
    %40 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %41 = llvm.mlir.constant(0 : index) : i64
    %42 = llvm.mlir.constant(15 : index) : i64
    %43 = llvm.ptrtoint %40 : !llvm.ptr<1> to i64
    %44 = llvm.and %43, %42  : i64
    %45 = llvm.icmp "eq" %44, %41 : i64
    "llvm.intr.assume"(%45) : (i1) -> ()
    %46 = llvm.mul %32, %26  : i32
    %47 = llvm.add %46, %27  : i32
    %48 = llvm.add %46, %25  : i32
    %49 = llvm.add %46, %24  : i32
    %50 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %51 = llvm.extractvalue %21[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %52 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %53 = llvm.insertvalue %51, %50[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %54 = llvm.insertvalue %52, %53[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %55 = llvm.insertvalue %28, %54[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %56 = llvm.insertvalue %arg21, %55[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %57 = llvm.insertvalue %27, %56[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %58 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %59 = llvm.mlir.constant(0 : index) : i64
    %60 = llvm.mlir.constant(15 : index) : i64
    %61 = llvm.ptrtoint %58 : !llvm.ptr<1> to i64
    %62 = llvm.and %61, %60  : i64
    %63 = llvm.icmp "eq" %62, %59 : i64
    "llvm.intr.assume"(%63) : (i1) -> ()
    %64 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %65 = llvm.mlir.constant(0 : index) : i64
    %66 = llvm.mlir.constant(15 : index) : i64
    %67 = llvm.ptrtoint %64 : !llvm.ptr<1> to i64
    %68 = llvm.and %67, %66  : i64
    %69 = llvm.icmp "eq" %68, %65 : i64
    "llvm.intr.assume"(%69) : (i1) -> ()
    %70 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %71 = llvm.mlir.constant(0 : index) : i64
    %72 = llvm.mlir.constant(15 : index) : i64
    %73 = llvm.ptrtoint %70 : !llvm.ptr<1> to i64
    %74 = llvm.and %73, %72  : i64
    %75 = llvm.icmp "eq" %74, %71 : i64
    "llvm.intr.assume"(%75) : (i1) -> ()
    %76 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %77 = llvm.mlir.constant(0 : index) : i64
    %78 = llvm.mlir.constant(15 : index) : i64
    %79 = llvm.ptrtoint %76 : !llvm.ptr<1> to i64
    %80 = llvm.and %79, %78  : i64
    %81 = llvm.icmp "eq" %80, %77 : i64
    "llvm.intr.assume"(%81) : (i1) -> ()
    %82 = llvm.urem %46, %23  : i32
    %83 = llvm.urem %47, %23  : i32
    %84 = llvm.urem %48, %23  : i32
    %85 = llvm.urem %49, %23  : i32
    %86 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %87 = llvm.extractvalue %7[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %88 = llvm.extractvalue %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %89 = llvm.insertvalue %87, %86[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %90 = llvm.insertvalue %88, %89[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %91 = llvm.insertvalue %28, %90[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %92 = llvm.insertvalue %arg21, %91[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %93 = llvm.insertvalue %27, %92[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %94 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %95 = llvm.mlir.constant(0 : index) : i64
    %96 = llvm.mlir.constant(15 : index) : i64
    %97 = llvm.ptrtoint %94 : !llvm.ptr<1> to i64
    %98 = llvm.and %97, %96  : i64
    %99 = llvm.icmp "eq" %98, %95 : i64
    "llvm.intr.assume"(%99) : (i1) -> ()
    %100 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %101 = llvm.getelementptr %100[%46] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %102 = llvm.load %101 : !llvm.ptr<1> -> f32
    %103 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %104 = llvm.mlir.constant(0 : index) : i64
    %105 = llvm.mlir.constant(15 : index) : i64
    %106 = llvm.ptrtoint %103 : !llvm.ptr<1> to i64
    %107 = llvm.and %106, %105  : i64
    %108 = llvm.icmp "eq" %107, %104 : i64
    "llvm.intr.assume"(%108) : (i1) -> ()
    %109 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %110 = llvm.getelementptr %109[%47] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %111 = llvm.load %110 : !llvm.ptr<1> -> f32
    %112 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %113 = llvm.mlir.constant(0 : index) : i64
    %114 = llvm.mlir.constant(15 : index) : i64
    %115 = llvm.ptrtoint %112 : !llvm.ptr<1> to i64
    %116 = llvm.and %115, %114  : i64
    %117 = llvm.icmp "eq" %116, %113 : i64
    "llvm.intr.assume"(%117) : (i1) -> ()
    %118 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %119 = llvm.getelementptr %118[%48] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %120 = llvm.load %119 : !llvm.ptr<1> -> f32
    %121 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %122 = llvm.mlir.constant(0 : index) : i64
    %123 = llvm.mlir.constant(15 : index) : i64
    %124 = llvm.ptrtoint %121 : !llvm.ptr<1> to i64
    %125 = llvm.and %124, %123  : i64
    %126 = llvm.icmp "eq" %125, %122 : i64
    "llvm.intr.assume"(%126) : (i1) -> ()
    %127 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %128 = llvm.getelementptr %127[%49] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %129 = llvm.load %128 : !llvm.ptr<1> -> f32
    %130 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %131 = llvm.extractvalue %13[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %132 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %133 = llvm.insertvalue %131, %130[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %134 = llvm.insertvalue %132, %133[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %135 = llvm.mlir.constant(0 : index) : i32
    %136 = llvm.insertvalue %135, %134[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %137 = llvm.mlir.constant(10 : index) : i32
    %138 = llvm.insertvalue %137, %136[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %139 = llvm.mlir.constant(1 : index) : i32
    %140 = llvm.insertvalue %139, %138[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %141 = llvm.extractvalue %140[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %142 = llvm.getelementptr %141[%82] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %143 = llvm.load %142 : !llvm.ptr<1> -> f32
    %144 = llvm.extractvalue %140[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %145 = llvm.getelementptr %144[%83] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %146 = llvm.load %145 : !llvm.ptr<1> -> f32
    %147 = llvm.extractvalue %140[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %148 = llvm.getelementptr %147[%84] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %149 = llvm.load %148 : !llvm.ptr<1> -> f32
    %150 = llvm.extractvalue %140[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %151 = llvm.getelementptr %150[%85] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %152 = llvm.load %151 : !llvm.ptr<1> -> f32
    %153 = llvm.fadd %102, %143  : f32
    %154 = llvm.fadd %111, %146  : f32
    %155 = llvm.fadd %120, %149  : f32
    %156 = llvm.fadd %129, %152  : f32
    %157 = llvm.fcmp "ugt" %153, %22 : f32
    %158 = llvm.select %157, %153, %22 : i1, f32
    %159 = llvm.fcmp "ugt" %154, %22 : f32
    %160 = llvm.select %159, %154, %22 : i1, f32
    %161 = llvm.fcmp "ugt" %155, %22 : f32
    %162 = llvm.select %161, %155, %22 : i1, f32
    %163 = llvm.fcmp "ugt" %156, %22 : f32
    %164 = llvm.select %163, %156, %22 : i1, f32
    %165 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %166 = llvm.mlir.constant(0 : index) : i64
    %167 = llvm.mlir.constant(15 : index) : i64
    %168 = llvm.ptrtoint %165 : !llvm.ptr<1> to i64
    %169 = llvm.and %168, %167  : i64
    %170 = llvm.icmp "eq" %169, %166 : i64
    "llvm.intr.assume"(%170) : (i1) -> ()
    %171 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %172 = llvm.getelementptr %171[%46] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %158, %172 : f32, !llvm.ptr<1>
    %173 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %174 = llvm.mlir.constant(0 : index) : i64
    %175 = llvm.mlir.constant(15 : index) : i64
    %176 = llvm.ptrtoint %173 : !llvm.ptr<1> to i64
    %177 = llvm.and %176, %175  : i64
    %178 = llvm.icmp "eq" %177, %174 : i64
    "llvm.intr.assume"(%178) : (i1) -> ()
    %179 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %180 = llvm.getelementptr %179[%47] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %160, %180 : f32, !llvm.ptr<1>
    %181 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %182 = llvm.mlir.constant(0 : index) : i64
    %183 = llvm.mlir.constant(15 : index) : i64
    %184 = llvm.ptrtoint %181 : !llvm.ptr<1> to i64
    %185 = llvm.and %184, %183  : i64
    %186 = llvm.icmp "eq" %185, %182 : i64
    "llvm.intr.assume"(%186) : (i1) -> ()
    %187 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %188 = llvm.getelementptr %187[%48] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %162, %188 : f32, !llvm.ptr<1>
    %189 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %190 = llvm.mlir.constant(0 : index) : i64
    %191 = llvm.mlir.constant(15 : index) : i64
    %192 = llvm.ptrtoint %189 : !llvm.ptr<1> to i64
    %193 = llvm.and %192, %191  : i64
    %194 = llvm.icmp "eq" %193, %190 : i64
    "llvm.intr.assume"(%194) : (i1) -> ()
    %195 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %196 = llvm.getelementptr %195[%49] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %164, %196 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<1>, %arg10: !llvm.ptr<1>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: !llvm.ptr<1>, %arg15: !llvm.ptr<1>, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32, %arg21: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(15 : index) : i64
  %1 = llvm.mlir.constant(0 : index) : i64
  %2 = llvm.mlir.constant(1 : index) : i32
  %3 = llvm.mlir.constant(4 : index) : i32
  %4 = llvm.mlir.constant(2 : index) : i32
  %5 = llvm.mlir.constant(3 : index) : i32
  %6 = llvm.mlir.constant(10 : index) : i32
  %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %8 = nvvm.read.ptx.sreg.ctaid.x : i32
  %9 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %10 = llvm.mul %8, %arg0  : i32
  %11 = llvm.add %9, %10  : i32
  %12 = llvm.icmp "ult" %11, %arg1 : i32
  llvm.cond_br %12, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %13 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
  %14 = llvm.and %13, %0  : i64
  %15 = llvm.icmp "eq" %14, %1 : i64
  "llvm.intr.assume"(%15) : (i1) -> ()
  %16 = llvm.ptrtoint %arg10 : !llvm.ptr<1> to i64
  %17 = llvm.and %16, %0  : i64
  %18 = llvm.icmp "eq" %17, %1 : i64
  "llvm.intr.assume"(%18) : (i1) -> ()
  %19 = llvm.mul %11, %3  : i32
  %20 = llvm.add %19, %2  : i32
  %21 = llvm.add %19, %4  : i32
  %22 = llvm.add %19, %5  : i32
  %23 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %24 = llvm.and %23, %0  : i64
  %25 = llvm.icmp "eq" %24, %1 : i64
  "llvm.intr.assume"(%25) : (i1) -> ()
  %26 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %27 = llvm.and %26, %0  : i64
  %28 = llvm.icmp "eq" %27, %1 : i64
  "llvm.intr.assume"(%28) : (i1) -> ()
  %29 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %30 = llvm.and %29, %0  : i64
  %31 = llvm.icmp "eq" %30, %1 : i64
  "llvm.intr.assume"(%31) : (i1) -> ()
  %32 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %33 = llvm.and %32, %0  : i64
  %34 = llvm.icmp "eq" %33, %1 : i64
  "llvm.intr.assume"(%34) : (i1) -> ()
  %35 = llvm.urem %19, %6  : i32
  %36 = llvm.urem %20, %6  : i32
  %37 = llvm.urem %21, %6  : i32
  %38 = llvm.urem %22, %6  : i32
  %39 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
  %40 = llvm.and %39, %0  : i64
  %41 = llvm.icmp "eq" %40, %1 : i64
  "llvm.intr.assume"(%41) : (i1) -> ()
  %42 = llvm.getelementptr %arg3[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %43 = llvm.load %42 : !llvm.ptr<1> -> f32
  %44 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
  %45 = llvm.and %44, %0  : i64
  %46 = llvm.icmp "eq" %45, %1 : i64
  "llvm.intr.assume"(%46) : (i1) -> ()
  %47 = llvm.getelementptr %arg3[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %48 = llvm.load %47 : !llvm.ptr<1> -> f32
  %49 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
  %50 = llvm.and %49, %0  : i64
  %51 = llvm.icmp "eq" %50, %1 : i64
  "llvm.intr.assume"(%51) : (i1) -> ()
  %52 = llvm.getelementptr %arg3[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %53 = llvm.load %52 : !llvm.ptr<1> -> f32
  %54 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
  %55 = llvm.and %54, %0  : i64
  %56 = llvm.icmp "eq" %55, %1 : i64
  "llvm.intr.assume"(%56) : (i1) -> ()
  %57 = llvm.getelementptr %arg3[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %58 = llvm.load %57 : !llvm.ptr<1> -> f32
  %59 = llvm.getelementptr %arg10[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %60 = llvm.load %59 : !llvm.ptr<1> -> f32
  %61 = llvm.getelementptr %arg10[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %62 = llvm.load %61 : !llvm.ptr<1> -> f32
  %63 = llvm.getelementptr %arg10[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %64 = llvm.load %63 : !llvm.ptr<1> -> f32
  %65 = llvm.getelementptr %arg10[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %66 = llvm.load %65 : !llvm.ptr<1> -> f32
  %67 = llvm.fadd %43, %60  : f32
  %68 = llvm.fadd %48, %62  : f32
  %69 = llvm.fadd %53, %64  : f32
  %70 = llvm.fadd %58, %66  : f32
  %71 = llvm.fcmp "ugt" %67, %7 : f32
  %72 = llvm.select %71, %67, %7 : i1, f32
  %73 = llvm.fcmp "ugt" %68, %7 : f32
  %74 = llvm.select %73, %68, %7 : i1, f32
  %75 = llvm.fcmp "ugt" %69, %7 : f32
  %76 = llvm.select %75, %69, %7 : i1, f32
  %77 = llvm.fcmp "ugt" %70, %7 : f32
  %78 = llvm.select %77, %70, %7 : i1, f32
  %79 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %80 = llvm.and %79, %0  : i64
  %81 = llvm.icmp "eq" %80, %1 : i64
  "llvm.intr.assume"(%81) : (i1) -> ()
  %82 = llvm.getelementptr %arg15[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %72, %82 : f32, !llvm.ptr<1>
  %83 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %84 = llvm.and %83, %0  : i64
  %85 = llvm.icmp "eq" %84, %1 : i64
  "llvm.intr.assume"(%85) : (i1) -> ()
  %86 = llvm.getelementptr %arg15[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %74, %86 : f32, !llvm.ptr<1>
  %87 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %88 = llvm.and %87, %0  : i64
  %89 = llvm.icmp "eq" %88, %1 : i64
  "llvm.intr.assume"(%89) : (i1) -> ()
  %90 = llvm.getelementptr %arg15[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %76, %90 : f32, !llvm.ptr<1>
  %91 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %92 = llvm.and %91, %0  : i64
  %93 = llvm.icmp "eq" %92, %1 : i64
  "llvm.intr.assume"(%93) : (i1) -> ()
  %94 = llvm.getelementptr %arg15[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %78, %94 : f32, !llvm.ptr<1>
  llvm.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel {
  llvm.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(15 : index) : i64
    %1 = llvm.mlir.constant(0 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i32
    %3 = llvm.mlir.constant(4 : index) : i32
    %4 = llvm.mlir.constant(2 : index) : i32
    %5 = llvm.mlir.constant(3 : index) : i32
    %6 = llvm.mlir.constant(10 : index) : i32
    %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %8 = nvvm.read.ptx.sreg.ctaid.x : i32
    %9 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %10 = llvm.mul %8, %arg0  : i32
    %11 = llvm.add %9, %10  : i32
    %12 = llvm.icmp "ult" %11, %arg1 : i32
    llvm.cond_br %12, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %14 = llvm.and %13, %0  : i64
    %15 = llvm.icmp "eq" %14, %1 : i64
    "llvm.intr.assume"(%15) : (i1) -> ()
    %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %17 = llvm.and %16, %0  : i64
    %18 = llvm.icmp "eq" %17, %1 : i64
    "llvm.intr.assume"(%18) : (i1) -> ()
    %19 = llvm.mul %11, %3  : i32
    %20 = llvm.add %19, %2  : i32
    %21 = llvm.add %19, %4  : i32
    %22 = llvm.add %19, %5  : i32
    %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %24 = llvm.and %23, %0  : i64
    %25 = llvm.icmp "eq" %24, %1 : i64
    "llvm.intr.assume"(%25) : (i1) -> ()
    %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %27 = llvm.and %26, %0  : i64
    %28 = llvm.icmp "eq" %27, %1 : i64
    "llvm.intr.assume"(%28) : (i1) -> ()
    %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %30 = llvm.and %29, %0  : i64
    %31 = llvm.icmp "eq" %30, %1 : i64
    "llvm.intr.assume"(%31) : (i1) -> ()
    %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %33 = llvm.and %32, %0  : i64
    %34 = llvm.icmp "eq" %33, %1 : i64
    "llvm.intr.assume"(%34) : (i1) -> ()
    %35 = llvm.urem %19, %6  : i32
    %36 = llvm.urem %20, %6  : i32
    %37 = llvm.urem %21, %6  : i32
    %38 = llvm.urem %22, %6  : i32
    %39 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %40 = llvm.and %39, %0  : i64
    %41 = llvm.icmp "eq" %40, %1 : i64
    "llvm.intr.assume"(%41) : (i1) -> ()
    %42 = llvm.getelementptr %arg2[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %43 = llvm.load %42 : !llvm.ptr<1> -> f32
    %44 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %45 = llvm.and %44, %0  : i64
    %46 = llvm.icmp "eq" %45, %1 : i64
    "llvm.intr.assume"(%46) : (i1) -> ()
    %47 = llvm.getelementptr %arg2[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %48 = llvm.load %47 : !llvm.ptr<1> -> f32
    %49 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %50 = llvm.and %49, %0  : i64
    %51 = llvm.icmp "eq" %50, %1 : i64
    "llvm.intr.assume"(%51) : (i1) -> ()
    %52 = llvm.getelementptr %arg2[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %53 = llvm.load %52 : !llvm.ptr<1> -> f32
    %54 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %55 = llvm.and %54, %0  : i64
    %56 = llvm.icmp "eq" %55, %1 : i64
    "llvm.intr.assume"(%56) : (i1) -> ()
    %57 = llvm.getelementptr %arg2[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %58 = llvm.load %57 : !llvm.ptr<1> -> f32
    %59 = llvm.getelementptr %arg3[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %60 = llvm.load %59 : !llvm.ptr<1> -> f32
    %61 = llvm.getelementptr %arg3[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %62 = llvm.load %61 : !llvm.ptr<1> -> f32
    %63 = llvm.getelementptr %arg3[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %64 = llvm.load %63 : !llvm.ptr<1> -> f32
    %65 = llvm.getelementptr %arg3[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %66 = llvm.load %65 : !llvm.ptr<1> -> f32
    %67 = llvm.fadd %43, %60  : f32
    %68 = llvm.fadd %48, %62  : f32
    %69 = llvm.fadd %53, %64  : f32
    %70 = llvm.fadd %58, %66  : f32
    %71 = llvm.fcmp "ugt" %67, %7 : f32
    %72 = llvm.select %71, %67, %7 : i1, f32
    %73 = llvm.fcmp "ugt" %68, %7 : f32
    %74 = llvm.select %73, %68, %7 : i1, f32
    %75 = llvm.fcmp "ugt" %69, %7 : f32
    %76 = llvm.select %75, %69, %7 : i1, f32
    %77 = llvm.fcmp "ugt" %70, %7 : f32
    %78 = llvm.select %77, %70, %7 : i1, f32
    %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %80 = llvm.and %79, %0  : i64
    %81 = llvm.icmp "eq" %80, %1 : i64
    "llvm.intr.assume"(%81) : (i1) -> ()
    %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %72, %82 : f32, !llvm.ptr<1>
    %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %84 = llvm.and %83, %0  : i64
    %85 = llvm.icmp "eq" %84, %1 : i64
    "llvm.intr.assume"(%85) : (i1) -> ()
    %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %74, %86 : f32, !llvm.ptr<1>
    %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %88 = llvm.and %87, %0  : i64
    %89 = llvm.icmp "eq" %88, %1 : i64
    "llvm.intr.assume"(%89) : (i1) -> ()
    %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %76, %90 : f32, !llvm.ptr<1>
    %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %92 = llvm.and %91, %0  : i64
    %93 = llvm.icmp "eq" %92, %1 : i64
    "llvm.intr.assume"(%93) : (i1) -> ()
    %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %78, %94 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BA\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_0___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,`\02\00\22\00\01y\02\91global.v4\1A\040{%f\1D\00\10f\AD\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\04\03\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00'11S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\183U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00\\p\03\03\E0\00Sv\04\00\00Zp\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00\\\00\00\13p\00\10\C8\10\00\84\02\00\00Z\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
  llvm.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(15 : index) : i64
    %1 = llvm.mlir.constant(0 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i32
    %3 = llvm.mlir.constant(4 : index) : i32
    %4 = llvm.mlir.constant(2 : index) : i32
    %5 = llvm.mlir.constant(3 : index) : i32
    %6 = llvm.mlir.constant(10 : index) : i32
    %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %8 = nvvm.read.ptx.sreg.ctaid.x : i32
    %9 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %10 = llvm.mul %8, %arg0  : i32
    %11 = llvm.add %9, %10  : i32
    %12 = llvm.icmp "ult" %11, %arg1 : i32
    llvm.cond_br %12, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %14 = llvm.and %13, %0  : i64
    %15 = llvm.icmp "eq" %14, %1 : i64
    "llvm.intr.assume"(%15) : (i1) -> ()
    %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %17 = llvm.and %16, %0  : i64
    %18 = llvm.icmp "eq" %17, %1 : i64
    "llvm.intr.assume"(%18) : (i1) -> ()
    %19 = llvm.mul %11, %3  : i32
    %20 = llvm.add %19, %2  : i32
    %21 = llvm.add %19, %4  : i32
    %22 = llvm.add %19, %5  : i32
    %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %24 = llvm.and %23, %0  : i64
    %25 = llvm.icmp "eq" %24, %1 : i64
    "llvm.intr.assume"(%25) : (i1) -> ()
    %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %27 = llvm.and %26, %0  : i64
    %28 = llvm.icmp "eq" %27, %1 : i64
    "llvm.intr.assume"(%28) : (i1) -> ()
    %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %30 = llvm.and %29, %0  : i64
    %31 = llvm.icmp "eq" %30, %1 : i64
    "llvm.intr.assume"(%31) : (i1) -> ()
    %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %33 = llvm.and %32, %0  : i64
    %34 = llvm.icmp "eq" %33, %1 : i64
    "llvm.intr.assume"(%34) : (i1) -> ()
    %35 = llvm.urem %19, %6  : i32
    %36 = llvm.urem %20, %6  : i32
    %37 = llvm.urem %21, %6  : i32
    %38 = llvm.urem %22, %6  : i32
    %39 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %40 = llvm.and %39, %0  : i64
    %41 = llvm.icmp "eq" %40, %1 : i64
    "llvm.intr.assume"(%41) : (i1) -> ()
    %42 = llvm.getelementptr %arg2[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %43 = llvm.load %42 : !llvm.ptr<1> -> f32
    %44 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %45 = llvm.and %44, %0  : i64
    %46 = llvm.icmp "eq" %45, %1 : i64
    "llvm.intr.assume"(%46) : (i1) -> ()
    %47 = llvm.getelementptr %arg2[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %48 = llvm.load %47 : !llvm.ptr<1> -> f32
    %49 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %50 = llvm.and %49, %0  : i64
    %51 = llvm.icmp "eq" %50, %1 : i64
    "llvm.intr.assume"(%51) : (i1) -> ()
    %52 = llvm.getelementptr %arg2[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %53 = llvm.load %52 : !llvm.ptr<1> -> f32
    %54 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %55 = llvm.and %54, %0  : i64
    %56 = llvm.icmp "eq" %55, %1 : i64
    "llvm.intr.assume"(%56) : (i1) -> ()
    %57 = llvm.getelementptr %arg2[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %58 = llvm.load %57 : !llvm.ptr<1> -> f32
    %59 = llvm.getelementptr %arg3[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %60 = llvm.load %59 : !llvm.ptr<1> -> f32
    %61 = llvm.getelementptr %arg3[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %62 = llvm.load %61 : !llvm.ptr<1> -> f32
    %63 = llvm.getelementptr %arg3[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %64 = llvm.load %63 : !llvm.ptr<1> -> f32
    %65 = llvm.getelementptr %arg3[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %66 = llvm.load %65 : !llvm.ptr<1> -> f32
    %67 = llvm.fadd %43, %60  : f32
    %68 = llvm.fadd %48, %62  : f32
    %69 = llvm.fadd %53, %64  : f32
    %70 = llvm.fadd %58, %66  : f32
    %71 = llvm.fcmp "ugt" %67, %7 : f32
    %72 = llvm.select %71, %67, %7 : i1, f32
    %73 = llvm.fcmp "ugt" %68, %7 : f32
    %74 = llvm.select %73, %68, %7 : i1, f32
    %75 = llvm.fcmp "ugt" %69, %7 : f32
    %76 = llvm.select %75, %69, %7 : i1, f32
    %77 = llvm.fcmp "ugt" %70, %7 : f32
    %78 = llvm.select %77, %70, %7 : i1, f32
    %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %80 = llvm.and %79, %0  : i64
    %81 = llvm.icmp "eq" %80, %1 : i64
    "llvm.intr.assume"(%81) : (i1) -> ()
    %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %72, %82 : f32, !llvm.ptr<1>
    %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %84 = llvm.and %83, %0  : i64
    %85 = llvm.icmp "eq" %84, %1 : i64
    "llvm.intr.assume"(%85) : (i1) -> ()
    %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %74, %86 : f32, !llvm.ptr<1>
    %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %88 = llvm.and %87, %0  : i64
    %89 = llvm.icmp "eq" %88, %1 : i64
    "llvm.intr.assume"(%89) : (i1) -> ()
    %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %76, %90 : f32, !llvm.ptr<1>
    %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %92 = llvm.and %91, %0  : i64
    %93 = llvm.icmp "eq" %92, %1 : i64
    "llvm.intr.assume"(%93) : (i1) -> ()
    %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %78, %94 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kLoop_maximum__5_1_0(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    scf.if %5 {
      %6 = arith.remui %4, %c10 : index
      %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      %7 = memref.load %reinterpret_cast[%4] : memref<?xf32, #gpu.address_space<global>>
      %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
      %8 = memref.load %reinterpret_cast_0[%6] : memref<10xf32, #gpu.address_space<global>>
      %9 = arith.addf %7, %8 : f32
      %10 = arith.cmpf ugt, %9, %cst : f32
      %11 = arith.select %10, %9, %cst : f32
      %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
      memref.store %11, %reinterpret_cast_1[%4] : memref<?xf32, #gpu.address_space<global>>
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kLoop_maximum__5_1_0(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %6 = arith.remui %4, %c10 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %7 = memref.load %reinterpret_cast[%4] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %8 = memref.load %reinterpret_cast_0[%6] : memref<10xf32, #gpu.address_space<global>>
    %9 = arith.addf %7, %8 : f32
    %10 = arith.cmpf ugt, %9, %cst : f32
    %11 = arith.select %10, %9, %cst : f32
    %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.store %11, %reinterpret_cast_1[%4] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kLoop_maximum__5_1_0(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %8 = arith.remui %6, %c10 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %9 = memref.load %reinterpret_cast[%6] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %10 = memref.load %reinterpret_cast_0[%8] : memref<10xf32, #gpu.address_space<global>>
    %11 = arith.addf %9, %10 : f32
    %12 = arith.cmpf ugt, %11, %cst : f32
    %13 = arith.select %12, %11, %cst : f32
    %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.store %13, %reinterpret_cast_1[%6] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kLoop_maximum__5_1_0(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %8 = arith.remui %6, %c10 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %9 = memref.load %reinterpret_cast[%6] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %10 = memref.load %reinterpret_cast_0[%8] : memref<10xf32, #gpu.address_space<global>>
    %11 = arith.addf %9, %10 : f32
    %12 = arith.cmpf ugt, %11, %cst : f32
    %13 = arith.select %12, %11, %cst : f32
    %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.store %13, %reinterpret_cast_1[%6] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel_0 {
  llvm.func @main_kLoop_maximum__5_1_0(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<1>, %arg10: !llvm.ptr<1>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: !llvm.ptr<1>, %arg15: !llvm.ptr<1>, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)>
    %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %5 = llvm.insertvalue %arg7, %4[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %6 = llvm.insertvalue %arg6, %5[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %7 = llvm.insertvalue %arg8, %6[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %8 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %9 = llvm.insertvalue %arg9, %8[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %10 = llvm.insertvalue %arg10, %9[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %11 = llvm.insertvalue %arg11, %10[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %12 = llvm.insertvalue %arg12, %11[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %13 = llvm.insertvalue %arg13, %12[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %14 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)>
    %15 = llvm.insertvalue %arg14, %14[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %16 = llvm.insertvalue %arg15, %15[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %17 = llvm.insertvalue %arg16, %16[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %18 = llvm.insertvalue %arg17, %17[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %19 = llvm.insertvalue %arg19, %18[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %20 = llvm.insertvalue %arg18, %19[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %21 = llvm.insertvalue %arg20, %20[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %22 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %23 = llvm.mlir.constant(10 : index) : i32
    %24 = llvm.mlir.constant(1 : index) : i32
    %25 = llvm.mlir.constant(0 : index) : i32
    %26 = nvvm.read.ptx.sreg.ctaid.x : i32
    %27 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %28 = llvm.mul %26, %arg0  : i32
    %29 = llvm.add %27, %28  : i32
    %30 = llvm.icmp "ult" %29, %arg1 : i32
    llvm.cond_br %30, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %31 = llvm.urem %29, %23  : i32
    %32 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %33 = llvm.extractvalue %7[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %34 = llvm.extractvalue %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %35 = llvm.insertvalue %33, %32[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %36 = llvm.insertvalue %34, %35[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %37 = llvm.insertvalue %25, %36[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %38 = llvm.insertvalue %arg1, %37[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %39 = llvm.insertvalue %24, %38[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %40 = llvm.extractvalue %39[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %41 = llvm.mlir.constant(0 : index) : i64
    %42 = llvm.mlir.constant(15 : index) : i64
    %43 = llvm.ptrtoint %40 : !llvm.ptr<1> to i64
    %44 = llvm.and %43, %42  : i64
    %45 = llvm.icmp "eq" %44, %41 : i64
    "llvm.intr.assume"(%45) : (i1) -> ()
    %46 = llvm.extractvalue %39[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %47 = llvm.getelementptr %46[%29] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %48 = llvm.load %47 : !llvm.ptr<1> -> f32
    %49 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %50 = llvm.extractvalue %13[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %51 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %52 = llvm.insertvalue %50, %49[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %53 = llvm.insertvalue %51, %52[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %54 = llvm.mlir.constant(0 : index) : i32
    %55 = llvm.insertvalue %54, %53[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %56 = llvm.mlir.constant(10 : index) : i32
    %57 = llvm.insertvalue %56, %55[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %58 = llvm.mlir.constant(1 : index) : i32
    %59 = llvm.insertvalue %58, %57[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %60 = llvm.extractvalue %59[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %61 = llvm.getelementptr %60[%31] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %62 = llvm.load %61 : !llvm.ptr<1> -> f32
    %63 = llvm.fadd %48, %62  : f32
    %64 = llvm.fcmp "ugt" %63, %22 : f32
    %65 = llvm.select %64, %63, %22 : i1, f32
    %66 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %67 = llvm.extractvalue %21[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %68 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %69 = llvm.insertvalue %67, %66[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %70 = llvm.insertvalue %68, %69[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %71 = llvm.insertvalue %25, %70[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %72 = llvm.insertvalue %arg1, %71[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %73 = llvm.insertvalue %24, %72[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %74 = llvm.extractvalue %73[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %75 = llvm.getelementptr %74[%29] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %65, %75 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kLoop_maximum__5_1_0(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<1>, %arg10: !llvm.ptr<1>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: !llvm.ptr<1>, %arg15: !llvm.ptr<1>, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(15 : index) : i64
  %1 = llvm.mlir.constant(0 : index) : i64
  %2 = llvm.mlir.constant(10 : index) : i32
  %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %4 = nvvm.read.ptx.sreg.ctaid.x : i32
  %5 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %6 = llvm.mul %4, %arg0  : i32
  %7 = llvm.add %5, %6  : i32
  %8 = llvm.icmp "ult" %7, %arg1 : i32
  llvm.cond_br %8, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %9 = llvm.urem %7, %2  : i32
  %10 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
  %11 = llvm.and %10, %0  : i64
  %12 = llvm.icmp "eq" %11, %1 : i64
  "llvm.intr.assume"(%12) : (i1) -> ()
  %13 = llvm.getelementptr %arg3[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %14 = llvm.load %13 : !llvm.ptr<1> -> f32
  %15 = llvm.getelementptr %arg10[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %16 = llvm.load %15 : !llvm.ptr<1> -> f32
  %17 = llvm.fadd %14, %16  : f32
  %18 = llvm.fcmp "ugt" %17, %3 : f32
  %19 = llvm.select %18, %17, %3 : i1, f32
  %20 = llvm.getelementptr %arg15[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %19, %20 : f32, !llvm.ptr<1>
  llvm.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel_0 {
  llvm.func @main_kLoop_maximum__5_1_0(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(15 : index) : i64
    %1 = llvm.mlir.constant(0 : index) : i64
    %2 = llvm.mlir.constant(10 : index) : i32
    %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %4 = nvvm.read.ptx.sreg.ctaid.x : i32
    %5 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %6 = llvm.mul %4, %arg0  : i32
    %7 = llvm.add %5, %6  : i32
    %8 = llvm.icmp "ult" %7, %arg1 : i32
    llvm.cond_br %8, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %9 = llvm.urem %7, %2  : i32
    %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %11 = llvm.and %10, %0  : i64
    %12 = llvm.icmp "eq" %11, %1 : i64
    "llvm.intr.assume"(%12) : (i1) -> ()
    %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %14 = llvm.load %13 : !llvm.ptr<1> -> f32
    %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %16 = llvm.load %15 : !llvm.ptr<1> -> f32
    %17 = llvm.fadd %14, %16  : f32
    %18 = llvm.fcmp "ugt" %17, %3 : f32
    %19 = llvm.select %18, %17, %3 : i1, f32
    %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %19, %20 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel_0 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_0(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
  llvm.func @main_kLoop_maximum__5_1_0(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(15 : index) : i64
    %1 = llvm.mlir.constant(0 : index) : i64
    %2 = llvm.mlir.constant(10 : index) : i32
    %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %4 = nvvm.read.ptx.sreg.ctaid.x : i32
    %5 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %6 = llvm.mul %4, %arg0  : i32
    %7 = llvm.add %5, %6  : i32
    %8 = llvm.icmp "ult" %7, %arg1 : i32
    llvm.cond_br %8, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %9 = llvm.urem %7, %2  : i32
    %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %11 = llvm.and %10, %0  : i64
    %12 = llvm.icmp "eq" %11, %1 : i64
    "llvm.intr.assume"(%12) : (i1) -> ()
    %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %14 = llvm.load %13 : !llvm.ptr<1> -> f32
    %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %16 = llvm.load %15 : !llvm.ptr<1> -> f32
    %17 = llvm.fadd %14, %16  : f32
    %18 = llvm.fcmp "ugt" %17, %3 : f32
    %19 = llvm.select %18, %17, %3 : i1, f32
    %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %19, %20 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel_1 {
  gpu.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: index, %arg1: index, %arg2: memref<10xf32, #gpu.address_space<global>>, %arg3: memref<?x10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    scf.if %5 {
      memref.assume_alignment %arg2, 16 : memref<10xf32, #gpu.address_space<global>>
      memref.assume_alignment %arg3, 16 : memref<?x10xf32, #gpu.address_space<global>>
      %6 = arith.muli %4, %c4 : index
      %7 = arith.addi %6, %c1 : index
      %8 = arith.addi %6, %c2 : index
      %9 = arith.addi %6, %c3 : index
      %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      %10 = arith.remui %6, %c10 : index
      %11 = arith.remui %7, %c10 : index
      %12 = arith.remui %8, %c10 : index
      %13 = arith.remui %9, %c10 : index
      %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
      %14 = memref.load %reinterpret_cast_0[%6] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
      %15 = memref.load %reinterpret_cast_0[%7] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
      %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
      %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
      %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
      %18 = memref.load %reinterpret_cast_1[%10] : memref<10xf32, #gpu.address_space<global>>
      %19 = memref.load %reinterpret_cast_1[%11] : memref<10xf32, #gpu.address_space<global>>
      %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
      %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
      %22 = arith.addf %14, %18 : f32
      %23 = arith.addf %15, %19 : f32
      %24 = arith.addf %16, %20 : f32
      %25 = arith.addf %17, %21 : f32
      %26 = arith.cmpf ugt, %22, %cst : f32
      %27 = arith.select %26, %22, %cst : f32
      %28 = arith.cmpf ugt, %23, %cst : f32
      %29 = arith.select %28, %23, %cst : f32
      %30 = arith.cmpf ugt, %24, %cst : f32
      %31 = arith.select %30, %24, %cst : f32
      %32 = arith.cmpf ugt, %25, %cst : f32
      %33 = arith.select %32, %25, %cst : f32
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.store %27, %reinterpret_cast[%6] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.store %29, %reinterpret_cast[%7] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.store %31, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      memref.store %33, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel_1 {
  gpu.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: index, %arg1: index, %arg2: memref<10xf32, #gpu.address_space<global>>, %arg3: memref<?x10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.assume_alignment %arg2, 16 : memref<10xf32, #gpu.address_space<global>>
    memref.assume_alignment %arg3, 16 : memref<?x10xf32, #gpu.address_space<global>>
    %6 = arith.muli %4, %c4 : index
    %7 = arith.addi %6, %c1 : index
    %8 = arith.addi %6, %c2 : index
    %9 = arith.addi %6, %c3 : index
    %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %10 = arith.remui %6, %c10 : index
    %11 = arith.remui %7, %c10 : index
    %12 = arith.remui %8, %c10 : index
    %13 = arith.remui %9, %c10 : index
    %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %14 = memref.load %reinterpret_cast_0[%6] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %15 = memref.load %reinterpret_cast_0[%7] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %18 = memref.load %reinterpret_cast_1[%10] : memref<10xf32, #gpu.address_space<global>>
    %19 = memref.load %reinterpret_cast_1[%11] : memref<10xf32, #gpu.address_space<global>>
    %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
    %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
    %22 = arith.addf %14, %18 : f32
    %23 = arith.addf %15, %19 : f32
    %24 = arith.addf %16, %20 : f32
    %25 = arith.addf %17, %21 : f32
    %26 = arith.cmpf ugt, %22, %cst : f32
    %27 = arith.select %26, %22, %cst : f32
    %28 = arith.cmpf ugt, %23, %cst : f32
    %29 = arith.select %28, %23, %cst : f32
    %30 = arith.cmpf ugt, %24, %cst : f32
    %31 = arith.select %30, %24, %cst : f32
    %32 = arith.cmpf ugt, %25, %cst : f32
    %33 = arith.select %32, %25, %cst : f32
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %27, %reinterpret_cast[%6] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %29, %reinterpret_cast[%7] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %31, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %33, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel_1 {
  gpu.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: index, %arg1: index, %arg2: memref<10xf32, #gpu.address_space<global>>, %arg3: memref<?x10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.assume_alignment %arg2, 16 : memref<10xf32, #gpu.address_space<global>>
    memref.assume_alignment %arg3, 16 : memref<?x10xf32, #gpu.address_space<global>>
    %8 = arith.muli %6, %c4 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.addi %8, %c2 : index
    %11 = arith.addi %8, %c3 : index
    %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %12 = arith.remui %8, %c10 : index
    %13 = arith.remui %9, %c10 : index
    %14 = arith.remui %10, %c10 : index
    %15 = arith.remui %11, %c10 : index
    %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %18 = memref.load %reinterpret_cast_0[%10] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %19 = memref.load %reinterpret_cast_0[%11] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
    %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
    %22 = memref.load %reinterpret_cast_1[%14] : memref<10xf32, #gpu.address_space<global>>
    %23 = memref.load %reinterpret_cast_1[%15] : memref<10xf32, #gpu.address_space<global>>
    %24 = arith.addf %16, %20 : f32
    %25 = arith.addf %17, %21 : f32
    %26 = arith.addf %18, %22 : f32
    %27 = arith.addf %19, %23 : f32
    %28 = arith.cmpf ugt, %24, %cst : f32
    %29 = arith.select %28, %24, %cst : f32
    %30 = arith.cmpf ugt, %25, %cst : f32
    %31 = arith.select %30, %25, %cst : f32
    %32 = arith.cmpf ugt, %26, %cst : f32
    %33 = arith.select %32, %26, %cst : f32
    %34 = arith.cmpf ugt, %27, %cst : f32
    %35 = arith.select %34, %27, %cst : f32
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %29, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %31, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %33, %reinterpret_cast[%10] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %35, %reinterpret_cast[%11] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel_1 {
  gpu.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: index, %arg1: index, %arg2: memref<10xf32, #gpu.address_space<global>>, %arg3: memref<?x10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>, %arg5: index) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    memref.assume_alignment %arg2, 16 : memref<10xf32, #gpu.address_space<global>>
    memref.assume_alignment %arg3, 16 : memref<?x10xf32, #gpu.address_space<global>>
    %8 = arith.muli %6, %c4 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.addi %8, %c2 : index
    %11 = arith.addi %8, %c3 : index
    %reinterpret_cast = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %12 = arith.remui %8, %c10 : index
    %13 = arith.remui %9, %c10 : index
    %14 = arith.remui %10, %c10 : index
    %15 = arith.remui %11, %c10 : index
    %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [%c0], sizes: [%arg5], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %16 = memref.load %reinterpret_cast_0[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %17 = memref.load %reinterpret_cast_0[%9] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %18 = memref.load %reinterpret_cast_0[%10] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast_0, 16 : memref<?xf32, #gpu.address_space<global>>
    %19 = memref.load %reinterpret_cast_0[%11] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %20 = memref.load %reinterpret_cast_1[%12] : memref<10xf32, #gpu.address_space<global>>
    %21 = memref.load %reinterpret_cast_1[%13] : memref<10xf32, #gpu.address_space<global>>
    %22 = memref.load %reinterpret_cast_1[%14] : memref<10xf32, #gpu.address_space<global>>
    %23 = memref.load %reinterpret_cast_1[%15] : memref<10xf32, #gpu.address_space<global>>
    %24 = arith.addf %16, %20 : f32
    %25 = arith.addf %17, %21 : f32
    %26 = arith.addf %18, %22 : f32
    %27 = arith.addf %19, %23 : f32
    %28 = arith.cmpf ugt, %24, %cst : f32
    %29 = arith.select %28, %24, %cst : f32
    %30 = arith.cmpf ugt, %25, %cst : f32
    %31 = arith.select %30, %25, %cst : f32
    %32 = arith.cmpf ugt, %26, %cst : f32
    %33 = arith.select %32, %26, %cst : f32
    %34 = arith.cmpf ugt, %27, %cst : f32
    %35 = arith.select %34, %27, %cst : f32
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %29, %reinterpret_cast[%8] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %31, %reinterpret_cast[%9] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %33, %reinterpret_cast[%10] : memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    memref.store %35, %reinterpret_cast[%11] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel_1 {
  llvm.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: !llvm.ptr<1>, %arg8: !llvm.ptr<1>, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: !llvm.ptr<1>, %arg15: !llvm.ptr<1>, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32, %arg21: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %5 = llvm.insertvalue %arg6, %4[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %6 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)>
    %7 = llvm.insertvalue %arg7, %6[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %8 = llvm.insertvalue %arg8, %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %9 = llvm.insertvalue %arg9, %8[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %10 = llvm.insertvalue %arg10, %9[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %11 = llvm.insertvalue %arg12, %10[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %12 = llvm.insertvalue %arg11, %11[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %13 = llvm.insertvalue %arg13, %12[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %14 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)>
    %15 = llvm.insertvalue %arg14, %14[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %16 = llvm.insertvalue %arg15, %15[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %17 = llvm.insertvalue %arg16, %16[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %18 = llvm.insertvalue %arg17, %17[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %19 = llvm.insertvalue %arg19, %18[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %20 = llvm.insertvalue %arg18, %19[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %21 = llvm.insertvalue %arg20, %20[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %22 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %23 = llvm.mlir.constant(10 : index) : i32
    %24 = llvm.mlir.constant(3 : index) : i32
    %25 = llvm.mlir.constant(2 : index) : i32
    %26 = llvm.mlir.constant(4 : index) : i32
    %27 = llvm.mlir.constant(1 : index) : i32
    %28 = llvm.mlir.constant(0 : index) : i32
    %29 = nvvm.read.ptx.sreg.ctaid.x : i32
    %30 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %31 = llvm.mul %29, %arg0  : i32
    %32 = llvm.add %30, %31  : i32
    %33 = llvm.icmp "ult" %32, %arg1 : i32
    llvm.cond_br %33, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %34 = llvm.extractvalue %5[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %35 = llvm.mlir.constant(0 : index) : i64
    %36 = llvm.mlir.constant(15 : index) : i64
    %37 = llvm.ptrtoint %34 : !llvm.ptr<1> to i64
    %38 = llvm.and %37, %36  : i64
    %39 = llvm.icmp "eq" %38, %35 : i64
    "llvm.intr.assume"(%39) : (i1) -> ()
    %40 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %41 = llvm.mlir.constant(0 : index) : i64
    %42 = llvm.mlir.constant(15 : index) : i64
    %43 = llvm.ptrtoint %40 : !llvm.ptr<1> to i64
    %44 = llvm.and %43, %42  : i64
    %45 = llvm.icmp "eq" %44, %41 : i64
    "llvm.intr.assume"(%45) : (i1) -> ()
    %46 = llvm.mul %32, %26  : i32
    %47 = llvm.add %46, %27  : i32
    %48 = llvm.add %46, %25  : i32
    %49 = llvm.add %46, %24  : i32
    %50 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %51 = llvm.extractvalue %21[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %52 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %53 = llvm.insertvalue %51, %50[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %54 = llvm.insertvalue %52, %53[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %55 = llvm.insertvalue %28, %54[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %56 = llvm.insertvalue %arg21, %55[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %57 = llvm.insertvalue %27, %56[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %58 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %59 = llvm.mlir.constant(0 : index) : i64
    %60 = llvm.mlir.constant(15 : index) : i64
    %61 = llvm.ptrtoint %58 : !llvm.ptr<1> to i64
    %62 = llvm.and %61, %60  : i64
    %63 = llvm.icmp "eq" %62, %59 : i64
    "llvm.intr.assume"(%63) : (i1) -> ()
    %64 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %65 = llvm.mlir.constant(0 : index) : i64
    %66 = llvm.mlir.constant(15 : index) : i64
    %67 = llvm.ptrtoint %64 : !llvm.ptr<1> to i64
    %68 = llvm.and %67, %66  : i64
    %69 = llvm.icmp "eq" %68, %65 : i64
    "llvm.intr.assume"(%69) : (i1) -> ()
    %70 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %71 = llvm.mlir.constant(0 : index) : i64
    %72 = llvm.mlir.constant(15 : index) : i64
    %73 = llvm.ptrtoint %70 : !llvm.ptr<1> to i64
    %74 = llvm.and %73, %72  : i64
    %75 = llvm.icmp "eq" %74, %71 : i64
    "llvm.intr.assume"(%75) : (i1) -> ()
    %76 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %77 = llvm.mlir.constant(0 : index) : i64
    %78 = llvm.mlir.constant(15 : index) : i64
    %79 = llvm.ptrtoint %76 : !llvm.ptr<1> to i64
    %80 = llvm.and %79, %78  : i64
    %81 = llvm.icmp "eq" %80, %77 : i64
    "llvm.intr.assume"(%81) : (i1) -> ()
    %82 = llvm.urem %46, %23  : i32
    %83 = llvm.urem %47, %23  : i32
    %84 = llvm.urem %48, %23  : i32
    %85 = llvm.urem %49, %23  : i32
    %86 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %87 = llvm.extractvalue %13[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %88 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %89 = llvm.insertvalue %87, %86[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %90 = llvm.insertvalue %88, %89[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %91 = llvm.insertvalue %28, %90[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %92 = llvm.insertvalue %arg21, %91[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %93 = llvm.insertvalue %27, %92[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %94 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %95 = llvm.mlir.constant(0 : index) : i64
    %96 = llvm.mlir.constant(15 : index) : i64
    %97 = llvm.ptrtoint %94 : !llvm.ptr<1> to i64
    %98 = llvm.and %97, %96  : i64
    %99 = llvm.icmp "eq" %98, %95 : i64
    "llvm.intr.assume"(%99) : (i1) -> ()
    %100 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %101 = llvm.getelementptr %100[%46] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %102 = llvm.load %101 : !llvm.ptr<1> -> f32
    %103 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %104 = llvm.mlir.constant(0 : index) : i64
    %105 = llvm.mlir.constant(15 : index) : i64
    %106 = llvm.ptrtoint %103 : !llvm.ptr<1> to i64
    %107 = llvm.and %106, %105  : i64
    %108 = llvm.icmp "eq" %107, %104 : i64
    "llvm.intr.assume"(%108) : (i1) -> ()
    %109 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %110 = llvm.getelementptr %109[%47] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %111 = llvm.load %110 : !llvm.ptr<1> -> f32
    %112 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %113 = llvm.mlir.constant(0 : index) : i64
    %114 = llvm.mlir.constant(15 : index) : i64
    %115 = llvm.ptrtoint %112 : !llvm.ptr<1> to i64
    %116 = llvm.and %115, %114  : i64
    %117 = llvm.icmp "eq" %116, %113 : i64
    "llvm.intr.assume"(%117) : (i1) -> ()
    %118 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %119 = llvm.getelementptr %118[%48] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %120 = llvm.load %119 : !llvm.ptr<1> -> f32
    %121 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %122 = llvm.mlir.constant(0 : index) : i64
    %123 = llvm.mlir.constant(15 : index) : i64
    %124 = llvm.ptrtoint %121 : !llvm.ptr<1> to i64
    %125 = llvm.and %124, %123  : i64
    %126 = llvm.icmp "eq" %125, %122 : i64
    "llvm.intr.assume"(%126) : (i1) -> ()
    %127 = llvm.extractvalue %93[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %128 = llvm.getelementptr %127[%49] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %129 = llvm.load %128 : !llvm.ptr<1> -> f32
    %130 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %131 = llvm.extractvalue %5[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %132 = llvm.extractvalue %5[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %133 = llvm.insertvalue %131, %130[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %134 = llvm.insertvalue %132, %133[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %135 = llvm.mlir.constant(0 : index) : i32
    %136 = llvm.insertvalue %135, %134[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %137 = llvm.mlir.constant(10 : index) : i32
    %138 = llvm.insertvalue %137, %136[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %139 = llvm.mlir.constant(1 : index) : i32
    %140 = llvm.insertvalue %139, %138[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %141 = llvm.extractvalue %140[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %142 = llvm.getelementptr %141[%82] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %143 = llvm.load %142 : !llvm.ptr<1> -> f32
    %144 = llvm.extractvalue %140[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %145 = llvm.getelementptr %144[%83] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %146 = llvm.load %145 : !llvm.ptr<1> -> f32
    %147 = llvm.extractvalue %140[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %148 = llvm.getelementptr %147[%84] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %149 = llvm.load %148 : !llvm.ptr<1> -> f32
    %150 = llvm.extractvalue %140[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %151 = llvm.getelementptr %150[%85] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %152 = llvm.load %151 : !llvm.ptr<1> -> f32
    %153 = llvm.fadd %102, %143  : f32
    %154 = llvm.fadd %111, %146  : f32
    %155 = llvm.fadd %120, %149  : f32
    %156 = llvm.fadd %129, %152  : f32
    %157 = llvm.fcmp "ugt" %153, %22 : f32
    %158 = llvm.select %157, %153, %22 : i1, f32
    %159 = llvm.fcmp "ugt" %154, %22 : f32
    %160 = llvm.select %159, %154, %22 : i1, f32
    %161 = llvm.fcmp "ugt" %155, %22 : f32
    %162 = llvm.select %161, %155, %22 : i1, f32
    %163 = llvm.fcmp "ugt" %156, %22 : f32
    %164 = llvm.select %163, %156, %22 : i1, f32
    %165 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %166 = llvm.mlir.constant(0 : index) : i64
    %167 = llvm.mlir.constant(15 : index) : i64
    %168 = llvm.ptrtoint %165 : !llvm.ptr<1> to i64
    %169 = llvm.and %168, %167  : i64
    %170 = llvm.icmp "eq" %169, %166 : i64
    "llvm.intr.assume"(%170) : (i1) -> ()
    %171 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %172 = llvm.getelementptr %171[%46] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %158, %172 : f32, !llvm.ptr<1>
    %173 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %174 = llvm.mlir.constant(0 : index) : i64
    %175 = llvm.mlir.constant(15 : index) : i64
    %176 = llvm.ptrtoint %173 : !llvm.ptr<1> to i64
    %177 = llvm.and %176, %175  : i64
    %178 = llvm.icmp "eq" %177, %174 : i64
    "llvm.intr.assume"(%178) : (i1) -> ()
    %179 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %180 = llvm.getelementptr %179[%47] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %160, %180 : f32, !llvm.ptr<1>
    %181 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %182 = llvm.mlir.constant(0 : index) : i64
    %183 = llvm.mlir.constant(15 : index) : i64
    %184 = llvm.ptrtoint %181 : !llvm.ptr<1> to i64
    %185 = llvm.and %184, %183  : i64
    %186 = llvm.icmp "eq" %185, %182 : i64
    "llvm.intr.assume"(%186) : (i1) -> ()
    %187 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %188 = llvm.getelementptr %187[%48] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %162, %188 : f32, !llvm.ptr<1>
    %189 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %190 = llvm.mlir.constant(0 : index) : i64
    %191 = llvm.mlir.constant(15 : index) : i64
    %192 = llvm.ptrtoint %189 : !llvm.ptr<1> to i64
    %193 = llvm.and %192, %191  : i64
    %194 = llvm.icmp "eq" %193, %190 : i64
    "llvm.intr.assume"(%194) : (i1) -> ()
    %195 = llvm.extractvalue %57[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %196 = llvm.getelementptr %195[%49] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %164, %196 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: !llvm.ptr<1>, %arg8: !llvm.ptr<1>, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: !llvm.ptr<1>, %arg15: !llvm.ptr<1>, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32, %arg21: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(15 : index) : i64
  %1 = llvm.mlir.constant(0 : index) : i64
  %2 = llvm.mlir.constant(1 : index) : i32
  %3 = llvm.mlir.constant(4 : index) : i32
  %4 = llvm.mlir.constant(2 : index) : i32
  %5 = llvm.mlir.constant(3 : index) : i32
  %6 = llvm.mlir.constant(10 : index) : i32
  %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %8 = nvvm.read.ptx.sreg.ctaid.x : i32
  %9 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %10 = llvm.mul %8, %arg0  : i32
  %11 = llvm.add %9, %10  : i32
  %12 = llvm.icmp "ult" %11, %arg1 : i32
  llvm.cond_br %12, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %13 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
  %14 = llvm.and %13, %0  : i64
  %15 = llvm.icmp "eq" %14, %1 : i64
  "llvm.intr.assume"(%15) : (i1) -> ()
  %16 = llvm.ptrtoint %arg8 : !llvm.ptr<1> to i64
  %17 = llvm.and %16, %0  : i64
  %18 = llvm.icmp "eq" %17, %1 : i64
  "llvm.intr.assume"(%18) : (i1) -> ()
  %19 = llvm.mul %11, %3  : i32
  %20 = llvm.add %19, %2  : i32
  %21 = llvm.add %19, %4  : i32
  %22 = llvm.add %19, %5  : i32
  %23 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %24 = llvm.and %23, %0  : i64
  %25 = llvm.icmp "eq" %24, %1 : i64
  "llvm.intr.assume"(%25) : (i1) -> ()
  %26 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %27 = llvm.and %26, %0  : i64
  %28 = llvm.icmp "eq" %27, %1 : i64
  "llvm.intr.assume"(%28) : (i1) -> ()
  %29 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %30 = llvm.and %29, %0  : i64
  %31 = llvm.icmp "eq" %30, %1 : i64
  "llvm.intr.assume"(%31) : (i1) -> ()
  %32 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %33 = llvm.and %32, %0  : i64
  %34 = llvm.icmp "eq" %33, %1 : i64
  "llvm.intr.assume"(%34) : (i1) -> ()
  %35 = llvm.urem %19, %6  : i32
  %36 = llvm.urem %20, %6  : i32
  %37 = llvm.urem %21, %6  : i32
  %38 = llvm.urem %22, %6  : i32
  %39 = llvm.ptrtoint %arg8 : !llvm.ptr<1> to i64
  %40 = llvm.and %39, %0  : i64
  %41 = llvm.icmp "eq" %40, %1 : i64
  "llvm.intr.assume"(%41) : (i1) -> ()
  %42 = llvm.getelementptr %arg8[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %43 = llvm.load %42 : !llvm.ptr<1> -> f32
  %44 = llvm.ptrtoint %arg8 : !llvm.ptr<1> to i64
  %45 = llvm.and %44, %0  : i64
  %46 = llvm.icmp "eq" %45, %1 : i64
  "llvm.intr.assume"(%46) : (i1) -> ()
  %47 = llvm.getelementptr %arg8[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %48 = llvm.load %47 : !llvm.ptr<1> -> f32
  %49 = llvm.ptrtoint %arg8 : !llvm.ptr<1> to i64
  %50 = llvm.and %49, %0  : i64
  %51 = llvm.icmp "eq" %50, %1 : i64
  "llvm.intr.assume"(%51) : (i1) -> ()
  %52 = llvm.getelementptr %arg8[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %53 = llvm.load %52 : !llvm.ptr<1> -> f32
  %54 = llvm.ptrtoint %arg8 : !llvm.ptr<1> to i64
  %55 = llvm.and %54, %0  : i64
  %56 = llvm.icmp "eq" %55, %1 : i64
  "llvm.intr.assume"(%56) : (i1) -> ()
  %57 = llvm.getelementptr %arg8[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %58 = llvm.load %57 : !llvm.ptr<1> -> f32
  %59 = llvm.getelementptr %arg3[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %60 = llvm.load %59 : !llvm.ptr<1> -> f32
  %61 = llvm.getelementptr %arg3[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %62 = llvm.load %61 : !llvm.ptr<1> -> f32
  %63 = llvm.getelementptr %arg3[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %64 = llvm.load %63 : !llvm.ptr<1> -> f32
  %65 = llvm.getelementptr %arg3[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %66 = llvm.load %65 : !llvm.ptr<1> -> f32
  %67 = llvm.fadd %43, %60  : f32
  %68 = llvm.fadd %48, %62  : f32
  %69 = llvm.fadd %53, %64  : f32
  %70 = llvm.fadd %58, %66  : f32
  %71 = llvm.fcmp "ugt" %67, %7 : f32
  %72 = llvm.select %71, %67, %7 : i1, f32
  %73 = llvm.fcmp "ugt" %68, %7 : f32
  %74 = llvm.select %73, %68, %7 : i1, f32
  %75 = llvm.fcmp "ugt" %69, %7 : f32
  %76 = llvm.select %75, %69, %7 : i1, f32
  %77 = llvm.fcmp "ugt" %70, %7 : f32
  %78 = llvm.select %77, %70, %7 : i1, f32
  %79 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %80 = llvm.and %79, %0  : i64
  %81 = llvm.icmp "eq" %80, %1 : i64
  "llvm.intr.assume"(%81) : (i1) -> ()
  %82 = llvm.getelementptr %arg15[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %72, %82 : f32, !llvm.ptr<1>
  %83 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %84 = llvm.and %83, %0  : i64
  %85 = llvm.icmp "eq" %84, %1 : i64
  "llvm.intr.assume"(%85) : (i1) -> ()
  %86 = llvm.getelementptr %arg15[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %74, %86 : f32, !llvm.ptr<1>
  %87 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %88 = llvm.and %87, %0  : i64
  %89 = llvm.icmp "eq" %88, %1 : i64
  "llvm.intr.assume"(%89) : (i1) -> ()
  %90 = llvm.getelementptr %arg15[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %76, %90 : f32, !llvm.ptr<1>
  %91 = llvm.ptrtoint %arg15 : !llvm.ptr<1> to i64
  %92 = llvm.and %91, %0  : i64
  %93 = llvm.icmp "eq" %92, %1 : i64
  "llvm.intr.assume"(%93) : (i1) -> ()
  %94 = llvm.getelementptr %arg15[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %78, %94 : f32, !llvm.ptr<1>
  llvm.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel_1 {
  llvm.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 9 : index, 10 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(15 : index) : i64
    %1 = llvm.mlir.constant(0 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i32
    %3 = llvm.mlir.constant(4 : index) : i32
    %4 = llvm.mlir.constant(2 : index) : i32
    %5 = llvm.mlir.constant(3 : index) : i32
    %6 = llvm.mlir.constant(10 : index) : i32
    %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %8 = nvvm.read.ptx.sreg.ctaid.x : i32
    %9 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %10 = llvm.mul %8, %arg0  : i32
    %11 = llvm.add %9, %10  : i32
    %12 = llvm.icmp "ult" %11, %arg1 : i32
    llvm.cond_br %12, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %14 = llvm.and %13, %0  : i64
    %15 = llvm.icmp "eq" %14, %1 : i64
    "llvm.intr.assume"(%15) : (i1) -> ()
    %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %17 = llvm.and %16, %0  : i64
    %18 = llvm.icmp "eq" %17, %1 : i64
    "llvm.intr.assume"(%18) : (i1) -> ()
    %19 = llvm.mul %11, %3  : i32
    %20 = llvm.add %19, %2  : i32
    %21 = llvm.add %19, %4  : i32
    %22 = llvm.add %19, %5  : i32
    %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %24 = llvm.and %23, %0  : i64
    %25 = llvm.icmp "eq" %24, %1 : i64
    "llvm.intr.assume"(%25) : (i1) -> ()
    %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %27 = llvm.and %26, %0  : i64
    %28 = llvm.icmp "eq" %27, %1 : i64
    "llvm.intr.assume"(%28) : (i1) -> ()
    %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %30 = llvm.and %29, %0  : i64
    %31 = llvm.icmp "eq" %30, %1 : i64
    "llvm.intr.assume"(%31) : (i1) -> ()
    %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %33 = llvm.and %32, %0  : i64
    %34 = llvm.icmp "eq" %33, %1 : i64
    "llvm.intr.assume"(%34) : (i1) -> ()
    %35 = llvm.urem %19, %6  : i32
    %36 = llvm.urem %20, %6  : i32
    %37 = llvm.urem %21, %6  : i32
    %38 = llvm.urem %22, %6  : i32
    %39 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %40 = llvm.and %39, %0  : i64
    %41 = llvm.icmp "eq" %40, %1 : i64
    "llvm.intr.assume"(%41) : (i1) -> ()
    %42 = llvm.getelementptr %arg3[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %43 = llvm.load %42 : !llvm.ptr<1> -> f32
    %44 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %45 = llvm.and %44, %0  : i64
    %46 = llvm.icmp "eq" %45, %1 : i64
    "llvm.intr.assume"(%46) : (i1) -> ()
    %47 = llvm.getelementptr %arg3[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %48 = llvm.load %47 : !llvm.ptr<1> -> f32
    %49 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %50 = llvm.and %49, %0  : i64
    %51 = llvm.icmp "eq" %50, %1 : i64
    "llvm.intr.assume"(%51) : (i1) -> ()
    %52 = llvm.getelementptr %arg3[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %53 = llvm.load %52 : !llvm.ptr<1> -> f32
    %54 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %55 = llvm.and %54, %0  : i64
    %56 = llvm.icmp "eq" %55, %1 : i64
    "llvm.intr.assume"(%56) : (i1) -> ()
    %57 = llvm.getelementptr %arg3[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %58 = llvm.load %57 : !llvm.ptr<1> -> f32
    %59 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %60 = llvm.load %59 : !llvm.ptr<1> -> f32
    %61 = llvm.getelementptr %arg2[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %62 = llvm.load %61 : !llvm.ptr<1> -> f32
    %63 = llvm.getelementptr %arg2[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %64 = llvm.load %63 : !llvm.ptr<1> -> f32
    %65 = llvm.getelementptr %arg2[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %66 = llvm.load %65 : !llvm.ptr<1> -> f32
    %67 = llvm.fadd %43, %60  : f32
    %68 = llvm.fadd %48, %62  : f32
    %69 = llvm.fadd %53, %64  : f32
    %70 = llvm.fadd %58, %66  : f32
    %71 = llvm.fcmp "ugt" %67, %7 : f32
    %72 = llvm.select %71, %67, %7 : i1, f32
    %73 = llvm.fcmp "ugt" %68, %7 : f32
    %74 = llvm.select %73, %68, %7 : i1, f32
    %75 = llvm.fcmp "ugt" %69, %7 : f32
    %76 = llvm.select %75, %69, %7 : i1, f32
    %77 = llvm.fcmp "ugt" %70, %7 : f32
    %78 = llvm.select %77, %70, %7 : i1, f32
    %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %80 = llvm.and %79, %0  : i64
    %81 = llvm.icmp "eq" %80, %1 : i64
    "llvm.intr.assume"(%81) : (i1) -> ()
    %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %72, %82 : f32, !llvm.ptr<1>
    %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %84 = llvm.and %83, %0  : i64
    %85 = llvm.icmp "eq" %84, %1 : i64
    "llvm.intr.assume"(%85) : (i1) -> ()
    %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %74, %86 : f32, !llvm.ptr<1>
    %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %88 = llvm.and %87, %0  : i64
    %89 = llvm.icmp "eq" %88, %1 : i64
    "llvm.intr.assume"(%89) : (i1) -> ()
    %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %76, %90 : f32, !llvm.ptr<1>
    %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %92 = llvm.and %91, %0  : i64
    %93 = llvm.icmp "eq" %92, %1 : i64
    "llvm.intr.assume"(%93) : (i1) -> ()
    %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %78, %94 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel_1 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BD\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_1___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,\9F\02\00\22\00\01y\02\91global.v4\1A\040{%f\C4\00\10f\22\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\C5\02\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00\02\B6\02\03S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\01\C4\01\04U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00Zp\03\03\E0\00Sv\04\00\00\\p\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00Z\00\00\13p\00\10\C8\10\00\84\02\00\00\\\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
  llvm.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 9 : index, 10 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(15 : index) : i64
    %1 = llvm.mlir.constant(0 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i32
    %3 = llvm.mlir.constant(4 : index) : i32
    %4 = llvm.mlir.constant(2 : index) : i32
    %5 = llvm.mlir.constant(3 : index) : i32
    %6 = llvm.mlir.constant(10 : index) : i32
    %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %8 = nvvm.read.ptx.sreg.ctaid.x : i32
    %9 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %10 = llvm.mul %8, %arg0  : i32
    %11 = llvm.add %9, %10  : i32
    %12 = llvm.icmp "ult" %11, %arg1 : i32
    llvm.cond_br %12, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %14 = llvm.and %13, %0  : i64
    %15 = llvm.icmp "eq" %14, %1 : i64
    "llvm.intr.assume"(%15) : (i1) -> ()
    %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %17 = llvm.and %16, %0  : i64
    %18 = llvm.icmp "eq" %17, %1 : i64
    "llvm.intr.assume"(%18) : (i1) -> ()
    %19 = llvm.mul %11, %3  : i32
    %20 = llvm.add %19, %2  : i32
    %21 = llvm.add %19, %4  : i32
    %22 = llvm.add %19, %5  : i32
    %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %24 = llvm.and %23, %0  : i64
    %25 = llvm.icmp "eq" %24, %1 : i64
    "llvm.intr.assume"(%25) : (i1) -> ()
    %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %27 = llvm.and %26, %0  : i64
    %28 = llvm.icmp "eq" %27, %1 : i64
    "llvm.intr.assume"(%28) : (i1) -> ()
    %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %30 = llvm.and %29, %0  : i64
    %31 = llvm.icmp "eq" %30, %1 : i64
    "llvm.intr.assume"(%31) : (i1) -> ()
    %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %33 = llvm.and %32, %0  : i64
    %34 = llvm.icmp "eq" %33, %1 : i64
    "llvm.intr.assume"(%34) : (i1) -> ()
    %35 = llvm.urem %19, %6  : i32
    %36 = llvm.urem %20, %6  : i32
    %37 = llvm.urem %21, %6  : i32
    %38 = llvm.urem %22, %6  : i32
    %39 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %40 = llvm.and %39, %0  : i64
    %41 = llvm.icmp "eq" %40, %1 : i64
    "llvm.intr.assume"(%41) : (i1) -> ()
    %42 = llvm.getelementptr %arg3[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %43 = llvm.load %42 : !llvm.ptr<1> -> f32
    %44 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %45 = llvm.and %44, %0  : i64
    %46 = llvm.icmp "eq" %45, %1 : i64
    "llvm.intr.assume"(%46) : (i1) -> ()
    %47 = llvm.getelementptr %arg3[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %48 = llvm.load %47 : !llvm.ptr<1> -> f32
    %49 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %50 = llvm.and %49, %0  : i64
    %51 = llvm.icmp "eq" %50, %1 : i64
    "llvm.intr.assume"(%51) : (i1) -> ()
    %52 = llvm.getelementptr %arg3[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %53 = llvm.load %52 : !llvm.ptr<1> -> f32
    %54 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
    %55 = llvm.and %54, %0  : i64
    %56 = llvm.icmp "eq" %55, %1 : i64
    "llvm.intr.assume"(%56) : (i1) -> ()
    %57 = llvm.getelementptr %arg3[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %58 = llvm.load %57 : !llvm.ptr<1> -> f32
    %59 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %60 = llvm.load %59 : !llvm.ptr<1> -> f32
    %61 = llvm.getelementptr %arg2[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %62 = llvm.load %61 : !llvm.ptr<1> -> f32
    %63 = llvm.getelementptr %arg2[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %64 = llvm.load %63 : !llvm.ptr<1> -> f32
    %65 = llvm.getelementptr %arg2[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %66 = llvm.load %65 : !llvm.ptr<1> -> f32
    %67 = llvm.fadd %43, %60  : f32
    %68 = llvm.fadd %48, %62  : f32
    %69 = llvm.fadd %53, %64  : f32
    %70 = llvm.fadd %58, %66  : f32
    %71 = llvm.fcmp "ugt" %67, %7 : f32
    %72 = llvm.select %71, %67, %7 : i1, f32
    %73 = llvm.fcmp "ugt" %68, %7 : f32
    %74 = llvm.select %73, %68, %7 : i1, f32
    %75 = llvm.fcmp "ugt" %69, %7 : f32
    %76 = llvm.select %75, %69, %7 : i1, f32
    %77 = llvm.fcmp "ugt" %70, %7 : f32
    %78 = llvm.select %77, %70, %7 : i1, f32
    %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %80 = llvm.and %79, %0  : i64
    %81 = llvm.icmp "eq" %80, %1 : i64
    "llvm.intr.assume"(%81) : (i1) -> ()
    %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %72, %82 : f32, !llvm.ptr<1>
    %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %84 = llvm.and %83, %0  : i64
    %85 = llvm.icmp "eq" %84, %1 : i64
    "llvm.intr.assume"(%85) : (i1) -> ()
    %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %74, %86 : f32, !llvm.ptr<1>
    %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %88 = llvm.and %87, %0  : i64
    %89 = llvm.icmp "eq" %88, %1 : i64
    "llvm.intr.assume"(%89) : (i1) -> ()
    %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %76, %90 : f32, !llvm.ptr<1>
    %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
    %92 = llvm.and %91, %0  : i64
    %93 = llvm.icmp "eq" %92, %1 : i64
    "llvm.intr.assume"(%93) : (i1) -> ()
    %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %78, %94 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel_2 {
  gpu.func @main_kLoop_maximum__5_1_1(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    scf.if %5 {
      %6 = arith.remui %4, %c10 : index
      %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
      memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
      %7 = memref.load %reinterpret_cast[%4] : memref<?xf32, #gpu.address_space<global>>
      %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
      %8 = memref.load %reinterpret_cast_0[%6] : memref<10xf32, #gpu.address_space<global>>
      %9 = arith.addf %7, %8 : f32
      %10 = arith.cmpf ugt, %9, %cst : f32
      %11 = arith.select %10, %9, %cst : f32
      %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
      memref.store %11, %reinterpret_cast_1[%4] : memref<?xf32, #gpu.address_space<global>>
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel_2 {
  gpu.func @main_kLoop_maximum__5_1_1(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %6 = arith.remui %4, %c10 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %7 = memref.load %reinterpret_cast[%4] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %8 = memref.load %reinterpret_cast_0[%6] : memref<10xf32, #gpu.address_space<global>>
    %9 = arith.addf %7, %8 : f32
    %10 = arith.cmpf ugt, %9, %cst : f32
    %11 = arith.select %10, %9, %cst : f32
    %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.store %11, %reinterpret_cast_1[%4] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel_2 {
  gpu.func @main_kLoop_maximum__5_1_1(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %8 = arith.remui %6, %c10 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %9 = memref.load %reinterpret_cast[%6] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %10 = memref.load %reinterpret_cast_0[%8] : memref<10xf32, #gpu.address_space<global>>
    %11 = arith.addf %9, %10 : f32
    %12 = arith.cmpf ugt, %11, %cst : f32
    %13 = arith.select %12, %11, %cst : f32
    %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.store %13, %reinterpret_cast_1[%6] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel_2 {
  gpu.func @main_kLoop_maximum__5_1_1(%arg0: index, %arg1: index, %arg2: memref<?x10xf32, #gpu.address_space<global>>, %arg3: memref<10xf32, #gpu.address_space<global>>, %arg4: memref<?x10xf32, #gpu.address_space<global>>) kernel {
    %cst = arith.constant 0.000000e+00 : f32
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %8 = arith.remui %6, %c10 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.assume_alignment %reinterpret_cast, 16 : memref<?xf32, #gpu.address_space<global>>
    %9 = memref.load %reinterpret_cast[%6] : memref<?xf32, #gpu.address_space<global>>
    %reinterpret_cast_0 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [10], strides: [1] : memref<10xf32, #gpu.address_space<global>> to memref<10xf32, #gpu.address_space<global>>
    %10 = memref.load %reinterpret_cast_0[%8] : memref<10xf32, #gpu.address_space<global>>
    %11 = arith.addf %9, %10 : f32
    %12 = arith.cmpf ugt, %11, %cst : f32
    %13 = arith.select %12, %11, %cst : f32
    %reinterpret_cast_1 = memref.reinterpret_cast %arg4 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?x10xf32, #gpu.address_space<global>> to memref<?xf32, #gpu.address_space<global>>
    memref.store %13, %reinterpret_cast_1[%6] : memref<?xf32, #gpu.address_space<global>>
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel_2 {
  llvm.func @main_kLoop_maximum__5_1_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<1>, %arg10: !llvm.ptr<1>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: !llvm.ptr<1>, %arg15: !llvm.ptr<1>, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)>
    %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %5 = llvm.insertvalue %arg7, %4[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %6 = llvm.insertvalue %arg6, %5[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %7 = llvm.insertvalue %arg8, %6[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %8 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %9 = llvm.insertvalue %arg9, %8[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %10 = llvm.insertvalue %arg10, %9[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %11 = llvm.insertvalue %arg11, %10[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %12 = llvm.insertvalue %arg12, %11[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %13 = llvm.insertvalue %arg13, %12[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %14 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)>
    %15 = llvm.insertvalue %arg14, %14[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %16 = llvm.insertvalue %arg15, %15[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %17 = llvm.insertvalue %arg16, %16[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %18 = llvm.insertvalue %arg17, %17[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %19 = llvm.insertvalue %arg19, %18[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %20 = llvm.insertvalue %arg18, %19[3, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %21 = llvm.insertvalue %arg20, %20[4, 1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %22 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %23 = llvm.mlir.constant(10 : index) : i32
    %24 = llvm.mlir.constant(1 : index) : i32
    %25 = llvm.mlir.constant(0 : index) : i32
    %26 = nvvm.read.ptx.sreg.ctaid.x : i32
    %27 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %28 = llvm.mul %26, %arg0  : i32
    %29 = llvm.add %27, %28  : i32
    %30 = llvm.icmp "ult" %29, %arg1 : i32
    llvm.cond_br %30, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %31 = llvm.urem %29, %23  : i32
    %32 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %33 = llvm.extractvalue %7[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %34 = llvm.extractvalue %7[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %35 = llvm.insertvalue %33, %32[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %36 = llvm.insertvalue %34, %35[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %37 = llvm.insertvalue %25, %36[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %38 = llvm.insertvalue %arg1, %37[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %39 = llvm.insertvalue %24, %38[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %40 = llvm.extractvalue %39[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %41 = llvm.mlir.constant(0 : index) : i64
    %42 = llvm.mlir.constant(15 : index) : i64
    %43 = llvm.ptrtoint %40 : !llvm.ptr<1> to i64
    %44 = llvm.and %43, %42  : i64
    %45 = llvm.icmp "eq" %44, %41 : i64
    "llvm.intr.assume"(%45) : (i1) -> ()
    %46 = llvm.extractvalue %39[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %47 = llvm.getelementptr %46[%29] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %48 = llvm.load %47 : !llvm.ptr<1> -> f32
    %49 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %50 = llvm.extractvalue %13[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %51 = llvm.extractvalue %13[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %52 = llvm.insertvalue %50, %49[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %53 = llvm.insertvalue %51, %52[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %54 = llvm.mlir.constant(0 : index) : i32
    %55 = llvm.insertvalue %54, %53[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %56 = llvm.mlir.constant(10 : index) : i32
    %57 = llvm.insertvalue %56, %55[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %58 = llvm.mlir.constant(1 : index) : i32
    %59 = llvm.insertvalue %58, %57[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %60 = llvm.extractvalue %59[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %61 = llvm.getelementptr %60[%31] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %62 = llvm.load %61 : !llvm.ptr<1> -> f32
    %63 = llvm.fadd %48, %62  : f32
    %64 = llvm.fcmp "ugt" %63, %22 : f32
    %65 = llvm.select %64, %63, %22 : i1, f32
    %66 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)>
    %67 = llvm.extractvalue %21[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %68 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<2 x i32>, array<2 x i32>)> 
    %69 = llvm.insertvalue %67, %66[0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %70 = llvm.insertvalue %68, %69[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %71 = llvm.insertvalue %25, %70[2] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %72 = llvm.insertvalue %arg1, %71[3, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %73 = llvm.insertvalue %24, %72[4, 0] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %74 = llvm.extractvalue %73[1] : !llvm.struct<(ptr<1>, ptr<1>, i32, array<1 x i32>, array<1 x i32>)> 
    %75 = llvm.getelementptr %74[%29] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %65, %75 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kLoop_maximum__5_1_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<1>, %arg10: !llvm.ptr<1>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: !llvm.ptr<1>, %arg15: !llvm.ptr<1>, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(15 : index) : i64
  %1 = llvm.mlir.constant(0 : index) : i64
  %2 = llvm.mlir.constant(10 : index) : i32
  %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
  %4 = nvvm.read.ptx.sreg.ctaid.x : i32
  %5 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %6 = llvm.mul %4, %arg0  : i32
  %7 = llvm.add %5, %6  : i32
  %8 = llvm.icmp "ult" %7, %arg1 : i32
  llvm.cond_br %8, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %9 = llvm.urem %7, %2  : i32
  %10 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
  %11 = llvm.and %10, %0  : i64
  %12 = llvm.icmp "eq" %11, %1 : i64
  "llvm.intr.assume"(%12) : (i1) -> ()
  %13 = llvm.getelementptr %arg3[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %14 = llvm.load %13 : !llvm.ptr<1> -> f32
  %15 = llvm.getelementptr %arg10[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  %16 = llvm.load %15 : !llvm.ptr<1> -> f32
  %17 = llvm.fadd %14, %16  : f32
  %18 = llvm.fcmp "ugt" %17, %3 : f32
  %19 = llvm.select %18, %17, %3 : i1, f32
  %20 = llvm.getelementptr %arg15[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
  llvm.store %19, %20 : f32, !llvm.ptr<1>
  llvm.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel_2 {
  llvm.func @main_kLoop_maximum__5_1_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(15 : index) : i64
    %1 = llvm.mlir.constant(0 : index) : i64
    %2 = llvm.mlir.constant(10 : index) : i32
    %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %4 = nvvm.read.ptx.sreg.ctaid.x : i32
    %5 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %6 = llvm.mul %4, %arg0  : i32
    %7 = llvm.add %5, %6  : i32
    %8 = llvm.icmp "ult" %7, %arg1 : i32
    llvm.cond_br %8, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %9 = llvm.urem %7, %2  : i32
    %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %11 = llvm.and %10, %0  : i64
    %12 = llvm.icmp "eq" %11, %1 : i64
    "llvm.intr.assume"(%12) : (i1) -> ()
    %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %14 = llvm.load %13 : !llvm.ptr<1> -> f32
    %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %16 = llvm.load %15 : !llvm.ptr<1> -> f32
    %17 = llvm.fadd %14, %16  : f32
    %18 = llvm.fcmp "ugt" %17, %3 : f32
    %19 = llvm.select %18, %17, %3 : i1, f32
    %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %19, %20 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel_2 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_1(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
  llvm.func @main_kLoop_maximum__5_1_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(15 : index) : i64
    %1 = llvm.mlir.constant(0 : index) : i64
    %2 = llvm.mlir.constant(10 : index) : i32
    %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %4 = nvvm.read.ptx.sreg.ctaid.x : i32
    %5 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %6 = llvm.mul %4, %arg0  : i32
    %7 = llvm.add %5, %6  : i32
    %8 = llvm.icmp "ult" %7, %arg1 : i32
    llvm.cond_br %8, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %9 = llvm.urem %7, %2  : i32
    %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %11 = llvm.and %10, %0  : i64
    %12 = llvm.icmp "eq" %11, %1 : i64
    "llvm.intr.assume"(%12) : (i1) -> ()
    %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %14 = llvm.load %13 : !llvm.ptr<1> -> f32
    %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    %16 = llvm.load %15 : !llvm.ptr<1> -> f32
    %17 = llvm.fadd %14, %16  : f32
    %18 = llvm.fcmp "ugt" %17, %3 : f32
    %19 = llvm.select %18, %17, %3 : i1, f32
    %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
    llvm.store %19, %20 : f32, !llvm.ptr<1>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c256 = arith.constant 256 : index
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
  %15 = arith.muli %dim, %c10 : index
  %16 = arith.remui %15, %c4 : index
  %17 = arith.cmpi eq, %16, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    %18 = arith.divui %15, %c4 : index
    %19 = affine.apply affine_map<(d0) -> (d0 ceildiv 256)>(%18)
    gpu.launch_func  @main_kernel::@main_kLoop_maximum__5_1_0___Vec4 blocks in (%19, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
  } else {
    %18 = affine.apply affine_map<()[s0] -> (s0 ceildiv 256)>()[%15]
    gpu.launch_func  @main_kernel_0::@main_kLoop_maximum__5_1_0 blocks in (%18, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
  }
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  scf.if %17 {
    %18 = arith.divui %15, %c4 : index
    %19 = affine.apply affine_map<(d0) -> (d0 ceildiv 256)>(%18)
    gpu.launch_func  @main_kernel_1::@main_kLoop_maximum__5_1_1___Vec4 blocks in (%19, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %18 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
  } else {
    %18 = affine.apply affine_map<()[s0] -> (s0 ceildiv 256)>()[%15]
    gpu.launch_func  @main_kernel_2::@main_kLoop_maximum__5_1_1 blocks in (%18, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>)
  }
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
#map = affine_map<(d0) -> (d0 ceildiv 256)>
#map1 = affine_map<()[s0] -> (s0 ceildiv 256)>
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c256 = arith.constant 256 : index
    %c3_i32 = arith.constant 3 : i32
    %c2_i32 = arith.constant 2 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %0 = llvm.mlir.constant(0 : i32) : i32
    %false = arith.constant false
    %true = arith.constant true
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
    %15 = arith.muli %dim, %c10 : index
    %16 = arith.remui %15, %c4 : index
    %17 = arith.cmpi eq, %16, %c0 : index
    %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    cf.cond_br %17, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %18 = arith.divui %15, %c4 : index
    %19 = affine.apply #map(%18)
    gpu.launch_func  @main_kernel::@main_kLoop_maximum__5_1_0___Vec4 blocks in (%19, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    %20 = affine.apply #map1()[%15]
    gpu.launch_func  @main_kernel_0::@main_kLoop_maximum__5_1_0 blocks in (%20, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
    %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    cf.cond_br %17, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %21 = arith.divui %15, %c4 : index
    %22 = affine.apply #map(%21)
    gpu.launch_func  @main_kernel_1::@main_kLoop_maximum__5_1_1___Vec4 blocks in (%22, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %21 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    cf.br ^bb6
  ^bb5:  // pred: ^bb3
    %23 = affine.apply #map1()[%15]
    gpu.launch_func  @main_kernel_2::@main_kLoop_maximum__5_1_1 blocks in (%23, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>)
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BA\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_0___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,`\02\00\22\00\01y\02\91global.v4\1A\040{%f\1D\00\10f\AD\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\04\03\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00'11S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\183U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00\\p\03\03\E0\00Sv\04\00\00Zp\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00\\\00\00\13p\00\10\C8\10\00\84\02\00\00Z\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(1 : index) : i32
      %3 = llvm.mlir.constant(4 : index) : i32
      %4 = llvm.mlir.constant(2 : index) : i32
      %5 = llvm.mlir.constant(3 : index) : i32
      %6 = llvm.mlir.constant(10 : index) : i32
      %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %14 = llvm.and %13, %0  : i64
      %15 = llvm.icmp "eq" %14, %1 : i64
      "llvm.intr.assume"(%15) : (i1) -> ()
      %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %17 = llvm.and %16, %0  : i64
      %18 = llvm.icmp "eq" %17, %1 : i64
      "llvm.intr.assume"(%18) : (i1) -> ()
      %19 = llvm.mul %11, %3  : i32
      %20 = llvm.add %19, %2  : i32
      %21 = llvm.add %19, %4  : i32
      %22 = llvm.add %19, %5  : i32
      %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %24 = llvm.and %23, %0  : i64
      %25 = llvm.icmp "eq" %24, %1 : i64
      "llvm.intr.assume"(%25) : (i1) -> ()
      %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %27 = llvm.and %26, %0  : i64
      %28 = llvm.icmp "eq" %27, %1 : i64
      "llvm.intr.assume"(%28) : (i1) -> ()
      %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %30 = llvm.and %29, %0  : i64
      %31 = llvm.icmp "eq" %30, %1 : i64
      "llvm.intr.assume"(%31) : (i1) -> ()
      %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %33 = llvm.and %32, %0  : i64
      %34 = llvm.icmp "eq" %33, %1 : i64
      "llvm.intr.assume"(%34) : (i1) -> ()
      %35 = llvm.urem %19, %6  : i32
      %36 = llvm.urem %20, %6  : i32
      %37 = llvm.urem %21, %6  : i32
      %38 = llvm.urem %22, %6  : i32
      %39 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %40 = llvm.and %39, %0  : i64
      %41 = llvm.icmp "eq" %40, %1 : i64
      "llvm.intr.assume"(%41) : (i1) -> ()
      %42 = llvm.getelementptr %arg2[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %43 = llvm.load %42 : !llvm.ptr<1> -> f32
      %44 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %45 = llvm.and %44, %0  : i64
      %46 = llvm.icmp "eq" %45, %1 : i64
      "llvm.intr.assume"(%46) : (i1) -> ()
      %47 = llvm.getelementptr %arg2[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %48 = llvm.load %47 : !llvm.ptr<1> -> f32
      %49 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %50 = llvm.and %49, %0  : i64
      %51 = llvm.icmp "eq" %50, %1 : i64
      "llvm.intr.assume"(%51) : (i1) -> ()
      %52 = llvm.getelementptr %arg2[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %53 = llvm.load %52 : !llvm.ptr<1> -> f32
      %54 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %55 = llvm.and %54, %0  : i64
      %56 = llvm.icmp "eq" %55, %1 : i64
      "llvm.intr.assume"(%56) : (i1) -> ()
      %57 = llvm.getelementptr %arg2[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %58 = llvm.load %57 : !llvm.ptr<1> -> f32
      %59 = llvm.getelementptr %arg3[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %60 = llvm.load %59 : !llvm.ptr<1> -> f32
      %61 = llvm.getelementptr %arg3[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %62 = llvm.load %61 : !llvm.ptr<1> -> f32
      %63 = llvm.getelementptr %arg3[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %64 = llvm.load %63 : !llvm.ptr<1> -> f32
      %65 = llvm.getelementptr %arg3[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %66 = llvm.load %65 : !llvm.ptr<1> -> f32
      %67 = llvm.fadd %43, %60  : f32
      %68 = llvm.fadd %48, %62  : f32
      %69 = llvm.fadd %53, %64  : f32
      %70 = llvm.fadd %58, %66  : f32
      %71 = llvm.fcmp "ugt" %67, %7 : f32
      %72 = llvm.select %71, %67, %7 : i1, f32
      %73 = llvm.fcmp "ugt" %68, %7 : f32
      %74 = llvm.select %73, %68, %7 : i1, f32
      %75 = llvm.fcmp "ugt" %69, %7 : f32
      %76 = llvm.select %75, %69, %7 : i1, f32
      %77 = llvm.fcmp "ugt" %70, %7 : f32
      %78 = llvm.select %77, %70, %7 : i1, f32
      %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %80 = llvm.and %79, %0  : i64
      %81 = llvm.icmp "eq" %80, %1 : i64
      "llvm.intr.assume"(%81) : (i1) -> ()
      %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %72, %82 : f32, !llvm.ptr<1>
      %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %84 = llvm.and %83, %0  : i64
      %85 = llvm.icmp "eq" %84, %1 : i64
      "llvm.intr.assume"(%85) : (i1) -> ()
      %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %74, %86 : f32, !llvm.ptr<1>
      %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %88 = llvm.and %87, %0  : i64
      %89 = llvm.icmp "eq" %88, %1 : i64
      "llvm.intr.assume"(%89) : (i1) -> ()
      %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %76, %90 : f32, !llvm.ptr<1>
      %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %92 = llvm.and %91, %0  : i64
      %93 = llvm.icmp "eq" %92, %1 : i64
      "llvm.intr.assume"(%93) : (i1) -> ()
      %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %78, %94 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_0(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_0(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(10 : index) : i32
      %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %4 = nvvm.read.ptx.sreg.ctaid.x : i32
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %6 = llvm.mul %4, %arg0  : i32
      %7 = llvm.add %5, %6  : i32
      %8 = llvm.icmp "ult" %7, %arg1 : i32
      llvm.cond_br %8, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %9 = llvm.urem %7, %2  : i32
      %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %11 = llvm.and %10, %0  : i64
      %12 = llvm.icmp "eq" %11, %1 : i64
      "llvm.intr.assume"(%12) : (i1) -> ()
      %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %14 = llvm.load %13 : !llvm.ptr<1> -> f32
      %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %16 = llvm.load %15 : !llvm.ptr<1> -> f32
      %17 = llvm.fadd %14, %16  : f32
      %18 = llvm.fcmp "ugt" %17, %3 : f32
      %19 = llvm.select %18, %17, %3 : i1, f32
      %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %19, %20 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_1 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BD\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_1___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,\9F\02\00\22\00\01y\02\91global.v4\1A\040{%f\C4\00\10f\22\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\C5\02\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00\02\B6\02\03S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\01\C4\01\04U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00Zp\03\03\E0\00Sv\04\00\00\\p\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00Z\00\00\13p\00\10\C8\10\00\84\02\00\00\\\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 9 : index, 10 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(1 : index) : i32
      %3 = llvm.mlir.constant(4 : index) : i32
      %4 = llvm.mlir.constant(2 : index) : i32
      %5 = llvm.mlir.constant(3 : index) : i32
      %6 = llvm.mlir.constant(10 : index) : i32
      %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %14 = llvm.and %13, %0  : i64
      %15 = llvm.icmp "eq" %14, %1 : i64
      "llvm.intr.assume"(%15) : (i1) -> ()
      %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %17 = llvm.and %16, %0  : i64
      %18 = llvm.icmp "eq" %17, %1 : i64
      "llvm.intr.assume"(%18) : (i1) -> ()
      %19 = llvm.mul %11, %3  : i32
      %20 = llvm.add %19, %2  : i32
      %21 = llvm.add %19, %4  : i32
      %22 = llvm.add %19, %5  : i32
      %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %24 = llvm.and %23, %0  : i64
      %25 = llvm.icmp "eq" %24, %1 : i64
      "llvm.intr.assume"(%25) : (i1) -> ()
      %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %27 = llvm.and %26, %0  : i64
      %28 = llvm.icmp "eq" %27, %1 : i64
      "llvm.intr.assume"(%28) : (i1) -> ()
      %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %30 = llvm.and %29, %0  : i64
      %31 = llvm.icmp "eq" %30, %1 : i64
      "llvm.intr.assume"(%31) : (i1) -> ()
      %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %33 = llvm.and %32, %0  : i64
      %34 = llvm.icmp "eq" %33, %1 : i64
      "llvm.intr.assume"(%34) : (i1) -> ()
      %35 = llvm.urem %19, %6  : i32
      %36 = llvm.urem %20, %6  : i32
      %37 = llvm.urem %21, %6  : i32
      %38 = llvm.urem %22, %6  : i32
      %39 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %40 = llvm.and %39, %0  : i64
      %41 = llvm.icmp "eq" %40, %1 : i64
      "llvm.intr.assume"(%41) : (i1) -> ()
      %42 = llvm.getelementptr %arg3[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %43 = llvm.load %42 : !llvm.ptr<1> -> f32
      %44 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %45 = llvm.and %44, %0  : i64
      %46 = llvm.icmp "eq" %45, %1 : i64
      "llvm.intr.assume"(%46) : (i1) -> ()
      %47 = llvm.getelementptr %arg3[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %48 = llvm.load %47 : !llvm.ptr<1> -> f32
      %49 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %50 = llvm.and %49, %0  : i64
      %51 = llvm.icmp "eq" %50, %1 : i64
      "llvm.intr.assume"(%51) : (i1) -> ()
      %52 = llvm.getelementptr %arg3[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %53 = llvm.load %52 : !llvm.ptr<1> -> f32
      %54 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %55 = llvm.and %54, %0  : i64
      %56 = llvm.icmp "eq" %55, %1 : i64
      "llvm.intr.assume"(%56) : (i1) -> ()
      %57 = llvm.getelementptr %arg3[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %58 = llvm.load %57 : !llvm.ptr<1> -> f32
      %59 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %60 = llvm.load %59 : !llvm.ptr<1> -> f32
      %61 = llvm.getelementptr %arg2[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %62 = llvm.load %61 : !llvm.ptr<1> -> f32
      %63 = llvm.getelementptr %arg2[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %64 = llvm.load %63 : !llvm.ptr<1> -> f32
      %65 = llvm.getelementptr %arg2[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %66 = llvm.load %65 : !llvm.ptr<1> -> f32
      %67 = llvm.fadd %43, %60  : f32
      %68 = llvm.fadd %48, %62  : f32
      %69 = llvm.fadd %53, %64  : f32
      %70 = llvm.fadd %58, %66  : f32
      %71 = llvm.fcmp "ugt" %67, %7 : f32
      %72 = llvm.select %71, %67, %7 : i1, f32
      %73 = llvm.fcmp "ugt" %68, %7 : f32
      %74 = llvm.select %73, %68, %7 : i1, f32
      %75 = llvm.fcmp "ugt" %69, %7 : f32
      %76 = llvm.select %75, %69, %7 : i1, f32
      %77 = llvm.fcmp "ugt" %70, %7 : f32
      %78 = llvm.select %77, %70, %7 : i1, f32
      %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %80 = llvm.and %79, %0  : i64
      %81 = llvm.icmp "eq" %80, %1 : i64
      "llvm.intr.assume"(%81) : (i1) -> ()
      %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %72, %82 : f32, !llvm.ptr<1>
      %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %84 = llvm.and %83, %0  : i64
      %85 = llvm.icmp "eq" %84, %1 : i64
      "llvm.intr.assume"(%85) : (i1) -> ()
      %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %74, %86 : f32, !llvm.ptr<1>
      %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %88 = llvm.and %87, %0  : i64
      %89 = llvm.icmp "eq" %88, %1 : i64
      "llvm.intr.assume"(%89) : (i1) -> ()
      %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %76, %90 : f32, !llvm.ptr<1>
      %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %92 = llvm.and %91, %0  : i64
      %93 = llvm.icmp "eq" %92, %1 : i64
      "llvm.intr.assume"(%93) : (i1) -> ()
      %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %78, %94 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_2 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_1(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(10 : index) : i32
      %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %4 = nvvm.read.ptx.sreg.ctaid.x : i32
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %6 = llvm.mul %4, %arg0  : i32
      %7 = llvm.add %5, %6  : i32
      %8 = llvm.icmp "ult" %7, %arg1 : i32
      llvm.cond_br %8, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %9 = llvm.urem %7, %2  : i32
      %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %11 = llvm.and %10, %0  : i64
      %12 = llvm.icmp "eq" %11, %1 : i64
      "llvm.intr.assume"(%12) : (i1) -> ()
      %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %14 = llvm.load %13 : !llvm.ptr<1> -> f32
      %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %16 = llvm.load %15 : !llvm.ptr<1> -> f32
      %17 = llvm.fadd %14, %16  : f32
      %18 = llvm.fcmp "ugt" %17, %3 : f32
      %19 = llvm.select %18, %17, %3 : i1, f32
      %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %19, %20 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
  %c256 = arith.constant 256 : index
  %c3_i32 = arith.constant 3 : i32
  %c2_i32 = arith.constant 2 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0_i32 = arith.constant 0 : i32
  %0 = llvm.mlir.constant(0 : i32) : i32
  %false = arith.constant false
  %true = arith.constant true
  %c1 = arith.constant 1 : index
  %c4 = arith.constant 4 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
  %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
  %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
  %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
  %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
  %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
  %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
  %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
  %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
  %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
  %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
  %15 = arith.muli %dim, %c10 : index
  %16 = arith.remui %15, %c4 : index
  %17 = arith.cmpi eq, %16, %c0 : index
  %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  cf.cond_br %17, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %18 = arith.divui %15, %c4 : index
  %19 = affine.apply affine_map<()[s0] -> (s0 ceildiv 256)>()[%18]
  gpu.launch_func  @main_kernel::@main_kLoop_maximum__5_1_0___Vec4 blocks in (%19, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
  cf.br ^bb3
^bb2:  // pred: ^bb0
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 256)>()[%15]
  gpu.launch_func  @main_kernel_0::@main_kLoop_maximum__5_1_0 blocks in (%20, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
  cf.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
  %alloc_1 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_1, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
  memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
  %alloc_2 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
  cf.cond_br %17, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %21 = arith.divui %15, %c4 : index
  %22 = affine.apply affine_map<()[s0] -> (s0 ceildiv 256)>()[%21]
  gpu.launch_func  @main_kernel_1::@main_kLoop_maximum__5_1_1___Vec4 blocks in (%22, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %21 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
  cf.br ^bb6
^bb5:  // pred: ^bb3
  %23 = affine.apply affine_map<()[s0] -> (s0 ceildiv 256)>()[%15]
  gpu.launch_func  @main_kernel_2::@main_kLoop_maximum__5_1_1 blocks in (%23, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_2 : memref<?x10xf32, #gpu.address_space<global>>)
  cf.br ^bb6
^bb6:  // 2 preds: ^bb4, ^bb5
  memref.dealloc %alloc_1 : memref<?x10xf32, #gpu.address_space<global>>
  memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
  return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c256 = arith.constant 256 : index
    %c3_i32 = arith.constant 3 : i32
    %c2_i32 = arith.constant 2 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %0 = llvm.mlir.constant(0 : i32) : i32
    %false = arith.constant false
    %true = arith.constant true
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
    %15 = arith.muli %dim, %c10 : index
    %16 = arith.remui %15, %c4 : index
    %17 = arith.cmpi eq, %16, %c0 : index
    %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    cf.cond_br %17, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %18 = arith.divui %15, %c4 : index
    %c256_1 = arith.constant 256 : index
    %c0_2 = arith.constant 0 : index
    %c1_3 = arith.constant 1 : index
    %19 = arith.cmpi sle, %18, %c0_2 : index
    %20 = arith.subi %c0_2, %18 : index
    %21 = arith.subi %18, %c1_3 : index
    %22 = arith.select %19, %20, %21 : index
    %23 = arith.divsi %22, %c256_1 : index
    %24 = arith.subi %c0_2, %23 : index
    %25 = arith.addi %23, %c1_3 : index
    %26 = arith.select %19, %24, %25 : index
    gpu.launch_func  @main_kernel::@main_kLoop_maximum__5_1_0___Vec4 blocks in (%26, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    %c256_4 = arith.constant 256 : index
    %c0_5 = arith.constant 0 : index
    %c1_6 = arith.constant 1 : index
    %27 = arith.cmpi sle, %15, %c0_5 : index
    %28 = arith.subi %c0_5, %15 : index
    %29 = arith.subi %15, %c1_6 : index
    %30 = arith.select %27, %28, %29 : index
    %31 = arith.divsi %30, %c256_4 : index
    %32 = arith.subi %c0_5, %31 : index
    %33 = arith.addi %31, %c1_6 : index
    %34 = arith.select %27, %32, %33 : index
    gpu.launch_func  @main_kernel_0::@main_kLoop_maximum__5_1_0 blocks in (%34, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
    %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_7, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    cf.cond_br %17, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %35 = arith.divui %15, %c4 : index
    %c256_9 = arith.constant 256 : index
    %c0_10 = arith.constant 0 : index
    %c1_11 = arith.constant 1 : index
    %36 = arith.cmpi sle, %35, %c0_10 : index
    %37 = arith.subi %c0_10, %35 : index
    %38 = arith.subi %35, %c1_11 : index
    %39 = arith.select %36, %37, %38 : index
    %40 = arith.divsi %39, %c256_9 : index
    %41 = arith.subi %c0_10, %40 : index
    %42 = arith.addi %40, %c1_11 : index
    %43 = arith.select %36, %41, %42 : index
    gpu.launch_func  @main_kernel_1::@main_kLoop_maximum__5_1_1___Vec4 blocks in (%43, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %35 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    cf.br ^bb6
  ^bb5:  // pred: ^bb3
    %c256_12 = arith.constant 256 : index
    %c0_13 = arith.constant 0 : index
    %c1_14 = arith.constant 1 : index
    %44 = arith.cmpi sle, %15, %c0_13 : index
    %45 = arith.subi %c0_13, %15 : index
    %46 = arith.subi %15, %c1_14 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c256_12 : index
    %49 = arith.subi %c0_13, %48 : index
    %50 = arith.addi %48, %c1_14 : index
    %51 = arith.select %44, %49, %50 : index
    gpu.launch_func  @main_kernel_2::@main_kLoop_maximum__5_1_1 blocks in (%51, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>)
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %c0, %alloc_8) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BA\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_0___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,`\02\00\22\00\01y\02\91global.v4\1A\040{%f\1D\00\10f\AD\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\04\03\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00'11S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\183U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00\\p\03\03\E0\00Sv\04\00\00Zp\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00\\\00\00\13p\00\10\C8\10\00\84\02\00\00Z\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(1 : index) : i32
      %3 = llvm.mlir.constant(4 : index) : i32
      %4 = llvm.mlir.constant(2 : index) : i32
      %5 = llvm.mlir.constant(3 : index) : i32
      %6 = llvm.mlir.constant(10 : index) : i32
      %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %14 = llvm.and %13, %0  : i64
      %15 = llvm.icmp "eq" %14, %1 : i64
      "llvm.intr.assume"(%15) : (i1) -> ()
      %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %17 = llvm.and %16, %0  : i64
      %18 = llvm.icmp "eq" %17, %1 : i64
      "llvm.intr.assume"(%18) : (i1) -> ()
      %19 = llvm.mul %11, %3  : i32
      %20 = llvm.add %19, %2  : i32
      %21 = llvm.add %19, %4  : i32
      %22 = llvm.add %19, %5  : i32
      %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %24 = llvm.and %23, %0  : i64
      %25 = llvm.icmp "eq" %24, %1 : i64
      "llvm.intr.assume"(%25) : (i1) -> ()
      %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %27 = llvm.and %26, %0  : i64
      %28 = llvm.icmp "eq" %27, %1 : i64
      "llvm.intr.assume"(%28) : (i1) -> ()
      %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %30 = llvm.and %29, %0  : i64
      %31 = llvm.icmp "eq" %30, %1 : i64
      "llvm.intr.assume"(%31) : (i1) -> ()
      %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %33 = llvm.and %32, %0  : i64
      %34 = llvm.icmp "eq" %33, %1 : i64
      "llvm.intr.assume"(%34) : (i1) -> ()
      %35 = llvm.urem %19, %6  : i32
      %36 = llvm.urem %20, %6  : i32
      %37 = llvm.urem %21, %6  : i32
      %38 = llvm.urem %22, %6  : i32
      %39 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %40 = llvm.and %39, %0  : i64
      %41 = llvm.icmp "eq" %40, %1 : i64
      "llvm.intr.assume"(%41) : (i1) -> ()
      %42 = llvm.getelementptr %arg2[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %43 = llvm.load %42 : !llvm.ptr<1> -> f32
      %44 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %45 = llvm.and %44, %0  : i64
      %46 = llvm.icmp "eq" %45, %1 : i64
      "llvm.intr.assume"(%46) : (i1) -> ()
      %47 = llvm.getelementptr %arg2[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %48 = llvm.load %47 : !llvm.ptr<1> -> f32
      %49 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %50 = llvm.and %49, %0  : i64
      %51 = llvm.icmp "eq" %50, %1 : i64
      "llvm.intr.assume"(%51) : (i1) -> ()
      %52 = llvm.getelementptr %arg2[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %53 = llvm.load %52 : !llvm.ptr<1> -> f32
      %54 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %55 = llvm.and %54, %0  : i64
      %56 = llvm.icmp "eq" %55, %1 : i64
      "llvm.intr.assume"(%56) : (i1) -> ()
      %57 = llvm.getelementptr %arg2[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %58 = llvm.load %57 : !llvm.ptr<1> -> f32
      %59 = llvm.getelementptr %arg3[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %60 = llvm.load %59 : !llvm.ptr<1> -> f32
      %61 = llvm.getelementptr %arg3[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %62 = llvm.load %61 : !llvm.ptr<1> -> f32
      %63 = llvm.getelementptr %arg3[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %64 = llvm.load %63 : !llvm.ptr<1> -> f32
      %65 = llvm.getelementptr %arg3[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %66 = llvm.load %65 : !llvm.ptr<1> -> f32
      %67 = llvm.fadd %43, %60  : f32
      %68 = llvm.fadd %48, %62  : f32
      %69 = llvm.fadd %53, %64  : f32
      %70 = llvm.fadd %58, %66  : f32
      %71 = llvm.fcmp "ugt" %67, %7 : f32
      %72 = llvm.select %71, %67, %7 : i1, f32
      %73 = llvm.fcmp "ugt" %68, %7 : f32
      %74 = llvm.select %73, %68, %7 : i1, f32
      %75 = llvm.fcmp "ugt" %69, %7 : f32
      %76 = llvm.select %75, %69, %7 : i1, f32
      %77 = llvm.fcmp "ugt" %70, %7 : f32
      %78 = llvm.select %77, %70, %7 : i1, f32
      %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %80 = llvm.and %79, %0  : i64
      %81 = llvm.icmp "eq" %80, %1 : i64
      "llvm.intr.assume"(%81) : (i1) -> ()
      %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %72, %82 : f32, !llvm.ptr<1>
      %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %84 = llvm.and %83, %0  : i64
      %85 = llvm.icmp "eq" %84, %1 : i64
      "llvm.intr.assume"(%85) : (i1) -> ()
      %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %74, %86 : f32, !llvm.ptr<1>
      %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %88 = llvm.and %87, %0  : i64
      %89 = llvm.icmp "eq" %88, %1 : i64
      "llvm.intr.assume"(%89) : (i1) -> ()
      %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %76, %90 : f32, !llvm.ptr<1>
      %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %92 = llvm.and %91, %0  : i64
      %93 = llvm.icmp "eq" %92, %1 : i64
      "llvm.intr.assume"(%93) : (i1) -> ()
      %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %78, %94 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_0(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_0(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(10 : index) : i32
      %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %4 = nvvm.read.ptx.sreg.ctaid.x : i32
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %6 = llvm.mul %4, %arg0  : i32
      %7 = llvm.add %5, %6  : i32
      %8 = llvm.icmp "ult" %7, %arg1 : i32
      llvm.cond_br %8, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %9 = llvm.urem %7, %2  : i32
      %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %11 = llvm.and %10, %0  : i64
      %12 = llvm.icmp "eq" %11, %1 : i64
      "llvm.intr.assume"(%12) : (i1) -> ()
      %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %14 = llvm.load %13 : !llvm.ptr<1> -> f32
      %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %16 = llvm.load %15 : !llvm.ptr<1> -> f32
      %17 = llvm.fadd %14, %16  : f32
      %18 = llvm.fcmp "ugt" %17, %3 : f32
      %19 = llvm.select %18, %17, %3 : i1, f32
      %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %19, %20 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_1 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BD\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_1___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,\9F\02\00\22\00\01y\02\91global.v4\1A\040{%f\C4\00\10f\22\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\C5\02\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00\02\B6\02\03S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\01\C4\01\04U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00Zp\03\03\E0\00Sv\04\00\00\\p\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00Z\00\00\13p\00\10\C8\10\00\84\02\00\00\\\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 9 : index, 10 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(1 : index) : i32
      %3 = llvm.mlir.constant(4 : index) : i32
      %4 = llvm.mlir.constant(2 : index) : i32
      %5 = llvm.mlir.constant(3 : index) : i32
      %6 = llvm.mlir.constant(10 : index) : i32
      %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %14 = llvm.and %13, %0  : i64
      %15 = llvm.icmp "eq" %14, %1 : i64
      "llvm.intr.assume"(%15) : (i1) -> ()
      %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %17 = llvm.and %16, %0  : i64
      %18 = llvm.icmp "eq" %17, %1 : i64
      "llvm.intr.assume"(%18) : (i1) -> ()
      %19 = llvm.mul %11, %3  : i32
      %20 = llvm.add %19, %2  : i32
      %21 = llvm.add %19, %4  : i32
      %22 = llvm.add %19, %5  : i32
      %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %24 = llvm.and %23, %0  : i64
      %25 = llvm.icmp "eq" %24, %1 : i64
      "llvm.intr.assume"(%25) : (i1) -> ()
      %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %27 = llvm.and %26, %0  : i64
      %28 = llvm.icmp "eq" %27, %1 : i64
      "llvm.intr.assume"(%28) : (i1) -> ()
      %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %30 = llvm.and %29, %0  : i64
      %31 = llvm.icmp "eq" %30, %1 : i64
      "llvm.intr.assume"(%31) : (i1) -> ()
      %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %33 = llvm.and %32, %0  : i64
      %34 = llvm.icmp "eq" %33, %1 : i64
      "llvm.intr.assume"(%34) : (i1) -> ()
      %35 = llvm.urem %19, %6  : i32
      %36 = llvm.urem %20, %6  : i32
      %37 = llvm.urem %21, %6  : i32
      %38 = llvm.urem %22, %6  : i32
      %39 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %40 = llvm.and %39, %0  : i64
      %41 = llvm.icmp "eq" %40, %1 : i64
      "llvm.intr.assume"(%41) : (i1) -> ()
      %42 = llvm.getelementptr %arg3[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %43 = llvm.load %42 : !llvm.ptr<1> -> f32
      %44 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %45 = llvm.and %44, %0  : i64
      %46 = llvm.icmp "eq" %45, %1 : i64
      "llvm.intr.assume"(%46) : (i1) -> ()
      %47 = llvm.getelementptr %arg3[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %48 = llvm.load %47 : !llvm.ptr<1> -> f32
      %49 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %50 = llvm.and %49, %0  : i64
      %51 = llvm.icmp "eq" %50, %1 : i64
      "llvm.intr.assume"(%51) : (i1) -> ()
      %52 = llvm.getelementptr %arg3[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %53 = llvm.load %52 : !llvm.ptr<1> -> f32
      %54 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %55 = llvm.and %54, %0  : i64
      %56 = llvm.icmp "eq" %55, %1 : i64
      "llvm.intr.assume"(%56) : (i1) -> ()
      %57 = llvm.getelementptr %arg3[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %58 = llvm.load %57 : !llvm.ptr<1> -> f32
      %59 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %60 = llvm.load %59 : !llvm.ptr<1> -> f32
      %61 = llvm.getelementptr %arg2[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %62 = llvm.load %61 : !llvm.ptr<1> -> f32
      %63 = llvm.getelementptr %arg2[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %64 = llvm.load %63 : !llvm.ptr<1> -> f32
      %65 = llvm.getelementptr %arg2[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %66 = llvm.load %65 : !llvm.ptr<1> -> f32
      %67 = llvm.fadd %43, %60  : f32
      %68 = llvm.fadd %48, %62  : f32
      %69 = llvm.fadd %53, %64  : f32
      %70 = llvm.fadd %58, %66  : f32
      %71 = llvm.fcmp "ugt" %67, %7 : f32
      %72 = llvm.select %71, %67, %7 : i1, f32
      %73 = llvm.fcmp "ugt" %68, %7 : f32
      %74 = llvm.select %73, %68, %7 : i1, f32
      %75 = llvm.fcmp "ugt" %69, %7 : f32
      %76 = llvm.select %75, %69, %7 : i1, f32
      %77 = llvm.fcmp "ugt" %70, %7 : f32
      %78 = llvm.select %77, %70, %7 : i1, f32
      %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %80 = llvm.and %79, %0  : i64
      %81 = llvm.icmp "eq" %80, %1 : i64
      "llvm.intr.assume"(%81) : (i1) -> ()
      %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %72, %82 : f32, !llvm.ptr<1>
      %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %84 = llvm.and %83, %0  : i64
      %85 = llvm.icmp "eq" %84, %1 : i64
      "llvm.intr.assume"(%85) : (i1) -> ()
      %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %74, %86 : f32, !llvm.ptr<1>
      %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %88 = llvm.and %87, %0  : i64
      %89 = llvm.icmp "eq" %88, %1 : i64
      "llvm.intr.assume"(%89) : (i1) -> ()
      %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %76, %90 : f32, !llvm.ptr<1>
      %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %92 = llvm.and %91, %0  : i64
      %93 = llvm.icmp "eq" %92, %1 : i64
      "llvm.intr.assume"(%93) : (i1) -> ()
      %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %78, %94 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_2 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_1(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(10 : index) : i32
      %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %4 = nvvm.read.ptx.sreg.ctaid.x : i32
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %6 = llvm.mul %4, %arg0  : i32
      %7 = llvm.add %5, %6  : i32
      %8 = llvm.icmp "ult" %7, %arg1 : i32
      llvm.cond_br %8, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %9 = llvm.urem %7, %2  : i32
      %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %11 = llvm.and %10, %0  : i64
      %12 = llvm.icmp "eq" %11, %1 : i64
      "llvm.intr.assume"(%12) : (i1) -> ()
      %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %14 = llvm.load %13 : !llvm.ptr<1> -> f32
      %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %16 = llvm.load %15 : !llvm.ptr<1> -> f32
      %17 = llvm.fadd %14, %16  : f32
      %18 = llvm.fcmp "ugt" %17, %3 : f32
      %19 = llvm.select %18, %17, %3 : i1, f32
      %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %19, %20 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c256 = arith.constant 256 : index
    %c3_i32 = arith.constant 3 : i32
    %c2_i32 = arith.constant 2 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %0 = llvm.mlir.constant(0 : i32) : i32
    %false = arith.constant false
    %true = arith.constant true
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
    %15 = arith.muli %dim, %c10 : index
    %16 = arith.remui %15, %c4 : index
    %17 = arith.cmpi eq, %16, %c0 : index
    %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    cf.cond_br %17, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %18 = arith.divui %15, %c4 : index
    %c256_1 = arith.constant 256 : index
    %c0_2 = arith.constant 0 : index
    %c1_3 = arith.constant 1 : index
    %19 = arith.cmpi sle, %18, %c0_2 : index
    %20 = arith.subi %c0_2, %18 : index
    %21 = arith.subi %18, %c1_3 : index
    %22 = arith.select %19, %20, %21 : index
    %23 = arith.divsi %22, %c256_1 : index
    %24 = arith.subi %c0_2, %23 : index
    %25 = arith.addi %23, %c1_3 : index
    %26 = arith.select %19, %24, %25 : index
    gpu.launch_func  @main_kernel::@main_kLoop_maximum__5_1_0___Vec4 blocks in (%26, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    %c256_4 = arith.constant 256 : index
    %c0_5 = arith.constant 0 : index
    %c1_6 = arith.constant 1 : index
    %27 = arith.cmpi sle, %15, %c0_5 : index
    %28 = arith.subi %c0_5, %15 : index
    %29 = arith.subi %15, %c1_6 : index
    %30 = arith.select %27, %28, %29 : index
    %31 = arith.divsi %30, %c256_4 : index
    %32 = arith.subi %c0_5, %31 : index
    %33 = arith.addi %31, %c1_6 : index
    %34 = arith.select %27, %32, %33 : index
    gpu.launch_func  @main_kernel_0::@main_kLoop_maximum__5_1_0 blocks in (%34, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
    %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_7, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    cf.cond_br %17, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %35 = arith.divui %15, %c4 : index
    %c256_9 = arith.constant 256 : index
    %c0_10 = arith.constant 0 : index
    %c1_11 = arith.constant 1 : index
    %36 = arith.cmpi sle, %35, %c0_10 : index
    %37 = arith.subi %c0_10, %35 : index
    %38 = arith.subi %35, %c1_11 : index
    %39 = arith.select %36, %37, %38 : index
    %40 = arith.divsi %39, %c256_9 : index
    %41 = arith.subi %c0_10, %40 : index
    %42 = arith.addi %40, %c1_11 : index
    %43 = arith.select %36, %41, %42 : index
    gpu.launch_func  @main_kernel_1::@main_kLoop_maximum__5_1_1___Vec4 blocks in (%43, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %35 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    cf.br ^bb6
  ^bb5:  // pred: ^bb3
    %c256_12 = arith.constant 256 : index
    %c0_13 = arith.constant 0 : index
    %c1_14 = arith.constant 1 : index
    %44 = arith.cmpi sle, %15, %c0_13 : index
    %45 = arith.subi %c0_13, %15 : index
    %46 = arith.subi %15, %c1_14 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c256_12 : index
    %49 = arith.subi %c0_13, %48 : index
    %50 = arith.addi %48, %c1_14 : index
    %51 = arith.select %44, %49, %50 : index
    gpu.launch_func  @main_kernel_2::@main_kLoop_maximum__5_1_1 blocks in (%51, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>)
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %c0, %alloc_8) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BA\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_0___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,`\02\00\22\00\01y\02\91global.v4\1A\040{%f\1D\00\10f\AD\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\04\03\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00'11S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\183U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00\\p\03\03\E0\00Sv\04\00\00Zp\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00\\\00\00\13p\00\10\C8\10\00\84\02\00\00Z\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(1 : index) : i32
      %3 = llvm.mlir.constant(4 : index) : i32
      %4 = llvm.mlir.constant(2 : index) : i32
      %5 = llvm.mlir.constant(3 : index) : i32
      %6 = llvm.mlir.constant(10 : index) : i32
      %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %14 = llvm.and %13, %0  : i64
      %15 = llvm.icmp "eq" %14, %1 : i64
      "llvm.intr.assume"(%15) : (i1) -> ()
      %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %17 = llvm.and %16, %0  : i64
      %18 = llvm.icmp "eq" %17, %1 : i64
      "llvm.intr.assume"(%18) : (i1) -> ()
      %19 = llvm.mul %11, %3  : i32
      %20 = llvm.add %19, %2  : i32
      %21 = llvm.add %19, %4  : i32
      %22 = llvm.add %19, %5  : i32
      %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %24 = llvm.and %23, %0  : i64
      %25 = llvm.icmp "eq" %24, %1 : i64
      "llvm.intr.assume"(%25) : (i1) -> ()
      %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %27 = llvm.and %26, %0  : i64
      %28 = llvm.icmp "eq" %27, %1 : i64
      "llvm.intr.assume"(%28) : (i1) -> ()
      %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %30 = llvm.and %29, %0  : i64
      %31 = llvm.icmp "eq" %30, %1 : i64
      "llvm.intr.assume"(%31) : (i1) -> ()
      %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %33 = llvm.and %32, %0  : i64
      %34 = llvm.icmp "eq" %33, %1 : i64
      "llvm.intr.assume"(%34) : (i1) -> ()
      %35 = llvm.urem %19, %6  : i32
      %36 = llvm.urem %20, %6  : i32
      %37 = llvm.urem %21, %6  : i32
      %38 = llvm.urem %22, %6  : i32
      %39 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %40 = llvm.and %39, %0  : i64
      %41 = llvm.icmp "eq" %40, %1 : i64
      "llvm.intr.assume"(%41) : (i1) -> ()
      %42 = llvm.getelementptr %arg2[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %43 = llvm.load %42 : !llvm.ptr<1> -> f32
      %44 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %45 = llvm.and %44, %0  : i64
      %46 = llvm.icmp "eq" %45, %1 : i64
      "llvm.intr.assume"(%46) : (i1) -> ()
      %47 = llvm.getelementptr %arg2[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %48 = llvm.load %47 : !llvm.ptr<1> -> f32
      %49 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %50 = llvm.and %49, %0  : i64
      %51 = llvm.icmp "eq" %50, %1 : i64
      "llvm.intr.assume"(%51) : (i1) -> ()
      %52 = llvm.getelementptr %arg2[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %53 = llvm.load %52 : !llvm.ptr<1> -> f32
      %54 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %55 = llvm.and %54, %0  : i64
      %56 = llvm.icmp "eq" %55, %1 : i64
      "llvm.intr.assume"(%56) : (i1) -> ()
      %57 = llvm.getelementptr %arg2[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %58 = llvm.load %57 : !llvm.ptr<1> -> f32
      %59 = llvm.getelementptr %arg3[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %60 = llvm.load %59 : !llvm.ptr<1> -> f32
      %61 = llvm.getelementptr %arg3[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %62 = llvm.load %61 : !llvm.ptr<1> -> f32
      %63 = llvm.getelementptr %arg3[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %64 = llvm.load %63 : !llvm.ptr<1> -> f32
      %65 = llvm.getelementptr %arg3[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %66 = llvm.load %65 : !llvm.ptr<1> -> f32
      %67 = llvm.fadd %43, %60  : f32
      %68 = llvm.fadd %48, %62  : f32
      %69 = llvm.fadd %53, %64  : f32
      %70 = llvm.fadd %58, %66  : f32
      %71 = llvm.fcmp "ugt" %67, %7 : f32
      %72 = llvm.select %71, %67, %7 : i1, f32
      %73 = llvm.fcmp "ugt" %68, %7 : f32
      %74 = llvm.select %73, %68, %7 : i1, f32
      %75 = llvm.fcmp "ugt" %69, %7 : f32
      %76 = llvm.select %75, %69, %7 : i1, f32
      %77 = llvm.fcmp "ugt" %70, %7 : f32
      %78 = llvm.select %77, %70, %7 : i1, f32
      %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %80 = llvm.and %79, %0  : i64
      %81 = llvm.icmp "eq" %80, %1 : i64
      "llvm.intr.assume"(%81) : (i1) -> ()
      %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %72, %82 : f32, !llvm.ptr<1>
      %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %84 = llvm.and %83, %0  : i64
      %85 = llvm.icmp "eq" %84, %1 : i64
      "llvm.intr.assume"(%85) : (i1) -> ()
      %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %74, %86 : f32, !llvm.ptr<1>
      %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %88 = llvm.and %87, %0  : i64
      %89 = llvm.icmp "eq" %88, %1 : i64
      "llvm.intr.assume"(%89) : (i1) -> ()
      %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %76, %90 : f32, !llvm.ptr<1>
      %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %92 = llvm.and %91, %0  : i64
      %93 = llvm.icmp "eq" %92, %1 : i64
      "llvm.intr.assume"(%93) : (i1) -> ()
      %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %78, %94 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_0(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_0(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(10 : index) : i32
      %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %4 = nvvm.read.ptx.sreg.ctaid.x : i32
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %6 = llvm.mul %4, %arg0  : i32
      %7 = llvm.add %5, %6  : i32
      %8 = llvm.icmp "ult" %7, %arg1 : i32
      llvm.cond_br %8, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %9 = llvm.urem %7, %2  : i32
      %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %11 = llvm.and %10, %0  : i64
      %12 = llvm.icmp "eq" %11, %1 : i64
      "llvm.intr.assume"(%12) : (i1) -> ()
      %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %14 = llvm.load %13 : !llvm.ptr<1> -> f32
      %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %16 = llvm.load %15 : !llvm.ptr<1> -> f32
      %17 = llvm.fadd %14, %16  : f32
      %18 = llvm.fcmp "ugt" %17, %3 : f32
      %19 = llvm.select %18, %17, %3 : i1, f32
      %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %19, %20 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_1 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BD\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_1___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,\9F\02\00\22\00\01y\02\91global.v4\1A\040{%f\C4\00\10f\22\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\C5\02\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00\02\B6\02\03S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\01\C4\01\04U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00Zp\03\03\E0\00Sv\04\00\00\\p\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00Z\00\00\13p\00\10\C8\10\00\84\02\00\00\\\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 9 : index, 10 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(1 : index) : i32
      %3 = llvm.mlir.constant(4 : index) : i32
      %4 = llvm.mlir.constant(2 : index) : i32
      %5 = llvm.mlir.constant(3 : index) : i32
      %6 = llvm.mlir.constant(10 : index) : i32
      %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %14 = llvm.and %13, %0  : i64
      %15 = llvm.icmp "eq" %14, %1 : i64
      "llvm.intr.assume"(%15) : (i1) -> ()
      %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %17 = llvm.and %16, %0  : i64
      %18 = llvm.icmp "eq" %17, %1 : i64
      "llvm.intr.assume"(%18) : (i1) -> ()
      %19 = llvm.mul %11, %3  : i32
      %20 = llvm.add %19, %2  : i32
      %21 = llvm.add %19, %4  : i32
      %22 = llvm.add %19, %5  : i32
      %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %24 = llvm.and %23, %0  : i64
      %25 = llvm.icmp "eq" %24, %1 : i64
      "llvm.intr.assume"(%25) : (i1) -> ()
      %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %27 = llvm.and %26, %0  : i64
      %28 = llvm.icmp "eq" %27, %1 : i64
      "llvm.intr.assume"(%28) : (i1) -> ()
      %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %30 = llvm.and %29, %0  : i64
      %31 = llvm.icmp "eq" %30, %1 : i64
      "llvm.intr.assume"(%31) : (i1) -> ()
      %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %33 = llvm.and %32, %0  : i64
      %34 = llvm.icmp "eq" %33, %1 : i64
      "llvm.intr.assume"(%34) : (i1) -> ()
      %35 = llvm.urem %19, %6  : i32
      %36 = llvm.urem %20, %6  : i32
      %37 = llvm.urem %21, %6  : i32
      %38 = llvm.urem %22, %6  : i32
      %39 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %40 = llvm.and %39, %0  : i64
      %41 = llvm.icmp "eq" %40, %1 : i64
      "llvm.intr.assume"(%41) : (i1) -> ()
      %42 = llvm.getelementptr %arg3[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %43 = llvm.load %42 : !llvm.ptr<1> -> f32
      %44 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %45 = llvm.and %44, %0  : i64
      %46 = llvm.icmp "eq" %45, %1 : i64
      "llvm.intr.assume"(%46) : (i1) -> ()
      %47 = llvm.getelementptr %arg3[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %48 = llvm.load %47 : !llvm.ptr<1> -> f32
      %49 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %50 = llvm.and %49, %0  : i64
      %51 = llvm.icmp "eq" %50, %1 : i64
      "llvm.intr.assume"(%51) : (i1) -> ()
      %52 = llvm.getelementptr %arg3[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %53 = llvm.load %52 : !llvm.ptr<1> -> f32
      %54 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %55 = llvm.and %54, %0  : i64
      %56 = llvm.icmp "eq" %55, %1 : i64
      "llvm.intr.assume"(%56) : (i1) -> ()
      %57 = llvm.getelementptr %arg3[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %58 = llvm.load %57 : !llvm.ptr<1> -> f32
      %59 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %60 = llvm.load %59 : !llvm.ptr<1> -> f32
      %61 = llvm.getelementptr %arg2[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %62 = llvm.load %61 : !llvm.ptr<1> -> f32
      %63 = llvm.getelementptr %arg2[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %64 = llvm.load %63 : !llvm.ptr<1> -> f32
      %65 = llvm.getelementptr %arg2[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %66 = llvm.load %65 : !llvm.ptr<1> -> f32
      %67 = llvm.fadd %43, %60  : f32
      %68 = llvm.fadd %48, %62  : f32
      %69 = llvm.fadd %53, %64  : f32
      %70 = llvm.fadd %58, %66  : f32
      %71 = llvm.fcmp "ugt" %67, %7 : f32
      %72 = llvm.select %71, %67, %7 : i1, f32
      %73 = llvm.fcmp "ugt" %68, %7 : f32
      %74 = llvm.select %73, %68, %7 : i1, f32
      %75 = llvm.fcmp "ugt" %69, %7 : f32
      %76 = llvm.select %75, %69, %7 : i1, f32
      %77 = llvm.fcmp "ugt" %70, %7 : f32
      %78 = llvm.select %77, %70, %7 : i1, f32
      %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %80 = llvm.and %79, %0  : i64
      %81 = llvm.icmp "eq" %80, %1 : i64
      "llvm.intr.assume"(%81) : (i1) -> ()
      %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %72, %82 : f32, !llvm.ptr<1>
      %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %84 = llvm.and %83, %0  : i64
      %85 = llvm.icmp "eq" %84, %1 : i64
      "llvm.intr.assume"(%85) : (i1) -> ()
      %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %74, %86 : f32, !llvm.ptr<1>
      %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %88 = llvm.and %87, %0  : i64
      %89 = llvm.icmp "eq" %88, %1 : i64
      "llvm.intr.assume"(%89) : (i1) -> ()
      %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %76, %90 : f32, !llvm.ptr<1>
      %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %92 = llvm.and %91, %0  : i64
      %93 = llvm.icmp "eq" %92, %1 : i64
      "llvm.intr.assume"(%93) : (i1) -> ()
      %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %78, %94 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_2 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_1(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(10 : index) : i32
      %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %4 = nvvm.read.ptx.sreg.ctaid.x : i32
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %6 = llvm.mul %4, %arg0  : i32
      %7 = llvm.add %5, %6  : i32
      %8 = llvm.icmp "ult" %7, %arg1 : i32
      llvm.cond_br %8, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %9 = llvm.urem %7, %2  : i32
      %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %11 = llvm.and %10, %0  : i64
      %12 = llvm.icmp "eq" %11, %1 : i64
      "llvm.intr.assume"(%12) : (i1) -> ()
      %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %14 = llvm.load %13 : !llvm.ptr<1> -> f32
      %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %16 = llvm.load %15 : !llvm.ptr<1> -> f32
      %17 = llvm.fadd %14, %16  : f32
      %18 = llvm.fcmp "ugt" %17, %3 : f32
      %19 = llvm.select %18, %17, %3 : i1, f32
      %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %19, %20 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = true, knownNonSizeZero = true, sym_name = "C10", value = 10 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscStripShapeConstraintOpsPass (disc-strip-shape-constraint-ops) //----- //
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %c256 = arith.constant 256 : index
    %c3_i32 = arith.constant 3 : i32
    %c2_i32 = arith.constant 2 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %0 = llvm.mlir.constant(0 : i32) : i32
    %false = arith.constant false
    %true = arith.constant true
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x10xf32, #gpu.address_space<global>>
    %dim = memref.dim %1, %c0 : memref<?x10xf32, #gpu.address_space<global>>
    %2 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %3 = llvm.getelementptr %2[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %4 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %5 = "disc_ral.dispatch"(%arg0, %4, %3, %c0_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %6 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %7 = llvm.getelementptr %6[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %8 = "disc_ral.dispatch"(%arg0, %4, %7, %c1_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10x10xf32, #gpu.address_space<global>>
    %9 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %10 = llvm.getelementptr %9[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %11 = "disc_ral.dispatch"(%arg0, %4, %10, %c2_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %12 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %13 = llvm.getelementptr %12[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %14 = "disc_ral.dispatch"(%arg0, %4, %13, %c3_i32) {backend_config = "", call_target_name = "ral_const", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, !llvm.ptr<i8>, i32) -> memref<10xf32, #gpu.address_space<global>>
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, 10], strides: [10, 1] {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>> to memref<?x10xf32, #gpu.address_space<global>>
    %alloc = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %reinterpret_cast, %8, %alloc, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %8 : memref<10x10xf32, #gpu.address_space<global>>
    %15 = arith.muli %dim, %c10 : index
    %16 = arith.remui %15, %c4 : index
    %17 = arith.cmpi eq, %16, %c0 : index
    %alloc_0 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    cf.cond_br %17, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %18 = arith.divui %15, %c4 : index
    %c256_1 = arith.constant 256 : index
    %c0_2 = arith.constant 0 : index
    %c1_3 = arith.constant 1 : index
    %19 = arith.cmpi sle, %18, %c0_2 : index
    %20 = arith.subi %c0_2, %18 : index
    %21 = arith.subi %18, %c1_3 : index
    %22 = arith.select %19, %20, %21 : index
    %23 = arith.divsi %22, %c256_1 : index
    %24 = arith.subi %c0_2, %23 : index
    %25 = arith.addi %23, %c1_3 : index
    %26 = arith.select %19, %24, %25 : index
    gpu.launch_func  @main_kernel::@main_kLoop_maximum__5_1_0___Vec4 blocks in (%26, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %18 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    %c256_4 = arith.constant 256 : index
    %c0_5 = arith.constant 0 : index
    %c1_6 = arith.constant 1 : index
    %27 = arith.cmpi sle, %15, %c0_5 : index
    %28 = arith.subi %c0_5, %15 : index
    %29 = arith.subi %15, %c1_6 : index
    %30 = arith.select %27, %28, %29 : index
    %31 = arith.divsi %30, %c256_4 : index
    %32 = arith.subi %c0_5, %31 : index
    %33 = arith.addi %31, %c1_6 : index
    %34 = arith.select %27, %32, %33 : index
    gpu.launch_func  @main_kernel_0::@main_kLoop_maximum__5_1_0 blocks in (%34, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc : memref<?x10xf32, #gpu.address_space<global>>, %11 : memref<10xf32, #gpu.address_space<global>>, %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>)
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    memref.dealloc %alloc : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %11 : memref<10xf32, #gpu.address_space<global>>
    %alloc_7 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %4, %alloc_0, %5, %alloc_7, %false, %false, %true) {backend_config = "", call_target_name = "ral_gemm", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?x10xf32, #gpu.address_space<global>>, memref<10x10xf32, #gpu.address_space<global>>, memref<?x10xf32, #gpu.address_space<global>>, i1, i1, i1) -> ()
    memref.dealloc %alloc_0 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %5 : memref<10x10xf32, #gpu.address_space<global>>
    %alloc_8 = memref.alloc(%dim) {kDiscSymbolicDimAttr = [@S0, @C10]} : memref<?x10xf32, #gpu.address_space<global>>
    cf.cond_br %17, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %35 = arith.divui %15, %c4 : index
    %c256_9 = arith.constant 256 : index
    %c0_10 = arith.constant 0 : index
    %c1_11 = arith.constant 1 : index
    %36 = arith.cmpi sle, %35, %c0_10 : index
    %37 = arith.subi %c0_10, %35 : index
    %38 = arith.subi %35, %c1_11 : index
    %39 = arith.select %36, %37, %38 : index
    %40 = arith.divsi %39, %c256_9 : index
    %41 = arith.subi %c0_10, %40 : index
    %42 = arith.addi %40, %c1_11 : index
    %43 = arith.select %36, %41, %42 : index
    gpu.launch_func  @main_kernel_1::@main_kLoop_maximum__5_1_1___Vec4 blocks in (%43, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %35 : index, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>, %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>, %15 : index)
    cf.br ^bb6
  ^bb5:  // pred: ^bb3
    %c256_12 = arith.constant 256 : index
    %c0_13 = arith.constant 0 : index
    %c1_14 = arith.constant 1 : index
    %44 = arith.cmpi sle, %15, %c0_13 : index
    %45 = arith.subi %c0_13, %15 : index
    %46 = arith.subi %15, %c1_14 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c256_12 : index
    %49 = arith.subi %c0_13, %48 : index
    %50 = arith.addi %48, %c1_14 : index
    %51 = arith.select %44, %49, %50 : index
    gpu.launch_func  @main_kernel_2::@main_kLoop_maximum__5_1_1 blocks in (%51, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %15 : index, %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>, %14 : memref<10xf32, #gpu.address_space<global>>, %alloc_8 : memref<?x10xf32, #gpu.address_space<global>>)
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    memref.dealloc %alloc_7 : memref<?x10xf32, #gpu.address_space<global>>
    memref.dealloc %14 : memref<10xf32, #gpu.address_space<global>>
    "disc_ral.dispatch"(%arg0, %c0, %alloc_8) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x10xf32, #gpu.address_space<global>>) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BA\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_0___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,`\02\00\22\00\01y\02\91global.v4\1A\040{%f\1D\00\10f\AD\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\04\03\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00'11S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\183U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00\\p\03\03\E0\00Sv\04\00\00Zp\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00\\\00\00\13p\00\10\C8\10\00\84\02\00\00Z\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_0___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(1 : index) : i32
      %3 = llvm.mlir.constant(4 : index) : i32
      %4 = llvm.mlir.constant(2 : index) : i32
      %5 = llvm.mlir.constant(3 : index) : i32
      %6 = llvm.mlir.constant(10 : index) : i32
      %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %14 = llvm.and %13, %0  : i64
      %15 = llvm.icmp "eq" %14, %1 : i64
      "llvm.intr.assume"(%15) : (i1) -> ()
      %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %17 = llvm.and %16, %0  : i64
      %18 = llvm.icmp "eq" %17, %1 : i64
      "llvm.intr.assume"(%18) : (i1) -> ()
      %19 = llvm.mul %11, %3  : i32
      %20 = llvm.add %19, %2  : i32
      %21 = llvm.add %19, %4  : i32
      %22 = llvm.add %19, %5  : i32
      %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %24 = llvm.and %23, %0  : i64
      %25 = llvm.icmp "eq" %24, %1 : i64
      "llvm.intr.assume"(%25) : (i1) -> ()
      %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %27 = llvm.and %26, %0  : i64
      %28 = llvm.icmp "eq" %27, %1 : i64
      "llvm.intr.assume"(%28) : (i1) -> ()
      %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %30 = llvm.and %29, %0  : i64
      %31 = llvm.icmp "eq" %30, %1 : i64
      "llvm.intr.assume"(%31) : (i1) -> ()
      %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %33 = llvm.and %32, %0  : i64
      %34 = llvm.icmp "eq" %33, %1 : i64
      "llvm.intr.assume"(%34) : (i1) -> ()
      %35 = llvm.urem %19, %6  : i32
      %36 = llvm.urem %20, %6  : i32
      %37 = llvm.urem %21, %6  : i32
      %38 = llvm.urem %22, %6  : i32
      %39 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %40 = llvm.and %39, %0  : i64
      %41 = llvm.icmp "eq" %40, %1 : i64
      "llvm.intr.assume"(%41) : (i1) -> ()
      %42 = llvm.getelementptr %arg2[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %43 = llvm.load %42 : !llvm.ptr<1> -> f32
      %44 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %45 = llvm.and %44, %0  : i64
      %46 = llvm.icmp "eq" %45, %1 : i64
      "llvm.intr.assume"(%46) : (i1) -> ()
      %47 = llvm.getelementptr %arg2[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %48 = llvm.load %47 : !llvm.ptr<1> -> f32
      %49 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %50 = llvm.and %49, %0  : i64
      %51 = llvm.icmp "eq" %50, %1 : i64
      "llvm.intr.assume"(%51) : (i1) -> ()
      %52 = llvm.getelementptr %arg2[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %53 = llvm.load %52 : !llvm.ptr<1> -> f32
      %54 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %55 = llvm.and %54, %0  : i64
      %56 = llvm.icmp "eq" %55, %1 : i64
      "llvm.intr.assume"(%56) : (i1) -> ()
      %57 = llvm.getelementptr %arg2[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %58 = llvm.load %57 : !llvm.ptr<1> -> f32
      %59 = llvm.getelementptr %arg3[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %60 = llvm.load %59 : !llvm.ptr<1> -> f32
      %61 = llvm.getelementptr %arg3[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %62 = llvm.load %61 : !llvm.ptr<1> -> f32
      %63 = llvm.getelementptr %arg3[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %64 = llvm.load %63 : !llvm.ptr<1> -> f32
      %65 = llvm.getelementptr %arg3[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %66 = llvm.load %65 : !llvm.ptr<1> -> f32
      %67 = llvm.fadd %43, %60  : f32
      %68 = llvm.fadd %48, %62  : f32
      %69 = llvm.fadd %53, %64  : f32
      %70 = llvm.fadd %58, %66  : f32
      %71 = llvm.fcmp "ugt" %67, %7 : f32
      %72 = llvm.select %71, %67, %7 : i1, f32
      %73 = llvm.fcmp "ugt" %68, %7 : f32
      %74 = llvm.select %73, %68, %7 : i1, f32
      %75 = llvm.fcmp "ugt" %69, %7 : f32
      %76 = llvm.select %75, %69, %7 : i1, f32
      %77 = llvm.fcmp "ugt" %70, %7 : f32
      %78 = llvm.select %77, %70, %7 : i1, f32
      %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %80 = llvm.and %79, %0  : i64
      %81 = llvm.icmp "eq" %80, %1 : i64
      "llvm.intr.assume"(%81) : (i1) -> ()
      %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %72, %82 : f32, !llvm.ptr<1>
      %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %84 = llvm.and %83, %0  : i64
      %85 = llvm.icmp "eq" %84, %1 : i64
      "llvm.intr.assume"(%85) : (i1) -> ()
      %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %74, %86 : f32, !llvm.ptr<1>
      %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %88 = llvm.and %87, %0  : i64
      %89 = llvm.icmp "eq" %88, %1 : i64
      "llvm.intr.assume"(%89) : (i1) -> ()
      %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %76, %90 : f32, !llvm.ptr<1>
      %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %92 = llvm.and %91, %0  : i64
      %93 = llvm.icmp "eq" %92, %1 : i64
      "llvm.intr.assume"(%93) : (i1) -> ()
      %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %78, %94 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_0(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_0(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(10 : index) : i32
      %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %4 = nvvm.read.ptx.sreg.ctaid.x : i32
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %6 = llvm.mul %4, %arg0  : i32
      %7 = llvm.add %5, %6  : i32
      %8 = llvm.icmp "ult" %7, %arg1 : i32
      llvm.cond_br %8, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %9 = llvm.urem %7, %2  : i32
      %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %11 = llvm.and %10, %0  : i64
      %12 = llvm.icmp "eq" %11, %1 : i64
      "llvm.intr.assume"(%12) : (i1) -> ()
      %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %14 = llvm.load %13 : !llvm.ptr<1> -> f32
      %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %16 = llvm.load %15 : !llvm.ptr<1> -> f32
      %17 = llvm.fadd %14, %16  : f32
      %18 = llvm.fcmp "ugt" %17, %3 : f32
      %19 = llvm.select %18, %17, %3 : i1, f32
      %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %19, %20 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_1 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BD\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_1___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,\9F\02\00\22\00\01y\02\91global.v4\1A\040{%f\C4\00\10f\22\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\C5\02\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00\02\B6\02\03S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\01\C4\01\04U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00Zp\03\03\E0\00Sv\04\00\00\\p\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00Z\00\00\13p\00\10\C8\10\00\84\02\00\00\\\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_1___Vec4(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 9 : index, 10 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index, 21 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(1 : index) : i32
      %3 = llvm.mlir.constant(4 : index) : i32
      %4 = llvm.mlir.constant(2 : index) : i32
      %5 = llvm.mlir.constant(3 : index) : i32
      %6 = llvm.mlir.constant(10 : index) : i32
      %7 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %13 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %14 = llvm.and %13, %0  : i64
      %15 = llvm.icmp "eq" %14, %1 : i64
      "llvm.intr.assume"(%15) : (i1) -> ()
      %16 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %17 = llvm.and %16, %0  : i64
      %18 = llvm.icmp "eq" %17, %1 : i64
      "llvm.intr.assume"(%18) : (i1) -> ()
      %19 = llvm.mul %11, %3  : i32
      %20 = llvm.add %19, %2  : i32
      %21 = llvm.add %19, %4  : i32
      %22 = llvm.add %19, %5  : i32
      %23 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %24 = llvm.and %23, %0  : i64
      %25 = llvm.icmp "eq" %24, %1 : i64
      "llvm.intr.assume"(%25) : (i1) -> ()
      %26 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %27 = llvm.and %26, %0  : i64
      %28 = llvm.icmp "eq" %27, %1 : i64
      "llvm.intr.assume"(%28) : (i1) -> ()
      %29 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %30 = llvm.and %29, %0  : i64
      %31 = llvm.icmp "eq" %30, %1 : i64
      "llvm.intr.assume"(%31) : (i1) -> ()
      %32 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %33 = llvm.and %32, %0  : i64
      %34 = llvm.icmp "eq" %33, %1 : i64
      "llvm.intr.assume"(%34) : (i1) -> ()
      %35 = llvm.urem %19, %6  : i32
      %36 = llvm.urem %20, %6  : i32
      %37 = llvm.urem %21, %6  : i32
      %38 = llvm.urem %22, %6  : i32
      %39 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %40 = llvm.and %39, %0  : i64
      %41 = llvm.icmp "eq" %40, %1 : i64
      "llvm.intr.assume"(%41) : (i1) -> ()
      %42 = llvm.getelementptr %arg3[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %43 = llvm.load %42 : !llvm.ptr<1> -> f32
      %44 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %45 = llvm.and %44, %0  : i64
      %46 = llvm.icmp "eq" %45, %1 : i64
      "llvm.intr.assume"(%46) : (i1) -> ()
      %47 = llvm.getelementptr %arg3[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %48 = llvm.load %47 : !llvm.ptr<1> -> f32
      %49 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %50 = llvm.and %49, %0  : i64
      %51 = llvm.icmp "eq" %50, %1 : i64
      "llvm.intr.assume"(%51) : (i1) -> ()
      %52 = llvm.getelementptr %arg3[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %53 = llvm.load %52 : !llvm.ptr<1> -> f32
      %54 = llvm.ptrtoint %arg3 : !llvm.ptr<1> to i64
      %55 = llvm.and %54, %0  : i64
      %56 = llvm.icmp "eq" %55, %1 : i64
      "llvm.intr.assume"(%56) : (i1) -> ()
      %57 = llvm.getelementptr %arg3[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %58 = llvm.load %57 : !llvm.ptr<1> -> f32
      %59 = llvm.getelementptr %arg2[%35] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %60 = llvm.load %59 : !llvm.ptr<1> -> f32
      %61 = llvm.getelementptr %arg2[%36] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %62 = llvm.load %61 : !llvm.ptr<1> -> f32
      %63 = llvm.getelementptr %arg2[%37] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %64 = llvm.load %63 : !llvm.ptr<1> -> f32
      %65 = llvm.getelementptr %arg2[%38] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %66 = llvm.load %65 : !llvm.ptr<1> -> f32
      %67 = llvm.fadd %43, %60  : f32
      %68 = llvm.fadd %48, %62  : f32
      %69 = llvm.fadd %53, %64  : f32
      %70 = llvm.fadd %58, %66  : f32
      %71 = llvm.fcmp "ugt" %67, %7 : f32
      %72 = llvm.select %71, %67, %7 : i1, f32
      %73 = llvm.fcmp "ugt" %68, %7 : f32
      %74 = llvm.select %73, %68, %7 : i1, f32
      %75 = llvm.fcmp "ugt" %69, %7 : f32
      %76 = llvm.select %75, %69, %7 : i1, f32
      %77 = llvm.fcmp "ugt" %70, %7 : f32
      %78 = llvm.select %77, %70, %7 : i1, f32
      %79 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %80 = llvm.and %79, %0  : i64
      %81 = llvm.icmp "eq" %80, %1 : i64
      "llvm.intr.assume"(%81) : (i1) -> ()
      %82 = llvm.getelementptr %arg4[%19] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %72, %82 : f32, !llvm.ptr<1>
      %83 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %84 = llvm.and %83, %0  : i64
      %85 = llvm.icmp "eq" %84, %1 : i64
      "llvm.intr.assume"(%85) : (i1) -> ()
      %86 = llvm.getelementptr %arg4[%20] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %74, %86 : f32, !llvm.ptr<1>
      %87 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %88 = llvm.and %87, %0  : i64
      %89 = llvm.icmp "eq" %88, %1 : i64
      "llvm.intr.assume"(%89) : (i1) -> ()
      %90 = llvm.getelementptr %arg4[%21] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %76, %90 : f32, !llvm.ptr<1>
      %91 = llvm.ptrtoint %arg4 : !llvm.ptr<1> to i64
      %92 = llvm.and %91, %0  : i64
      %93 = llvm.icmp "eq" %92, %1 : i64
      "llvm.intr.assume"(%93) : (i1) -> ()
      %94 = llvm.getelementptr %arg4[%22] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %78, %94 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_2 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_1(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"} {
    llvm.func @main_kLoop_maximum__5_1_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<1>, %arg3: !llvm.ptr<1>, %arg4: !llvm.ptr<1>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 11 : index, 12 : index, 13 : index, 14 : index, 16 : index, 17 : index, 18 : index, 19 : index, 20 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(15 : index) : i64
      %1 = llvm.mlir.constant(0 : index) : i64
      %2 = llvm.mlir.constant(10 : index) : i32
      %3 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %4 = nvvm.read.ptx.sreg.ctaid.x : i32
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %6 = llvm.mul %4, %arg0  : i32
      %7 = llvm.add %5, %6  : i32
      %8 = llvm.icmp "ult" %7, %arg1 : i32
      llvm.cond_br %8, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %9 = llvm.urem %7, %2  : i32
      %10 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %11 = llvm.and %10, %0  : i64
      %12 = llvm.icmp "eq" %11, %1 : i64
      "llvm.intr.assume"(%12) : (i1) -> ()
      %13 = llvm.getelementptr %arg2[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %14 = llvm.load %13 : !llvm.ptr<1> -> f32
      %15 = llvm.getelementptr %arg3[%9] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      %16 = llvm.load %15 : !llvm.ptr<1> -> f32
      %17 = llvm.fadd %14, %16  : f32
      %18 = llvm.fcmp "ugt" %17, %3 : f32
      %19 = llvm.select %18, %17, %3 : i1, f32
      %20 = llvm.getelementptr %arg4[%7] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32
      llvm.store %19, %20 : f32, !llvm.ptr<1>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
}


// -----// IR Dump After DiscToLLVMPass (disc-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @main_kernel_0_main_kLoop_maximum__5_1_0_kernel_name("main_kLoop_maximum__5_1_0\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_blob_gpu.binary_sm_75("P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_blob_gpu.binary_sm_70("P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_blob_gpu.binary_compute_60("P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_0(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_2_main_kLoop_maximum__5_1_1_kernel_name("main_kLoop_maximum__5_1_1\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_2_blob_gpu.binary_sm_75("P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_2_blob_gpu.binary_sm_70("P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_2_blob_gpu.binary_compute_60("P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_1(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_send_output___cpu___pvoid_i64_m2df32___void("ral_send_output___cpu___pvoid_i64_m2df32___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_1_main_kLoop_maximum__5_1_1___Vec4_kernel_name("main_kLoop_maximum__5_1_1___Vec4\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_1_blob_gpu.binary_sm_75("P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00Z\00\00\13p\00\10\C8\10\00\84\02\00\00\\\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_1_blob_gpu.binary_sm_70("P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00Zp\03\03\E0\00Sv\04\00\00\\p\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_1_blob_gpu.binary_compute_60("P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BD\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_1___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,\9F\02\00\22\00\01y\02\91global.v4\1A\040{%f\C4\00\10f\22\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\C5\02\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00\02\B6\02\03S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\01\C4\01\04U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void("ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_main_kLoop_maximum__5_1_0___Vec4_kernel_name("main_kLoop_maximum__5_1_0___Vec4\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_blob_gpu.binary_sm_75("P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00\\\00\00\13p\00\10\C8\10\00\84\02\00\00Z\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_blob_gpu.binary_sm_70("P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00\\p\03\03\E0\00Sv\04\00\00Zp\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_blob_gpu.binary_compute_60("P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BA\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_0___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,`\02\00\22\00\01y\02\91global.v4\1A\040{%f\1D\00\10f\AD\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\04\03\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00'11S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\183U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @dealloc___gpu___pvoid_pvoid___void("dealloc___gpu___pvoid_pvoid___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void("ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @alloc___gpu___pvoid_i64___pvoid("alloc___gpu___pvoid_i64___pvoid\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32("ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32("ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_recv_input___cpu___pvoid_i64___m2df32("ral_recv_input___cpu___pvoid_i64___m2df32\00") {addr_space = 0 : i32}
  llvm.func @disc_ral_call(!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>)
  llvm.mlir.global internal constant @__global_const_3("3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_2("21438FB9F9F436186309DCC96AB50683_f32_10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_1("857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @__global_const_0("08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00") {addr_space = 0 : i32}
  llvm.func @main(%arg0: !llvm.ptr<i8>) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input.1_", output_placements = "gpu", outputs = "8"}} {
    %0 = llvm.mlir.constant(256 : index) : i64
    %1 = llvm.mlir.constant(3 : i32) : i32
    %2 = llvm.mlir.constant(2 : i32) : i32
    %3 = llvm.mlir.constant(1 : i32) : i32
    %4 = llvm.mlir.constant(0 : i32) : i32
    %5 = llvm.mlir.constant(0 : i32) : i32
    %6 = llvm.mlir.constant(false) : i1
    %7 = llvm.mlir.constant(true) : i1
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.mlir.constant(4 : index) : i64
    %10 = llvm.mlir.constant(10 : index) : i64
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.mlir.constant(0 : i32) : i32
    %13 = llvm.mlir.constant(1 : i32) : i32
    %14 = llvm.alloca %13 x !llvm.struct<"", (ptr<i8>, i64, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)> : (i32) -> !llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>
    %15 = llvm.mlir.constant(3 : i32) : i32
    %16 = llvm.alloca %15 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %17 = llvm.mlir.constant(0 : i32) : i32
    %18 = llvm.getelementptr %14[%12, 0] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %18 : !llvm.ptr<ptr<i8>>
    %19 = llvm.getelementptr %16[%17] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %20 = llvm.bitcast %18 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %20, %19 : !llvm.ptr<ptr<i8>>
    %21 = llvm.mlir.constant(1 : i32) : i32
    %22 = llvm.getelementptr %14[%12, 1] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %11, %22 : !llvm.ptr<i64>
    %23 = llvm.getelementptr %16[%21] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %24 = llvm.bitcast %22 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %24, %23 : !llvm.ptr<ptr<i8>>
    %25 = llvm.mlir.constant(2 : i32) : i32
    %26 = llvm.getelementptr %14[%12, 2] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>>
    %27 = llvm.getelementptr %16[%25] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %28 = llvm.bitcast %26 : !llvm.ptr<struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>> to !llvm.ptr<i8>
    llvm.store %28, %27 : !llvm.ptr<ptr<i8>>
    %29 = llvm.mlir.addressof @ral_recv_input___cpu___pvoid_i64___m2df32 : !llvm.ptr<array<42 x i8>>
    %30 = llvm.mlir.constant(0 : index) : i64
    %31 = llvm.getelementptr %29[%30, %30] : (!llvm.ptr<array<42 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %31, %16) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %32 = llvm.load %26 : !llvm.ptr<struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>>
    %33 = llvm.extractvalue %32[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %34 = llvm.mlir.addressof @__global_const_0 : !llvm.ptr<array<43 x i8>>
    %35 = llvm.getelementptr %34[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %36 = llvm.inttoptr %5 : i32 to !llvm.ptr<i8>
    %37 = llvm.mlir.constant(0 : i32) : i32
    %38 = llvm.mlir.constant(1 : i32) : i32
    %39 = llvm.alloca %38 x !llvm.struct<".1", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)> : (i32) -> !llvm.ptr<struct<".1", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>
    %40 = llvm.mlir.constant(5 : i32) : i32
    %41 = llvm.alloca %40 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %42 = llvm.mlir.constant(0 : i32) : i32
    %43 = llvm.getelementptr %39[%37, 0] : (!llvm.ptr<struct<".1", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %43 : !llvm.ptr<ptr<i8>>
    %44 = llvm.getelementptr %41[%42] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %45 = llvm.bitcast %43 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %45, %44 : !llvm.ptr<ptr<i8>>
    %46 = llvm.mlir.constant(1 : i32) : i32
    %47 = llvm.getelementptr %39[%37, 1] : (!llvm.ptr<struct<".1", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %36, %47 : !llvm.ptr<ptr<i8>>
    %48 = llvm.getelementptr %41[%46] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %49 = llvm.bitcast %47 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %49, %48 : !llvm.ptr<ptr<i8>>
    %50 = llvm.mlir.constant(2 : i32) : i32
    %51 = llvm.getelementptr %39[%37, 2] : (!llvm.ptr<struct<".1", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %35, %51 : !llvm.ptr<ptr<i8>>
    %52 = llvm.getelementptr %41[%50] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %53 = llvm.bitcast %51 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %53, %52 : !llvm.ptr<ptr<i8>>
    %54 = llvm.mlir.constant(3 : i32) : i32
    %55 = llvm.getelementptr %39[%37, 3] : (!llvm.ptr<struct<".1", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %4, %55 : !llvm.ptr<i32>
    %56 = llvm.getelementptr %41[%54] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %57 = llvm.bitcast %55 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %57, %56 : !llvm.ptr<ptr<i8>>
    %58 = llvm.mlir.constant(4 : i32) : i32
    %59 = llvm.getelementptr %39[%37, 4] : (!llvm.ptr<struct<".1", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>>
    %60 = llvm.getelementptr %41[%58] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %61 = llvm.bitcast %59 : !llvm.ptr<struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>> to !llvm.ptr<i8>
    llvm.store %61, %60 : !llvm.ptr<ptr<i8>>
    %62 = llvm.mlir.addressof @ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32 : !llvm.ptr<array<49 x i8>>
    %63 = llvm.mlir.constant(0 : index) : i64
    %64 = llvm.getelementptr %62[%63, %63] : (!llvm.ptr<array<49 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %64, %41) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %65 = llvm.load %59 : !llvm.ptr<struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>>
    %66 = llvm.mlir.addressof @__global_const_1 : !llvm.ptr<array<43 x i8>>
    %67 = llvm.getelementptr %66[0, 0] : (!llvm.ptr<array<43 x i8>>) -> !llvm.ptr<i8>
    %68 = llvm.mlir.constant(0 : i32) : i32
    %69 = llvm.mlir.constant(1 : i32) : i32
    %70 = llvm.alloca %69 x !llvm.struct<".2", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)> : (i32) -> !llvm.ptr<struct<".2", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>
    %71 = llvm.mlir.constant(5 : i32) : i32
    %72 = llvm.alloca %71 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %73 = llvm.mlir.constant(0 : i32) : i32
    %74 = llvm.getelementptr %70[%68, 0] : (!llvm.ptr<struct<".2", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %74 : !llvm.ptr<ptr<i8>>
    %75 = llvm.getelementptr %72[%73] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %76 = llvm.bitcast %74 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %76, %75 : !llvm.ptr<ptr<i8>>
    %77 = llvm.mlir.constant(1 : i32) : i32
    %78 = llvm.getelementptr %70[%68, 1] : (!llvm.ptr<struct<".2", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %36, %78 : !llvm.ptr<ptr<i8>>
    %79 = llvm.getelementptr %72[%77] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %80 = llvm.bitcast %78 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %80, %79 : !llvm.ptr<ptr<i8>>
    %81 = llvm.mlir.constant(2 : i32) : i32
    %82 = llvm.getelementptr %70[%68, 2] : (!llvm.ptr<struct<".2", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %67, %82 : !llvm.ptr<ptr<i8>>
    %83 = llvm.getelementptr %72[%81] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %84 = llvm.bitcast %82 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %84, %83 : !llvm.ptr<ptr<i8>>
    %85 = llvm.mlir.constant(3 : i32) : i32
    %86 = llvm.getelementptr %70[%68, 3] : (!llvm.ptr<struct<".2", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %3, %86 : !llvm.ptr<i32>
    %87 = llvm.getelementptr %72[%85] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %88 = llvm.bitcast %86 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %88, %87 : !llvm.ptr<ptr<i8>>
    %89 = llvm.mlir.constant(4 : i32) : i32
    %90 = llvm.getelementptr %70[%68, 4] : (!llvm.ptr<struct<".2", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>>
    %91 = llvm.getelementptr %72[%89] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %92 = llvm.bitcast %90 : !llvm.ptr<struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>> to !llvm.ptr<i8>
    llvm.store %92, %91 : !llvm.ptr<ptr<i8>>
    %93 = llvm.mlir.addressof @ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32 : !llvm.ptr<array<49 x i8>>
    %94 = llvm.mlir.constant(0 : index) : i64
    %95 = llvm.getelementptr %93[%94, %94] : (!llvm.ptr<array<49 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %95, %72) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %96 = llvm.load %90 : !llvm.ptr<struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>>
    %97 = llvm.mlir.addressof @__global_const_2 : !llvm.ptr<array<40 x i8>>
    %98 = llvm.getelementptr %97[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %99 = llvm.mlir.constant(0 : i32) : i32
    %100 = llvm.mlir.constant(1 : i32) : i32
    %101 = llvm.alloca %100 x !llvm.struct<".3", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)> : (i32) -> !llvm.ptr<struct<".3", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>
    %102 = llvm.mlir.constant(5 : i32) : i32
    %103 = llvm.alloca %102 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %104 = llvm.mlir.constant(0 : i32) : i32
    %105 = llvm.getelementptr %101[%99, 0] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %105 : !llvm.ptr<ptr<i8>>
    %106 = llvm.getelementptr %103[%104] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %107 = llvm.bitcast %105 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %107, %106 : !llvm.ptr<ptr<i8>>
    %108 = llvm.mlir.constant(1 : i32) : i32
    %109 = llvm.getelementptr %101[%99, 1] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %36, %109 : !llvm.ptr<ptr<i8>>
    %110 = llvm.getelementptr %103[%108] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %111 = llvm.bitcast %109 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %111, %110 : !llvm.ptr<ptr<i8>>
    %112 = llvm.mlir.constant(2 : i32) : i32
    %113 = llvm.getelementptr %101[%99, 2] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %98, %113 : !llvm.ptr<ptr<i8>>
    %114 = llvm.getelementptr %103[%112] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %115 = llvm.bitcast %113 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %115, %114 : !llvm.ptr<ptr<i8>>
    %116 = llvm.mlir.constant(3 : i32) : i32
    %117 = llvm.getelementptr %101[%99, 3] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %2, %117 : !llvm.ptr<i32>
    %118 = llvm.getelementptr %103[%116] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %119 = llvm.bitcast %117 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %119, %118 : !llvm.ptr<ptr<i8>>
    %120 = llvm.mlir.constant(4 : i32) : i32
    %121 = llvm.getelementptr %101[%99, 4] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>>
    %122 = llvm.getelementptr %103[%120] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %123 = llvm.bitcast %121 : !llvm.ptr<struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>> to !llvm.ptr<i8>
    llvm.store %123, %122 : !llvm.ptr<ptr<i8>>
    %124 = llvm.mlir.addressof @ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32 : !llvm.ptr<array<49 x i8>>
    %125 = llvm.mlir.constant(0 : index) : i64
    %126 = llvm.getelementptr %124[%125, %125] : (!llvm.ptr<array<49 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %126, %103) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %127 = llvm.load %121 : !llvm.ptr<struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>>
    %128 = llvm.mlir.addressof @__global_const_3 : !llvm.ptr<array<40 x i8>>
    %129 = llvm.getelementptr %128[0, 0] : (!llvm.ptr<array<40 x i8>>) -> !llvm.ptr<i8>
    %130 = llvm.mlir.constant(0 : i32) : i32
    %131 = llvm.mlir.constant(1 : i32) : i32
    %132 = llvm.alloca %131 x !llvm.struct<".4", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)> : (i32) -> !llvm.ptr<struct<".4", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>
    %133 = llvm.mlir.constant(5 : i32) : i32
    %134 = llvm.alloca %133 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %135 = llvm.mlir.constant(0 : i32) : i32
    %136 = llvm.getelementptr %132[%130, 0] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %136 : !llvm.ptr<ptr<i8>>
    %137 = llvm.getelementptr %134[%135] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %138 = llvm.bitcast %136 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %138, %137 : !llvm.ptr<ptr<i8>>
    %139 = llvm.mlir.constant(1 : i32) : i32
    %140 = llvm.getelementptr %132[%130, 1] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %36, %140 : !llvm.ptr<ptr<i8>>
    %141 = llvm.getelementptr %134[%139] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %142 = llvm.bitcast %140 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %142, %141 : !llvm.ptr<ptr<i8>>
    %143 = llvm.mlir.constant(2 : i32) : i32
    %144 = llvm.getelementptr %132[%130, 2] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %129, %144 : !llvm.ptr<ptr<i8>>
    %145 = llvm.getelementptr %134[%143] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %146 = llvm.bitcast %144 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %146, %145 : !llvm.ptr<ptr<i8>>
    %147 = llvm.mlir.constant(3 : i32) : i32
    %148 = llvm.getelementptr %132[%130, 3] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %1, %148 : !llvm.ptr<i32>
    %149 = llvm.getelementptr %134[%147] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %150 = llvm.bitcast %148 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %150, %149 : !llvm.ptr<ptr<i8>>
    %151 = llvm.mlir.constant(4 : i32) : i32
    %152 = llvm.getelementptr %132[%130, 4] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<i8>, ptr<i8>, i32, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>>
    %153 = llvm.getelementptr %134[%151] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %154 = llvm.bitcast %152 : !llvm.ptr<struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>> to !llvm.ptr<i8>
    llvm.store %154, %153 : !llvm.ptr<ptr<i8>>
    %155 = llvm.mlir.addressof @ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32 : !llvm.ptr<array<49 x i8>>
    %156 = llvm.mlir.constant(0 : index) : i64
    %157 = llvm.getelementptr %155[%156, %156] : (!llvm.ptr<array<49 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %157, %134) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %158 = llvm.load %152 : !llvm.ptr<struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>>
    %159 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %160 = llvm.extractvalue %32[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %161 = llvm.extractvalue %32[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %162 = llvm.insertvalue %160, %159[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %163 = llvm.insertvalue %161, %162[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %164 = llvm.mlir.constant(0 : index) : i64
    %165 = llvm.insertvalue %164, %163[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %166 = llvm.insertvalue %33, %165[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %167 = llvm.mlir.constant(10 : index) : i64
    %168 = llvm.insertvalue %167, %166[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %169 = llvm.mlir.constant(10 : index) : i64
    %170 = llvm.insertvalue %169, %168[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %171 = llvm.mlir.constant(1 : index) : i64
    %172 = llvm.insertvalue %171, %170[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %173 = llvm.mlir.constant(10 : index) : i64
    %174 = llvm.mlir.constant(1 : index) : i64
    %175 = llvm.mul %173, %33  : i64
    %176 = llvm.mlir.null : !llvm.ptr
    %177 = llvm.getelementptr %176[%175] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %178 = llvm.ptrtoint %177 : !llvm.ptr to i64
    %179 = llvm.mlir.constant(0 : i32) : i32
    %180 = llvm.mlir.constant(1 : i32) : i32
    %181 = llvm.alloca %180 x !llvm.struct<".5", (ptr<i8>, i64, ptr)> : (i32) -> !llvm.ptr<struct<".5", (ptr<i8>, i64, ptr)>>
    %182 = llvm.mlir.constant(3 : i32) : i32
    %183 = llvm.alloca %182 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %184 = llvm.mlir.constant(0 : i32) : i32
    %185 = llvm.getelementptr %181[%179, 0] : (!llvm.ptr<struct<".5", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %185 : !llvm.ptr<ptr<i8>>
    %186 = llvm.getelementptr %183[%184] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %187 = llvm.bitcast %185 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %187, %186 : !llvm.ptr<ptr<i8>>
    %188 = llvm.mlir.constant(1 : i32) : i32
    %189 = llvm.getelementptr %181[%179, 1] : (!llvm.ptr<struct<".5", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %178, %189 : !llvm.ptr<i64>
    %190 = llvm.getelementptr %183[%188] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %191 = llvm.bitcast %189 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %191, %190 : !llvm.ptr<ptr<i8>>
    %192 = llvm.mlir.constant(2 : i32) : i32
    %193 = llvm.getelementptr %181[%179, 2] : (!llvm.ptr<struct<".5", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<ptr>
    %194 = llvm.getelementptr %183[%192] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %195 = llvm.bitcast %193 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %195, %194 : !llvm.ptr<ptr<i8>>
    %196 = llvm.mlir.addressof @alloc___gpu___pvoid_i64___pvoid : !llvm.ptr<array<32 x i8>>
    %197 = llvm.mlir.constant(0 : index) : i64
    %198 = llvm.getelementptr %196[%197, %197] : (!llvm.ptr<array<32 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %198, %183) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %199 = llvm.load %193 : !llvm.ptr<ptr>
    %200 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %201 = llvm.bitcast %199 : !llvm.ptr to !llvm.ptr
    %202 = llvm.insertvalue %201, %200[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %203 = llvm.insertvalue %201, %202[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %204 = llvm.mlir.constant(0 : index) : i64
    %205 = llvm.insertvalue %204, %203[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %206 = llvm.mlir.constant(1 : index) : i64
    %207 = llvm.insertvalue %173, %205[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %208 = llvm.insertvalue %206, %207[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %209 = llvm.mul %206, %173  : i64
    %210 = llvm.insertvalue %33, %208[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %211 = llvm.insertvalue %209, %210[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %212 = llvm.mlir.constant(0 : i32) : i32
    %213 = llvm.mlir.constant(1 : i32) : i32
    %214 = llvm.extractvalue %172[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %215 = llvm.extractvalue %172[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %216 = llvm.extractvalue %172[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %217 = llvm.extractvalue %172[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %218 = llvm.extractvalue %172[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %219 = llvm.extractvalue %172[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %220 = llvm.extractvalue %172[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %221 = llvm.extractvalue %96[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %222 = llvm.extractvalue %96[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %223 = llvm.extractvalue %96[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %224 = llvm.extractvalue %96[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %225 = llvm.extractvalue %96[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %226 = llvm.extractvalue %96[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %227 = llvm.extractvalue %96[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %228 = llvm.extractvalue %211[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %229 = llvm.extractvalue %211[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %230 = llvm.extractvalue %211[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %231 = llvm.extractvalue %211[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %232 = llvm.extractvalue %211[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %233 = llvm.extractvalue %211[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %234 = llvm.extractvalue %211[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %235 = llvm.alloca %213 x !llvm.struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)> : (i32) -> !llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>
    %236 = llvm.mlir.constant(26 : i32) : i32
    %237 = llvm.alloca %236 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %238 = llvm.mlir.constant(0 : i32) : i32
    %239 = llvm.getelementptr %235[%212, 0] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %239 : !llvm.ptr<ptr<i8>>
    %240 = llvm.getelementptr %237[%238] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %241 = llvm.bitcast %239 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %241, %240 : !llvm.ptr<ptr<i8>>
    %242 = llvm.mlir.constant(1 : i32) : i32
    %243 = llvm.getelementptr %235[%212, 1] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %36, %243 : !llvm.ptr<ptr<i8>>
    %244 = llvm.getelementptr %237[%242] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %245 = llvm.bitcast %243 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %245, %244 : !llvm.ptr<ptr<i8>>
    %246 = llvm.mlir.constant(2 : i32) : i32
    %247 = llvm.getelementptr %235[%212, 2] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %214, %247 : !llvm.ptr<ptr>
    %248 = llvm.getelementptr %237[%246] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %249 = llvm.bitcast %247 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %249, %248 : !llvm.ptr<ptr<i8>>
    %250 = llvm.mlir.constant(3 : i32) : i32
    %251 = llvm.getelementptr %235[%212, 3] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %215, %251 : !llvm.ptr<ptr>
    %252 = llvm.getelementptr %237[%250] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %253 = llvm.bitcast %251 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %253, %252 : !llvm.ptr<ptr<i8>>
    %254 = llvm.mlir.constant(4 : i32) : i32
    %255 = llvm.getelementptr %235[%212, 4] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %216, %255 : !llvm.ptr<i64>
    %256 = llvm.getelementptr %237[%254] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %257 = llvm.bitcast %255 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %257, %256 : !llvm.ptr<ptr<i8>>
    %258 = llvm.mlir.constant(5 : i32) : i32
    %259 = llvm.getelementptr %235[%212, 5] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %217, %259 : !llvm.ptr<i64>
    %260 = llvm.getelementptr %237[%258] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %261 = llvm.bitcast %259 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %261, %260 : !llvm.ptr<ptr<i8>>
    %262 = llvm.mlir.constant(6 : i32) : i32
    %263 = llvm.getelementptr %235[%212, 6] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %218, %263 : !llvm.ptr<i64>
    %264 = llvm.getelementptr %237[%262] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %265 = llvm.bitcast %263 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %265, %264 : !llvm.ptr<ptr<i8>>
    %266 = llvm.mlir.constant(7 : i32) : i32
    %267 = llvm.getelementptr %235[%212, 7] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %219, %267 : !llvm.ptr<i64>
    %268 = llvm.getelementptr %237[%266] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %269 = llvm.bitcast %267 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %269, %268 : !llvm.ptr<ptr<i8>>
    %270 = llvm.mlir.constant(8 : i32) : i32
    %271 = llvm.getelementptr %235[%212, 8] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %220, %271 : !llvm.ptr<i64>
    %272 = llvm.getelementptr %237[%270] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %273 = llvm.bitcast %271 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %273, %272 : !llvm.ptr<ptr<i8>>
    %274 = llvm.mlir.constant(9 : i32) : i32
    %275 = llvm.getelementptr %235[%212, 9] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %221, %275 : !llvm.ptr<ptr>
    %276 = llvm.getelementptr %237[%274] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %277 = llvm.bitcast %275 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %277, %276 : !llvm.ptr<ptr<i8>>
    %278 = llvm.mlir.constant(10 : i32) : i32
    %279 = llvm.getelementptr %235[%212, 10] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %222, %279 : !llvm.ptr<ptr>
    %280 = llvm.getelementptr %237[%278] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %281 = llvm.bitcast %279 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %281, %280 : !llvm.ptr<ptr<i8>>
    %282 = llvm.mlir.constant(11 : i32) : i32
    %283 = llvm.getelementptr %235[%212, 11] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %223, %283 : !llvm.ptr<i64>
    %284 = llvm.getelementptr %237[%282] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %285 = llvm.bitcast %283 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %285, %284 : !llvm.ptr<ptr<i8>>
    %286 = llvm.mlir.constant(12 : i32) : i32
    %287 = llvm.getelementptr %235[%212, 12] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %224, %287 : !llvm.ptr<i64>
    %288 = llvm.getelementptr %237[%286] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %289 = llvm.bitcast %287 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %289, %288 : !llvm.ptr<ptr<i8>>
    %290 = llvm.mlir.constant(13 : i32) : i32
    %291 = llvm.getelementptr %235[%212, 13] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %225, %291 : !llvm.ptr<i64>
    %292 = llvm.getelementptr %237[%290] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %293 = llvm.bitcast %291 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %293, %292 : !llvm.ptr<ptr<i8>>
    %294 = llvm.mlir.constant(14 : i32) : i32
    %295 = llvm.getelementptr %235[%212, 14] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %226, %295 : !llvm.ptr<i64>
    %296 = llvm.getelementptr %237[%294] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %297 = llvm.bitcast %295 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %297, %296 : !llvm.ptr<ptr<i8>>
    %298 = llvm.mlir.constant(15 : i32) : i32
    %299 = llvm.getelementptr %235[%212, 15] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %227, %299 : !llvm.ptr<i64>
    %300 = llvm.getelementptr %237[%298] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %301 = llvm.bitcast %299 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %301, %300 : !llvm.ptr<ptr<i8>>
    %302 = llvm.mlir.constant(16 : i32) : i32
    %303 = llvm.getelementptr %235[%212, 16] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %228, %303 : !llvm.ptr<ptr>
    %304 = llvm.getelementptr %237[%302] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %305 = llvm.bitcast %303 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %305, %304 : !llvm.ptr<ptr<i8>>
    %306 = llvm.mlir.constant(17 : i32) : i32
    %307 = llvm.getelementptr %235[%212, 17] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %229, %307 : !llvm.ptr<ptr>
    %308 = llvm.getelementptr %237[%306] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %309 = llvm.bitcast %307 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %309, %308 : !llvm.ptr<ptr<i8>>
    %310 = llvm.mlir.constant(18 : i32) : i32
    %311 = llvm.getelementptr %235[%212, 18] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %230, %311 : !llvm.ptr<i64>
    %312 = llvm.getelementptr %237[%310] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %313 = llvm.bitcast %311 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %313, %312 : !llvm.ptr<ptr<i8>>
    %314 = llvm.mlir.constant(19 : i32) : i32
    %315 = llvm.getelementptr %235[%212, 19] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %231, %315 : !llvm.ptr<i64>
    %316 = llvm.getelementptr %237[%314] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %317 = llvm.bitcast %315 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %317, %316 : !llvm.ptr<ptr<i8>>
    %318 = llvm.mlir.constant(20 : i32) : i32
    %319 = llvm.getelementptr %235[%212, 20] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %232, %319 : !llvm.ptr<i64>
    %320 = llvm.getelementptr %237[%318] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %321 = llvm.bitcast %319 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %321, %320 : !llvm.ptr<ptr<i8>>
    %322 = llvm.mlir.constant(21 : i32) : i32
    %323 = llvm.getelementptr %235[%212, 21] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %233, %323 : !llvm.ptr<i64>
    %324 = llvm.getelementptr %237[%322] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %325 = llvm.bitcast %323 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %325, %324 : !llvm.ptr<ptr<i8>>
    %326 = llvm.mlir.constant(22 : i32) : i32
    %327 = llvm.getelementptr %235[%212, 22] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %234, %327 : !llvm.ptr<i64>
    %328 = llvm.getelementptr %237[%326] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %329 = llvm.bitcast %327 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %329, %328 : !llvm.ptr<ptr<i8>>
    %330 = llvm.mlir.constant(23 : i32) : i32
    %331 = llvm.getelementptr %235[%212, 23] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i1>
    llvm.store %6, %331 : !llvm.ptr<i1>
    %332 = llvm.getelementptr %237[%330] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %333 = llvm.bitcast %331 : !llvm.ptr<i1> to !llvm.ptr<i8>
    llvm.store %333, %332 : !llvm.ptr<ptr<i8>>
    %334 = llvm.mlir.constant(24 : i32) : i32
    %335 = llvm.getelementptr %235[%212, 24] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i1>
    llvm.store %6, %335 : !llvm.ptr<i1>
    %336 = llvm.getelementptr %237[%334] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %337 = llvm.bitcast %335 : !llvm.ptr<i1> to !llvm.ptr<i8>
    llvm.store %337, %336 : !llvm.ptr<ptr<i8>>
    %338 = llvm.mlir.constant(25 : i32) : i32
    %339 = llvm.getelementptr %235[%212, 25] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i1>
    llvm.store %7, %339 : !llvm.ptr<i1>
    %340 = llvm.getelementptr %237[%338] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %341 = llvm.bitcast %339 : !llvm.ptr<i1> to !llvm.ptr<i8>
    llvm.store %341, %340 : !llvm.ptr<ptr<i8>>
    %342 = llvm.mlir.addressof @ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void : !llvm.ptr<array<66 x i8>>
    %343 = llvm.mlir.constant(0 : index) : i64
    %344 = llvm.getelementptr %342[%343, %343] : (!llvm.ptr<array<66 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %344, %237) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %345 = llvm.extractvalue %96[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %346 = llvm.bitcast %345 : !llvm.ptr to !llvm.ptr
    %347 = llvm.mlir.constant(0 : i32) : i32
    %348 = llvm.mlir.constant(1 : i32) : i32
    %349 = llvm.alloca %348 x !llvm.struct<".7", (ptr<i8>, ptr)> : (i32) -> !llvm.ptr<struct<".7", (ptr<i8>, ptr)>>
    %350 = llvm.mlir.constant(2 : i32) : i32
    %351 = llvm.alloca %350 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %352 = llvm.mlir.constant(0 : i32) : i32
    %353 = llvm.getelementptr %349[%347, 0] : (!llvm.ptr<struct<".7", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %353 : !llvm.ptr<ptr<i8>>
    %354 = llvm.getelementptr %351[%352] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %355 = llvm.bitcast %353 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %355, %354 : !llvm.ptr<ptr<i8>>
    %356 = llvm.mlir.constant(1 : i32) : i32
    %357 = llvm.getelementptr %349[%347, 1] : (!llvm.ptr<struct<".7", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %346, %357 : !llvm.ptr<ptr>
    %358 = llvm.getelementptr %351[%356] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %359 = llvm.bitcast %357 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %359, %358 : !llvm.ptr<ptr<i8>>
    %360 = llvm.mlir.addressof @dealloc___gpu___pvoid_pvoid___void : !llvm.ptr<array<35 x i8>>
    %361 = llvm.mlir.constant(0 : index) : i64
    %362 = llvm.getelementptr %360[%361, %361] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %362, %351) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %363 = llvm.mul %33, %10  : i64
    %364 = llvm.urem %363, %9  : i64
    %365 = llvm.icmp "eq" %364, %11 : i64
    %366 = llvm.mlir.constant(10 : index) : i64
    %367 = llvm.mlir.constant(1 : index) : i64
    %368 = llvm.mul %366, %33  : i64
    %369 = llvm.mlir.null : !llvm.ptr
    %370 = llvm.getelementptr %369[%368] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %371 = llvm.ptrtoint %370 : !llvm.ptr to i64
    %372 = llvm.mlir.constant(0 : i32) : i32
    %373 = llvm.mlir.constant(1 : i32) : i32
    %374 = llvm.alloca %373 x !llvm.struct<".8", (ptr<i8>, i64, ptr)> : (i32) -> !llvm.ptr<struct<".8", (ptr<i8>, i64, ptr)>>
    %375 = llvm.mlir.constant(3 : i32) : i32
    %376 = llvm.alloca %375 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %377 = llvm.mlir.constant(0 : i32) : i32
    %378 = llvm.getelementptr %374[%372, 0] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %378 : !llvm.ptr<ptr<i8>>
    %379 = llvm.getelementptr %376[%377] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %380 = llvm.bitcast %378 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %380, %379 : !llvm.ptr<ptr<i8>>
    %381 = llvm.mlir.constant(1 : i32) : i32
    %382 = llvm.getelementptr %374[%372, 1] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %371, %382 : !llvm.ptr<i64>
    %383 = llvm.getelementptr %376[%381] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %384 = llvm.bitcast %382 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %384, %383 : !llvm.ptr<ptr<i8>>
    %385 = llvm.mlir.constant(2 : i32) : i32
    %386 = llvm.getelementptr %374[%372, 2] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<ptr>
    %387 = llvm.getelementptr %376[%385] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %388 = llvm.bitcast %386 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %388, %387 : !llvm.ptr<ptr<i8>>
    %389 = llvm.mlir.addressof @alloc___gpu___pvoid_i64___pvoid : !llvm.ptr<array<32 x i8>>
    %390 = llvm.mlir.constant(0 : index) : i64
    %391 = llvm.getelementptr %389[%390, %390] : (!llvm.ptr<array<32 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %391, %376) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %392 = llvm.load %386 : !llvm.ptr<ptr>
    %393 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %394 = llvm.bitcast %392 : !llvm.ptr to !llvm.ptr
    %395 = llvm.insertvalue %394, %393[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %396 = llvm.insertvalue %394, %395[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %397 = llvm.mlir.constant(0 : index) : i64
    %398 = llvm.insertvalue %397, %396[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %399 = llvm.mlir.constant(1 : index) : i64
    %400 = llvm.insertvalue %366, %398[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %401 = llvm.insertvalue %399, %400[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %402 = llvm.mul %399, %366  : i64
    %403 = llvm.insertvalue %33, %401[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %404 = llvm.insertvalue %402, %403[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.cond_br %365, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %405 = llvm.udiv %363, %9  : i64
    %406 = llvm.icmp "sle" %405, %11 : i64
    %407 = llvm.sub %11, %405  : i64
    %408 = llvm.sub %405, %8  : i64
    %409 = llvm.select %406, %407, %408 : i1, i64
    %410 = llvm.sdiv %409, %0  : i64
    %411 = llvm.sub %11, %410  : i64
    %412 = llvm.add %410, %8  : i64
    %413 = llvm.select %406, %411, %412 : i1, i64
    %414 = llvm.mlir.addressof @main_kernel_blob_gpu.binary_compute_60 : !llvm.ptr<array<1048 x i8>>
    %415 = llvm.mlir.constant(0 : index) : i64
    %416 = llvm.getelementptr %414[%415, %415] : (!llvm.ptr<array<1048 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %417 = llvm.mlir.addressof @main_kernel_blob_gpu.binary_sm_70 : !llvm.ptr<array<1512 x i8>>
    %418 = llvm.mlir.constant(0 : index) : i64
    %419 = llvm.getelementptr %417[%418, %418] : (!llvm.ptr<array<1512 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %420 = llvm.mlir.addressof @main_kernel_blob_gpu.binary_sm_75 : !llvm.ptr<array<1472 x i8>>
    %421 = llvm.mlir.constant(0 : index) : i64
    %422 = llvm.getelementptr %420[%421, %421] : (!llvm.ptr<array<1472 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %423 = llvm.mlir.constant(3 : i32) : i32
    %424 = llvm.alloca %423 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %425 = llvm.mlir.constant(0 : i32) : i32
    %426 = llvm.getelementptr %424[%425] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %416, %426 : !llvm.ptr<ptr<i8>>
    %427 = llvm.mlir.constant(1 : i32) : i32
    %428 = llvm.getelementptr %424[%427] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %419, %428 : !llvm.ptr<ptr<i8>>
    %429 = llvm.mlir.constant(2 : i32) : i32
    %430 = llvm.getelementptr %424[%429] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %422, %430 : !llvm.ptr<ptr<i8>>
    %431 = llvm.mlir.constant(3 : i64) : i64
    %432 = llvm.mlir.addressof @main_kernel_main_kLoop_maximum__5_1_0___Vec4_kernel_name : !llvm.ptr<array<33 x i8>>
    %433 = llvm.mlir.constant(0 : index) : i64
    %434 = llvm.getelementptr %432[%433, %433] : (!llvm.ptr<array<33 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %435 = llvm.extractvalue %211[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %436 = llvm.extractvalue %211[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %437 = llvm.extractvalue %211[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %438 = llvm.extractvalue %211[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %439 = llvm.extractvalue %211[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %440 = llvm.extractvalue %211[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %441 = llvm.extractvalue %211[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %442 = llvm.extractvalue %127[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %443 = llvm.extractvalue %127[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %444 = llvm.extractvalue %127[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %445 = llvm.extractvalue %127[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %446 = llvm.extractvalue %127[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %447 = llvm.extractvalue %404[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %448 = llvm.extractvalue %404[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %449 = llvm.extractvalue %404[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %450 = llvm.extractvalue %404[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %451 = llvm.extractvalue %404[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %452 = llvm.extractvalue %404[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %453 = llvm.extractvalue %404[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %454 = llvm.mlir.constant(1 : i32) : i32
    %455 = llvm.alloca %454 x !llvm.struct<".9", (i64, i64, ptr, ptr, ptr)> : (i32) -> !llvm.ptr<struct<".9", (i64, i64, ptr, ptr, ptr)>>
    %456 = llvm.mlir.constant(5 : i32) : i32
    %457 = llvm.alloca %456 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %458 = llvm.mlir.constant(0 : i32) : i32
    %459 = llvm.mlir.constant(0 : i32) : i32
    %460 = llvm.getelementptr %455[%458, 0] : (!llvm.ptr<struct<".9", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %460 : !llvm.ptr<i64>
    %461 = llvm.getelementptr %457[%459] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %462 = llvm.bitcast %460 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %462, %461 : !llvm.ptr<ptr<i8>>
    %463 = llvm.mlir.constant(1 : i32) : i32
    %464 = llvm.getelementptr %455[%458, 1] : (!llvm.ptr<struct<".9", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %405, %464 : !llvm.ptr<i64>
    %465 = llvm.getelementptr %457[%463] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %466 = llvm.bitcast %464 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %466, %465 : !llvm.ptr<ptr<i8>>
    %467 = llvm.mlir.constant(2 : i32) : i32
    %468 = llvm.getelementptr %455[%458, 2] : (!llvm.ptr<struct<".9", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %436, %468 : !llvm.ptr<ptr>
    %469 = llvm.getelementptr %457[%467] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %470 = llvm.bitcast %468 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %470, %469 : !llvm.ptr<ptr<i8>>
    %471 = llvm.mlir.constant(3 : i32) : i32
    %472 = llvm.getelementptr %455[%458, 3] : (!llvm.ptr<struct<".9", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %443, %472 : !llvm.ptr<ptr>
    %473 = llvm.getelementptr %457[%471] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %474 = llvm.bitcast %472 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %474, %473 : !llvm.ptr<ptr<i8>>
    %475 = llvm.mlir.constant(4 : i32) : i32
    %476 = llvm.getelementptr %455[%458, 4] : (!llvm.ptr<struct<".9", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %448, %476 : !llvm.ptr<ptr>
    %477 = llvm.getelementptr %457[%475] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %478 = llvm.bitcast %476 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %478, %477 : !llvm.ptr<ptr<i8>>
    %479 = llvm.mlir.constant(0 : i32) : i32
    %480 = llvm.mlir.constant(5 : i32) : i32
    %481 = llvm.inttoptr %479 : i32 to !llvm.ptr<i8>
    %482 = llvm.mlir.constant(0 : i32) : i32
    %483 = llvm.mlir.constant(1 : i32) : i32
    %484 = llvm.alloca %483 x !llvm.struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %485 = llvm.mlir.constant(14 : i32) : i32
    %486 = llvm.alloca %485 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %487 = llvm.mlir.constant(0 : i32) : i32
    %488 = llvm.getelementptr %484[%482, 0] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %488 : !llvm.ptr<ptr<i8>>
    %489 = llvm.getelementptr %486[%487] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %490 = llvm.bitcast %488 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %490, %489 : !llvm.ptr<ptr<i8>>
    %491 = llvm.mlir.constant(1 : i32) : i32
    %492 = llvm.getelementptr %484[%482, 1] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %424, %492 : !llvm.ptr<ptr<ptr<i8>>>
    %493 = llvm.getelementptr %486[%491] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %494 = llvm.bitcast %492 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %494, %493 : !llvm.ptr<ptr<i8>>
    %495 = llvm.mlir.constant(2 : i32) : i32
    %496 = llvm.getelementptr %484[%482, 2] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %431, %496 : !llvm.ptr<i64>
    %497 = llvm.getelementptr %486[%495] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %498 = llvm.bitcast %496 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %498, %497 : !llvm.ptr<ptr<i8>>
    %499 = llvm.mlir.constant(3 : i32) : i32
    %500 = llvm.getelementptr %484[%482, 3] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %434, %500 : !llvm.ptr<ptr<i8>>
    %501 = llvm.getelementptr %486[%499] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %502 = llvm.bitcast %500 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %502, %501 : !llvm.ptr<ptr<i8>>
    %503 = llvm.mlir.constant(4 : i32) : i32
    %504 = llvm.getelementptr %484[%482, 4] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %413, %504 : !llvm.ptr<i64>
    %505 = llvm.getelementptr %486[%503] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %506 = llvm.bitcast %504 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %506, %505 : !llvm.ptr<ptr<i8>>
    %507 = llvm.mlir.constant(5 : i32) : i32
    %508 = llvm.getelementptr %484[%482, 5] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %508 : !llvm.ptr<i64>
    %509 = llvm.getelementptr %486[%507] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %510 = llvm.bitcast %508 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %510, %509 : !llvm.ptr<ptr<i8>>
    %511 = llvm.mlir.constant(6 : i32) : i32
    %512 = llvm.getelementptr %484[%482, 6] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %512 : !llvm.ptr<i64>
    %513 = llvm.getelementptr %486[%511] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %514 = llvm.bitcast %512 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %514, %513 : !llvm.ptr<ptr<i8>>
    %515 = llvm.mlir.constant(7 : i32) : i32
    %516 = llvm.getelementptr %484[%482, 7] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %516 : !llvm.ptr<i64>
    %517 = llvm.getelementptr %486[%515] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %518 = llvm.bitcast %516 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %518, %517 : !llvm.ptr<ptr<i8>>
    %519 = llvm.mlir.constant(8 : i32) : i32
    %520 = llvm.getelementptr %484[%482, 8] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %520 : !llvm.ptr<i64>
    %521 = llvm.getelementptr %486[%519] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %522 = llvm.bitcast %520 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %522, %521 : !llvm.ptr<ptr<i8>>
    %523 = llvm.mlir.constant(9 : i32) : i32
    %524 = llvm.getelementptr %484[%482, 9] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %524 : !llvm.ptr<i64>
    %525 = llvm.getelementptr %486[%523] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %526 = llvm.bitcast %524 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %526, %525 : !llvm.ptr<ptr<i8>>
    %527 = llvm.mlir.constant(10 : i32) : i32
    %528 = llvm.getelementptr %484[%482, 10] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %479, %528 : !llvm.ptr<i32>
    %529 = llvm.getelementptr %486[%527] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %530 = llvm.bitcast %528 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %530, %529 : !llvm.ptr<ptr<i8>>
    %531 = llvm.mlir.constant(11 : i32) : i32
    %532 = llvm.getelementptr %484[%482, 11] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %481, %532 : !llvm.ptr<ptr<i8>>
    %533 = llvm.getelementptr %486[%531] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %534 = llvm.bitcast %532 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %534, %533 : !llvm.ptr<ptr<i8>>
    %535 = llvm.mlir.constant(12 : i32) : i32
    %536 = llvm.getelementptr %484[%482, 12] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %480, %536 : !llvm.ptr<i32>
    %537 = llvm.getelementptr %486[%535] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %538 = llvm.bitcast %536 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %538, %537 : !llvm.ptr<ptr<i8>>
    %539 = llvm.mlir.constant(13 : i32) : i32
    %540 = llvm.getelementptr %484[%482, 13] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %457, %540 : !llvm.ptr<ptr<ptr<i8>>>
    %541 = llvm.getelementptr %486[%539] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %542 = llvm.bitcast %540 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %542, %541 : !llvm.ptr<ptr<i8>>
    %543 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %544 = llvm.mlir.constant(0 : index) : i64
    %545 = llvm.getelementptr %543[%544, %544] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %545, %486) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.br ^bb3
  ^bb2:  // pred: ^bb0
    %546 = llvm.icmp "sle" %363, %11 : i64
    %547 = llvm.sub %11, %363  : i64
    %548 = llvm.sub %363, %8  : i64
    %549 = llvm.select %546, %547, %548 : i1, i64
    %550 = llvm.sdiv %549, %0  : i64
    %551 = llvm.sub %11, %550  : i64
    %552 = llvm.add %550, %8  : i64
    %553 = llvm.select %546, %551, %552 : i1, i64
    %554 = llvm.mlir.addressof @main_kernel_0_blob_gpu.binary_compute_60 : !llvm.ptr<array<688 x i8>>
    %555 = llvm.mlir.constant(0 : index) : i64
    %556 = llvm.getelementptr %554[%555, %555] : (!llvm.ptr<array<688 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %557 = llvm.mlir.addressof @main_kernel_0_blob_gpu.binary_sm_70 : !llvm.ptr<array<1216 x i8>>
    %558 = llvm.mlir.constant(0 : index) : i64
    %559 = llvm.getelementptr %557[%558, %558] : (!llvm.ptr<array<1216 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %560 = llvm.mlir.addressof @main_kernel_0_blob_gpu.binary_sm_75 : !llvm.ptr<array<1200 x i8>>
    %561 = llvm.mlir.constant(0 : index) : i64
    %562 = llvm.getelementptr %560[%561, %561] : (!llvm.ptr<array<1200 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %563 = llvm.mlir.constant(3 : i32) : i32
    %564 = llvm.alloca %563 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %565 = llvm.mlir.constant(0 : i32) : i32
    %566 = llvm.getelementptr %564[%565] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %556, %566 : !llvm.ptr<ptr<i8>>
    %567 = llvm.mlir.constant(1 : i32) : i32
    %568 = llvm.getelementptr %564[%567] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %559, %568 : !llvm.ptr<ptr<i8>>
    %569 = llvm.mlir.constant(2 : i32) : i32
    %570 = llvm.getelementptr %564[%569] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %562, %570 : !llvm.ptr<ptr<i8>>
    %571 = llvm.mlir.constant(3 : i64) : i64
    %572 = llvm.mlir.addressof @main_kernel_0_main_kLoop_maximum__5_1_0_kernel_name : !llvm.ptr<array<26 x i8>>
    %573 = llvm.mlir.constant(0 : index) : i64
    %574 = llvm.getelementptr %572[%573, %573] : (!llvm.ptr<array<26 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %575 = llvm.extractvalue %211[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %576 = llvm.extractvalue %211[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %577 = llvm.extractvalue %211[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %578 = llvm.extractvalue %211[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %579 = llvm.extractvalue %211[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %580 = llvm.extractvalue %211[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %581 = llvm.extractvalue %211[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %582 = llvm.extractvalue %127[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %583 = llvm.extractvalue %127[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %584 = llvm.extractvalue %127[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %585 = llvm.extractvalue %127[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %586 = llvm.extractvalue %127[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %587 = llvm.extractvalue %404[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %588 = llvm.extractvalue %404[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %589 = llvm.extractvalue %404[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %590 = llvm.extractvalue %404[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %591 = llvm.extractvalue %404[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %592 = llvm.extractvalue %404[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %593 = llvm.extractvalue %404[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %594 = llvm.mlir.constant(1 : i32) : i32
    %595 = llvm.alloca %594 x !llvm.struct<".25", (i64, i64, ptr, ptr, ptr)> : (i32) -> !llvm.ptr<struct<".25", (i64, i64, ptr, ptr, ptr)>>
    %596 = llvm.mlir.constant(5 : i32) : i32
    %597 = llvm.alloca %596 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %598 = llvm.mlir.constant(0 : i32) : i32
    %599 = llvm.mlir.constant(0 : i32) : i32
    %600 = llvm.getelementptr %595[%598, 0] : (!llvm.ptr<struct<".25", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %600 : !llvm.ptr<i64>
    %601 = llvm.getelementptr %597[%599] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %602 = llvm.bitcast %600 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %602, %601 : !llvm.ptr<ptr<i8>>
    %603 = llvm.mlir.constant(1 : i32) : i32
    %604 = llvm.getelementptr %595[%598, 1] : (!llvm.ptr<struct<".25", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %363, %604 : !llvm.ptr<i64>
    %605 = llvm.getelementptr %597[%603] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %606 = llvm.bitcast %604 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %606, %605 : !llvm.ptr<ptr<i8>>
    %607 = llvm.mlir.constant(2 : i32) : i32
    %608 = llvm.getelementptr %595[%598, 2] : (!llvm.ptr<struct<".25", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %576, %608 : !llvm.ptr<ptr>
    %609 = llvm.getelementptr %597[%607] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %610 = llvm.bitcast %608 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %610, %609 : !llvm.ptr<ptr<i8>>
    %611 = llvm.mlir.constant(3 : i32) : i32
    %612 = llvm.getelementptr %595[%598, 3] : (!llvm.ptr<struct<".25", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %583, %612 : !llvm.ptr<ptr>
    %613 = llvm.getelementptr %597[%611] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %614 = llvm.bitcast %612 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %614, %613 : !llvm.ptr<ptr<i8>>
    %615 = llvm.mlir.constant(4 : i32) : i32
    %616 = llvm.getelementptr %595[%598, 4] : (!llvm.ptr<struct<".25", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %588, %616 : !llvm.ptr<ptr>
    %617 = llvm.getelementptr %597[%615] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %618 = llvm.bitcast %616 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %618, %617 : !llvm.ptr<ptr<i8>>
    %619 = llvm.mlir.constant(0 : i32) : i32
    %620 = llvm.mlir.constant(5 : i32) : i32
    %621 = llvm.inttoptr %619 : i32 to !llvm.ptr<i8>
    %622 = llvm.mlir.constant(0 : i32) : i32
    %623 = llvm.mlir.constant(1 : i32) : i32
    %624 = llvm.alloca %623 x !llvm.struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %625 = llvm.mlir.constant(14 : i32) : i32
    %626 = llvm.alloca %625 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %627 = llvm.mlir.constant(0 : i32) : i32
    %628 = llvm.getelementptr %624[%622, 0] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %628 : !llvm.ptr<ptr<i8>>
    %629 = llvm.getelementptr %626[%627] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %630 = llvm.bitcast %628 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %630, %629 : !llvm.ptr<ptr<i8>>
    %631 = llvm.mlir.constant(1 : i32) : i32
    %632 = llvm.getelementptr %624[%622, 1] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %564, %632 : !llvm.ptr<ptr<ptr<i8>>>
    %633 = llvm.getelementptr %626[%631] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %634 = llvm.bitcast %632 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %634, %633 : !llvm.ptr<ptr<i8>>
    %635 = llvm.mlir.constant(2 : i32) : i32
    %636 = llvm.getelementptr %624[%622, 2] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %571, %636 : !llvm.ptr<i64>
    %637 = llvm.getelementptr %626[%635] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %638 = llvm.bitcast %636 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %638, %637 : !llvm.ptr<ptr<i8>>
    %639 = llvm.mlir.constant(3 : i32) : i32
    %640 = llvm.getelementptr %624[%622, 3] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %574, %640 : !llvm.ptr<ptr<i8>>
    %641 = llvm.getelementptr %626[%639] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %642 = llvm.bitcast %640 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %642, %641 : !llvm.ptr<ptr<i8>>
    %643 = llvm.mlir.constant(4 : i32) : i32
    %644 = llvm.getelementptr %624[%622, 4] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %553, %644 : !llvm.ptr<i64>
    %645 = llvm.getelementptr %626[%643] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %646 = llvm.bitcast %644 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %646, %645 : !llvm.ptr<ptr<i8>>
    %647 = llvm.mlir.constant(5 : i32) : i32
    %648 = llvm.getelementptr %624[%622, 5] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %648 : !llvm.ptr<i64>
    %649 = llvm.getelementptr %626[%647] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %650 = llvm.bitcast %648 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %650, %649 : !llvm.ptr<ptr<i8>>
    %651 = llvm.mlir.constant(6 : i32) : i32
    %652 = llvm.getelementptr %624[%622, 6] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %652 : !llvm.ptr<i64>
    %653 = llvm.getelementptr %626[%651] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %654 = llvm.bitcast %652 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %654, %653 : !llvm.ptr<ptr<i8>>
    %655 = llvm.mlir.constant(7 : i32) : i32
    %656 = llvm.getelementptr %624[%622, 7] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %656 : !llvm.ptr<i64>
    %657 = llvm.getelementptr %626[%655] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %658 = llvm.bitcast %656 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %658, %657 : !llvm.ptr<ptr<i8>>
    %659 = llvm.mlir.constant(8 : i32) : i32
    %660 = llvm.getelementptr %624[%622, 8] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %660 : !llvm.ptr<i64>
    %661 = llvm.getelementptr %626[%659] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %662 = llvm.bitcast %660 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %662, %661 : !llvm.ptr<ptr<i8>>
    %663 = llvm.mlir.constant(9 : i32) : i32
    %664 = llvm.getelementptr %624[%622, 9] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %664 : !llvm.ptr<i64>
    %665 = llvm.getelementptr %626[%663] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %666 = llvm.bitcast %664 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %666, %665 : !llvm.ptr<ptr<i8>>
    %667 = llvm.mlir.constant(10 : i32) : i32
    %668 = llvm.getelementptr %624[%622, 10] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %619, %668 : !llvm.ptr<i32>
    %669 = llvm.getelementptr %626[%667] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %670 = llvm.bitcast %668 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %670, %669 : !llvm.ptr<ptr<i8>>
    %671 = llvm.mlir.constant(11 : i32) : i32
    %672 = llvm.getelementptr %624[%622, 11] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %621, %672 : !llvm.ptr<ptr<i8>>
    %673 = llvm.getelementptr %626[%671] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %674 = llvm.bitcast %672 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %674, %673 : !llvm.ptr<ptr<i8>>
    %675 = llvm.mlir.constant(12 : i32) : i32
    %676 = llvm.getelementptr %624[%622, 12] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %620, %676 : !llvm.ptr<i32>
    %677 = llvm.getelementptr %626[%675] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %678 = llvm.bitcast %676 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %678, %677 : !llvm.ptr<ptr<i8>>
    %679 = llvm.mlir.constant(13 : i32) : i32
    %680 = llvm.getelementptr %624[%622, 13] : (!llvm.ptr<struct<".26", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %597, %680 : !llvm.ptr<ptr<ptr<i8>>>
    %681 = llvm.getelementptr %626[%679] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %682 = llvm.bitcast %680 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %682, %681 : !llvm.ptr<ptr<i8>>
    %683 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %684 = llvm.mlir.constant(0 : index) : i64
    %685 = llvm.getelementptr %683[%684, %684] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %685, %626) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    %686 = llvm.extractvalue %211[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %687 = llvm.bitcast %686 : !llvm.ptr to !llvm.ptr
    %688 = llvm.mlir.constant(0 : i32) : i32
    %689 = llvm.mlir.constant(1 : i32) : i32
    %690 = llvm.alloca %689 x !llvm.struct<".11", (ptr<i8>, ptr)> : (i32) -> !llvm.ptr<struct<".11", (ptr<i8>, ptr)>>
    %691 = llvm.mlir.constant(2 : i32) : i32
    %692 = llvm.alloca %691 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %693 = llvm.mlir.constant(0 : i32) : i32
    %694 = llvm.getelementptr %690[%688, 0] : (!llvm.ptr<struct<".11", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %694 : !llvm.ptr<ptr<i8>>
    %695 = llvm.getelementptr %692[%693] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %696 = llvm.bitcast %694 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %696, %695 : !llvm.ptr<ptr<i8>>
    %697 = llvm.mlir.constant(1 : i32) : i32
    %698 = llvm.getelementptr %690[%688, 1] : (!llvm.ptr<struct<".11", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %687, %698 : !llvm.ptr<ptr>
    %699 = llvm.getelementptr %692[%697] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %700 = llvm.bitcast %698 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %700, %699 : !llvm.ptr<ptr<i8>>
    %701 = llvm.mlir.addressof @dealloc___gpu___pvoid_pvoid___void : !llvm.ptr<array<35 x i8>>
    %702 = llvm.mlir.constant(0 : index) : i64
    %703 = llvm.getelementptr %701[%702, %702] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %703, %692) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %704 = llvm.extractvalue %127[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %705 = llvm.bitcast %704 : !llvm.ptr to !llvm.ptr
    %706 = llvm.mlir.constant(0 : i32) : i32
    %707 = llvm.mlir.constant(1 : i32) : i32
    %708 = llvm.alloca %707 x !llvm.struct<".12", (ptr<i8>, ptr)> : (i32) -> !llvm.ptr<struct<".12", (ptr<i8>, ptr)>>
    %709 = llvm.mlir.constant(2 : i32) : i32
    %710 = llvm.alloca %709 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %711 = llvm.mlir.constant(0 : i32) : i32
    %712 = llvm.getelementptr %708[%706, 0] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %712 : !llvm.ptr<ptr<i8>>
    %713 = llvm.getelementptr %710[%711] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %714 = llvm.bitcast %712 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %714, %713 : !llvm.ptr<ptr<i8>>
    %715 = llvm.mlir.constant(1 : i32) : i32
    %716 = llvm.getelementptr %708[%706, 1] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %705, %716 : !llvm.ptr<ptr>
    %717 = llvm.getelementptr %710[%715] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %718 = llvm.bitcast %716 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %718, %717 : !llvm.ptr<ptr<i8>>
    %719 = llvm.mlir.addressof @dealloc___gpu___pvoid_pvoid___void : !llvm.ptr<array<35 x i8>>
    %720 = llvm.mlir.constant(0 : index) : i64
    %721 = llvm.getelementptr %719[%720, %720] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %721, %710) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %722 = llvm.mlir.constant(10 : index) : i64
    %723 = llvm.mlir.constant(1 : index) : i64
    %724 = llvm.mul %722, %33  : i64
    %725 = llvm.mlir.null : !llvm.ptr
    %726 = llvm.getelementptr %725[%724] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %727 = llvm.ptrtoint %726 : !llvm.ptr to i64
    %728 = llvm.mlir.constant(0 : i32) : i32
    %729 = llvm.mlir.constant(1 : i32) : i32
    %730 = llvm.alloca %729 x !llvm.struct<".13", (ptr<i8>, i64, ptr)> : (i32) -> !llvm.ptr<struct<".13", (ptr<i8>, i64, ptr)>>
    %731 = llvm.mlir.constant(3 : i32) : i32
    %732 = llvm.alloca %731 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %733 = llvm.mlir.constant(0 : i32) : i32
    %734 = llvm.getelementptr %730[%728, 0] : (!llvm.ptr<struct<".13", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %734 : !llvm.ptr<ptr<i8>>
    %735 = llvm.getelementptr %732[%733] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %736 = llvm.bitcast %734 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %736, %735 : !llvm.ptr<ptr<i8>>
    %737 = llvm.mlir.constant(1 : i32) : i32
    %738 = llvm.getelementptr %730[%728, 1] : (!llvm.ptr<struct<".13", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %727, %738 : !llvm.ptr<i64>
    %739 = llvm.getelementptr %732[%737] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %740 = llvm.bitcast %738 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %740, %739 : !llvm.ptr<ptr<i8>>
    %741 = llvm.mlir.constant(2 : i32) : i32
    %742 = llvm.getelementptr %730[%728, 2] : (!llvm.ptr<struct<".13", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<ptr>
    %743 = llvm.getelementptr %732[%741] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %744 = llvm.bitcast %742 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %744, %743 : !llvm.ptr<ptr<i8>>
    %745 = llvm.mlir.addressof @alloc___gpu___pvoid_i64___pvoid : !llvm.ptr<array<32 x i8>>
    %746 = llvm.mlir.constant(0 : index) : i64
    %747 = llvm.getelementptr %745[%746, %746] : (!llvm.ptr<array<32 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %747, %732) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %748 = llvm.load %742 : !llvm.ptr<ptr>
    %749 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %750 = llvm.bitcast %748 : !llvm.ptr to !llvm.ptr
    %751 = llvm.insertvalue %750, %749[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %752 = llvm.insertvalue %750, %751[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %753 = llvm.mlir.constant(0 : index) : i64
    %754 = llvm.insertvalue %753, %752[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %755 = llvm.mlir.constant(1 : index) : i64
    %756 = llvm.insertvalue %722, %754[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %757 = llvm.insertvalue %755, %756[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %758 = llvm.mul %755, %722  : i64
    %759 = llvm.insertvalue %33, %757[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %760 = llvm.insertvalue %758, %759[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %761 = llvm.mlir.constant(0 : i32) : i32
    %762 = llvm.mlir.constant(1 : i32) : i32
    %763 = llvm.extractvalue %404[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %764 = llvm.extractvalue %404[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %765 = llvm.extractvalue %404[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %766 = llvm.extractvalue %404[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %767 = llvm.extractvalue %404[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %768 = llvm.extractvalue %404[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %769 = llvm.extractvalue %404[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %770 = llvm.extractvalue %65[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %771 = llvm.extractvalue %65[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %772 = llvm.extractvalue %65[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %773 = llvm.extractvalue %65[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %774 = llvm.extractvalue %65[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %775 = llvm.extractvalue %65[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %776 = llvm.extractvalue %65[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %777 = llvm.extractvalue %760[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %778 = llvm.extractvalue %760[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %779 = llvm.extractvalue %760[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %780 = llvm.extractvalue %760[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %781 = llvm.extractvalue %760[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %782 = llvm.extractvalue %760[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %783 = llvm.extractvalue %760[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %784 = llvm.alloca %762 x !llvm.struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)> : (i32) -> !llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>
    %785 = llvm.mlir.constant(26 : i32) : i32
    %786 = llvm.alloca %785 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %787 = llvm.mlir.constant(0 : i32) : i32
    %788 = llvm.getelementptr %784[%761, 0] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %788 : !llvm.ptr<ptr<i8>>
    %789 = llvm.getelementptr %786[%787] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %790 = llvm.bitcast %788 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %790, %789 : !llvm.ptr<ptr<i8>>
    %791 = llvm.mlir.constant(1 : i32) : i32
    %792 = llvm.getelementptr %784[%761, 1] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %36, %792 : !llvm.ptr<ptr<i8>>
    %793 = llvm.getelementptr %786[%791] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %794 = llvm.bitcast %792 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %794, %793 : !llvm.ptr<ptr<i8>>
    %795 = llvm.mlir.constant(2 : i32) : i32
    %796 = llvm.getelementptr %784[%761, 2] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %763, %796 : !llvm.ptr<ptr>
    %797 = llvm.getelementptr %786[%795] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %798 = llvm.bitcast %796 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %798, %797 : !llvm.ptr<ptr<i8>>
    %799 = llvm.mlir.constant(3 : i32) : i32
    %800 = llvm.getelementptr %784[%761, 3] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %764, %800 : !llvm.ptr<ptr>
    %801 = llvm.getelementptr %786[%799] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %802 = llvm.bitcast %800 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %802, %801 : !llvm.ptr<ptr<i8>>
    %803 = llvm.mlir.constant(4 : i32) : i32
    %804 = llvm.getelementptr %784[%761, 4] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %765, %804 : !llvm.ptr<i64>
    %805 = llvm.getelementptr %786[%803] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %806 = llvm.bitcast %804 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %806, %805 : !llvm.ptr<ptr<i8>>
    %807 = llvm.mlir.constant(5 : i32) : i32
    %808 = llvm.getelementptr %784[%761, 5] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %766, %808 : !llvm.ptr<i64>
    %809 = llvm.getelementptr %786[%807] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %810 = llvm.bitcast %808 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %810, %809 : !llvm.ptr<ptr<i8>>
    %811 = llvm.mlir.constant(6 : i32) : i32
    %812 = llvm.getelementptr %784[%761, 6] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %767, %812 : !llvm.ptr<i64>
    %813 = llvm.getelementptr %786[%811] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %814 = llvm.bitcast %812 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %814, %813 : !llvm.ptr<ptr<i8>>
    %815 = llvm.mlir.constant(7 : i32) : i32
    %816 = llvm.getelementptr %784[%761, 7] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %768, %816 : !llvm.ptr<i64>
    %817 = llvm.getelementptr %786[%815] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %818 = llvm.bitcast %816 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %818, %817 : !llvm.ptr<ptr<i8>>
    %819 = llvm.mlir.constant(8 : i32) : i32
    %820 = llvm.getelementptr %784[%761, 8] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %769, %820 : !llvm.ptr<i64>
    %821 = llvm.getelementptr %786[%819] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %822 = llvm.bitcast %820 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %822, %821 : !llvm.ptr<ptr<i8>>
    %823 = llvm.mlir.constant(9 : i32) : i32
    %824 = llvm.getelementptr %784[%761, 9] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %770, %824 : !llvm.ptr<ptr>
    %825 = llvm.getelementptr %786[%823] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %826 = llvm.bitcast %824 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %826, %825 : !llvm.ptr<ptr<i8>>
    %827 = llvm.mlir.constant(10 : i32) : i32
    %828 = llvm.getelementptr %784[%761, 10] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %771, %828 : !llvm.ptr<ptr>
    %829 = llvm.getelementptr %786[%827] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %830 = llvm.bitcast %828 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %830, %829 : !llvm.ptr<ptr<i8>>
    %831 = llvm.mlir.constant(11 : i32) : i32
    %832 = llvm.getelementptr %784[%761, 11] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %772, %832 : !llvm.ptr<i64>
    %833 = llvm.getelementptr %786[%831] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %834 = llvm.bitcast %832 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %834, %833 : !llvm.ptr<ptr<i8>>
    %835 = llvm.mlir.constant(12 : i32) : i32
    %836 = llvm.getelementptr %784[%761, 12] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %773, %836 : !llvm.ptr<i64>
    %837 = llvm.getelementptr %786[%835] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %838 = llvm.bitcast %836 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %838, %837 : !llvm.ptr<ptr<i8>>
    %839 = llvm.mlir.constant(13 : i32) : i32
    %840 = llvm.getelementptr %784[%761, 13] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %774, %840 : !llvm.ptr<i64>
    %841 = llvm.getelementptr %786[%839] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %842 = llvm.bitcast %840 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %842, %841 : !llvm.ptr<ptr<i8>>
    %843 = llvm.mlir.constant(14 : i32) : i32
    %844 = llvm.getelementptr %784[%761, 14] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %775, %844 : !llvm.ptr<i64>
    %845 = llvm.getelementptr %786[%843] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %846 = llvm.bitcast %844 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %846, %845 : !llvm.ptr<ptr<i8>>
    %847 = llvm.mlir.constant(15 : i32) : i32
    %848 = llvm.getelementptr %784[%761, 15] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %776, %848 : !llvm.ptr<i64>
    %849 = llvm.getelementptr %786[%847] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %850 = llvm.bitcast %848 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %850, %849 : !llvm.ptr<ptr<i8>>
    %851 = llvm.mlir.constant(16 : i32) : i32
    %852 = llvm.getelementptr %784[%761, 16] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %777, %852 : !llvm.ptr<ptr>
    %853 = llvm.getelementptr %786[%851] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %854 = llvm.bitcast %852 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %854, %853 : !llvm.ptr<ptr<i8>>
    %855 = llvm.mlir.constant(17 : i32) : i32
    %856 = llvm.getelementptr %784[%761, 17] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %778, %856 : !llvm.ptr<ptr>
    %857 = llvm.getelementptr %786[%855] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %858 = llvm.bitcast %856 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %858, %857 : !llvm.ptr<ptr<i8>>
    %859 = llvm.mlir.constant(18 : i32) : i32
    %860 = llvm.getelementptr %784[%761, 18] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %779, %860 : !llvm.ptr<i64>
    %861 = llvm.getelementptr %786[%859] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %862 = llvm.bitcast %860 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %862, %861 : !llvm.ptr<ptr<i8>>
    %863 = llvm.mlir.constant(19 : i32) : i32
    %864 = llvm.getelementptr %784[%761, 19] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %780, %864 : !llvm.ptr<i64>
    %865 = llvm.getelementptr %786[%863] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %866 = llvm.bitcast %864 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %866, %865 : !llvm.ptr<ptr<i8>>
    %867 = llvm.mlir.constant(20 : i32) : i32
    %868 = llvm.getelementptr %784[%761, 20] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %781, %868 : !llvm.ptr<i64>
    %869 = llvm.getelementptr %786[%867] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %870 = llvm.bitcast %868 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %870, %869 : !llvm.ptr<ptr<i8>>
    %871 = llvm.mlir.constant(21 : i32) : i32
    %872 = llvm.getelementptr %784[%761, 21] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %782, %872 : !llvm.ptr<i64>
    %873 = llvm.getelementptr %786[%871] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %874 = llvm.bitcast %872 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %874, %873 : !llvm.ptr<ptr<i8>>
    %875 = llvm.mlir.constant(22 : i32) : i32
    %876 = llvm.getelementptr %784[%761, 22] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i64>
    llvm.store %783, %876 : !llvm.ptr<i64>
    %877 = llvm.getelementptr %786[%875] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %878 = llvm.bitcast %876 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %878, %877 : !llvm.ptr<ptr<i8>>
    %879 = llvm.mlir.constant(23 : i32) : i32
    %880 = llvm.getelementptr %784[%761, 23] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i1>
    llvm.store %6, %880 : !llvm.ptr<i1>
    %881 = llvm.getelementptr %786[%879] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %882 = llvm.bitcast %880 : !llvm.ptr<i1> to !llvm.ptr<i8>
    llvm.store %882, %881 : !llvm.ptr<ptr<i8>>
    %883 = llvm.mlir.constant(24 : i32) : i32
    %884 = llvm.getelementptr %784[%761, 24] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i1>
    llvm.store %6, %884 : !llvm.ptr<i1>
    %885 = llvm.getelementptr %786[%883] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %886 = llvm.bitcast %884 : !llvm.ptr<i1> to !llvm.ptr<i8>
    llvm.store %886, %885 : !llvm.ptr<ptr<i8>>
    %887 = llvm.mlir.constant(25 : i32) : i32
    %888 = llvm.getelementptr %784[%761, 25] : (!llvm.ptr<struct<".14", (ptr<i8>, ptr<i8>, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1)>>, i32) -> !llvm.ptr<i1>
    llvm.store %7, %888 : !llvm.ptr<i1>
    %889 = llvm.getelementptr %786[%887] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %890 = llvm.bitcast %888 : !llvm.ptr<i1> to !llvm.ptr<i8>
    llvm.store %890, %889 : !llvm.ptr<ptr<i8>>
    %891 = llvm.mlir.addressof @ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void : !llvm.ptr<array<66 x i8>>
    %892 = llvm.mlir.constant(0 : index) : i64
    %893 = llvm.getelementptr %891[%892, %892] : (!llvm.ptr<array<66 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %893, %786) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %894 = llvm.extractvalue %404[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %895 = llvm.bitcast %894 : !llvm.ptr to !llvm.ptr
    %896 = llvm.mlir.constant(0 : i32) : i32
    %897 = llvm.mlir.constant(1 : i32) : i32
    %898 = llvm.alloca %897 x !llvm.struct<".15", (ptr<i8>, ptr)> : (i32) -> !llvm.ptr<struct<".15", (ptr<i8>, ptr)>>
    %899 = llvm.mlir.constant(2 : i32) : i32
    %900 = llvm.alloca %899 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %901 = llvm.mlir.constant(0 : i32) : i32
    %902 = llvm.getelementptr %898[%896, 0] : (!llvm.ptr<struct<".15", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %902 : !llvm.ptr<ptr<i8>>
    %903 = llvm.getelementptr %900[%901] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %904 = llvm.bitcast %902 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %904, %903 : !llvm.ptr<ptr<i8>>
    %905 = llvm.mlir.constant(1 : i32) : i32
    %906 = llvm.getelementptr %898[%896, 1] : (!llvm.ptr<struct<".15", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %895, %906 : !llvm.ptr<ptr>
    %907 = llvm.getelementptr %900[%905] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %908 = llvm.bitcast %906 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %908, %907 : !llvm.ptr<ptr<i8>>
    %909 = llvm.mlir.addressof @dealloc___gpu___pvoid_pvoid___void : !llvm.ptr<array<35 x i8>>
    %910 = llvm.mlir.constant(0 : index) : i64
    %911 = llvm.getelementptr %909[%910, %910] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %911, %900) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %912 = llvm.extractvalue %65[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %913 = llvm.bitcast %912 : !llvm.ptr to !llvm.ptr
    %914 = llvm.mlir.constant(0 : i32) : i32
    %915 = llvm.mlir.constant(1 : i32) : i32
    %916 = llvm.alloca %915 x !llvm.struct<".16", (ptr<i8>, ptr)> : (i32) -> !llvm.ptr<struct<".16", (ptr<i8>, ptr)>>
    %917 = llvm.mlir.constant(2 : i32) : i32
    %918 = llvm.alloca %917 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %919 = llvm.mlir.constant(0 : i32) : i32
    %920 = llvm.getelementptr %916[%914, 0] : (!llvm.ptr<struct<".16", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %920 : !llvm.ptr<ptr<i8>>
    %921 = llvm.getelementptr %918[%919] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %922 = llvm.bitcast %920 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %922, %921 : !llvm.ptr<ptr<i8>>
    %923 = llvm.mlir.constant(1 : i32) : i32
    %924 = llvm.getelementptr %916[%914, 1] : (!llvm.ptr<struct<".16", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %913, %924 : !llvm.ptr<ptr>
    %925 = llvm.getelementptr %918[%923] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %926 = llvm.bitcast %924 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %926, %925 : !llvm.ptr<ptr<i8>>
    %927 = llvm.mlir.addressof @dealloc___gpu___pvoid_pvoid___void : !llvm.ptr<array<35 x i8>>
    %928 = llvm.mlir.constant(0 : index) : i64
    %929 = llvm.getelementptr %927[%928, %928] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %929, %918) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %930 = llvm.mlir.constant(10 : index) : i64
    %931 = llvm.mlir.constant(1 : index) : i64
    %932 = llvm.mul %930, %33  : i64
    %933 = llvm.mlir.null : !llvm.ptr
    %934 = llvm.getelementptr %933[%932] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %935 = llvm.ptrtoint %934 : !llvm.ptr to i64
    %936 = llvm.mlir.constant(0 : i32) : i32
    %937 = llvm.mlir.constant(1 : i32) : i32
    %938 = llvm.alloca %937 x !llvm.struct<".17", (ptr<i8>, i64, ptr)> : (i32) -> !llvm.ptr<struct<".17", (ptr<i8>, i64, ptr)>>
    %939 = llvm.mlir.constant(3 : i32) : i32
    %940 = llvm.alloca %939 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %941 = llvm.mlir.constant(0 : i32) : i32
    %942 = llvm.getelementptr %938[%936, 0] : (!llvm.ptr<struct<".17", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %942 : !llvm.ptr<ptr<i8>>
    %943 = llvm.getelementptr %940[%941] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %944 = llvm.bitcast %942 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %944, %943 : !llvm.ptr<ptr<i8>>
    %945 = llvm.mlir.constant(1 : i32) : i32
    %946 = llvm.getelementptr %938[%936, 1] : (!llvm.ptr<struct<".17", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %935, %946 : !llvm.ptr<i64>
    %947 = llvm.getelementptr %940[%945] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %948 = llvm.bitcast %946 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %948, %947 : !llvm.ptr<ptr<i8>>
    %949 = llvm.mlir.constant(2 : i32) : i32
    %950 = llvm.getelementptr %938[%936, 2] : (!llvm.ptr<struct<".17", (ptr<i8>, i64, ptr)>>, i32) -> !llvm.ptr<ptr>
    %951 = llvm.getelementptr %940[%949] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %952 = llvm.bitcast %950 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %952, %951 : !llvm.ptr<ptr<i8>>
    %953 = llvm.mlir.addressof @alloc___gpu___pvoid_i64___pvoid : !llvm.ptr<array<32 x i8>>
    %954 = llvm.mlir.constant(0 : index) : i64
    %955 = llvm.getelementptr %953[%954, %954] : (!llvm.ptr<array<32 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %955, %940) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %956 = llvm.load %950 : !llvm.ptr<ptr>
    %957 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %958 = llvm.bitcast %956 : !llvm.ptr to !llvm.ptr
    %959 = llvm.insertvalue %958, %957[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %960 = llvm.insertvalue %958, %959[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %961 = llvm.mlir.constant(0 : index) : i64
    %962 = llvm.insertvalue %961, %960[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %963 = llvm.mlir.constant(1 : index) : i64
    %964 = llvm.insertvalue %930, %962[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %965 = llvm.insertvalue %963, %964[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %966 = llvm.mul %963, %930  : i64
    %967 = llvm.insertvalue %33, %965[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %968 = llvm.insertvalue %966, %967[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.cond_br %365, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %969 = llvm.udiv %363, %9  : i64
    %970 = llvm.icmp "sle" %969, %11 : i64
    %971 = llvm.sub %11, %969  : i64
    %972 = llvm.sub %969, %8  : i64
    %973 = llvm.select %970, %971, %972 : i1, i64
    %974 = llvm.sdiv %973, %0  : i64
    %975 = llvm.sub %11, %974  : i64
    %976 = llvm.add %974, %8  : i64
    %977 = llvm.select %970, %975, %976 : i1, i64
    %978 = llvm.mlir.addressof @main_kernel_1_blob_gpu.binary_compute_60 : !llvm.ptr<array<1048 x i8>>
    %979 = llvm.mlir.constant(0 : index) : i64
    %980 = llvm.getelementptr %978[%979, %979] : (!llvm.ptr<array<1048 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %981 = llvm.mlir.addressof @main_kernel_1_blob_gpu.binary_sm_70 : !llvm.ptr<array<1512 x i8>>
    %982 = llvm.mlir.constant(0 : index) : i64
    %983 = llvm.getelementptr %981[%982, %982] : (!llvm.ptr<array<1512 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %984 = llvm.mlir.addressof @main_kernel_1_blob_gpu.binary_sm_75 : !llvm.ptr<array<1472 x i8>>
    %985 = llvm.mlir.constant(0 : index) : i64
    %986 = llvm.getelementptr %984[%985, %985] : (!llvm.ptr<array<1472 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %987 = llvm.mlir.constant(3 : i32) : i32
    %988 = llvm.alloca %987 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %989 = llvm.mlir.constant(0 : i32) : i32
    %990 = llvm.getelementptr %988[%989] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %980, %990 : !llvm.ptr<ptr<i8>>
    %991 = llvm.mlir.constant(1 : i32) : i32
    %992 = llvm.getelementptr %988[%991] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %983, %992 : !llvm.ptr<ptr<i8>>
    %993 = llvm.mlir.constant(2 : i32) : i32
    %994 = llvm.getelementptr %988[%993] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %986, %994 : !llvm.ptr<ptr<i8>>
    %995 = llvm.mlir.constant(3 : i64) : i64
    %996 = llvm.mlir.addressof @main_kernel_1_main_kLoop_maximum__5_1_1___Vec4_kernel_name : !llvm.ptr<array<33 x i8>>
    %997 = llvm.mlir.constant(0 : index) : i64
    %998 = llvm.getelementptr %996[%997, %997] : (!llvm.ptr<array<33 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %999 = llvm.extractvalue %158[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1000 = llvm.extractvalue %158[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1001 = llvm.extractvalue %158[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1002 = llvm.extractvalue %158[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1003 = llvm.extractvalue %158[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1004 = llvm.extractvalue %760[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1005 = llvm.extractvalue %760[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1006 = llvm.extractvalue %760[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1007 = llvm.extractvalue %760[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1008 = llvm.extractvalue %760[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1009 = llvm.extractvalue %760[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1010 = llvm.extractvalue %760[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1011 = llvm.extractvalue %968[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1012 = llvm.extractvalue %968[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1013 = llvm.extractvalue %968[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1014 = llvm.extractvalue %968[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1015 = llvm.extractvalue %968[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1016 = llvm.extractvalue %968[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1017 = llvm.extractvalue %968[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1018 = llvm.mlir.constant(1 : i32) : i32
    %1019 = llvm.alloca %1018 x !llvm.struct<".18", (i64, i64, ptr, ptr, ptr)> : (i32) -> !llvm.ptr<struct<".18", (i64, i64, ptr, ptr, ptr)>>
    %1020 = llvm.mlir.constant(5 : i32) : i32
    %1021 = llvm.alloca %1020 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %1022 = llvm.mlir.constant(0 : i32) : i32
    %1023 = llvm.mlir.constant(0 : i32) : i32
    %1024 = llvm.getelementptr %1019[%1022, 0] : (!llvm.ptr<struct<".18", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %1024 : !llvm.ptr<i64>
    %1025 = llvm.getelementptr %1021[%1023] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1026 = llvm.bitcast %1024 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1026, %1025 : !llvm.ptr<ptr<i8>>
    %1027 = llvm.mlir.constant(1 : i32) : i32
    %1028 = llvm.getelementptr %1019[%1022, 1] : (!llvm.ptr<struct<".18", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %969, %1028 : !llvm.ptr<i64>
    %1029 = llvm.getelementptr %1021[%1027] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1030 = llvm.bitcast %1028 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1030, %1029 : !llvm.ptr<ptr<i8>>
    %1031 = llvm.mlir.constant(2 : i32) : i32
    %1032 = llvm.getelementptr %1019[%1022, 2] : (!llvm.ptr<struct<".18", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1000, %1032 : !llvm.ptr<ptr>
    %1033 = llvm.getelementptr %1021[%1031] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1034 = llvm.bitcast %1032 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1034, %1033 : !llvm.ptr<ptr<i8>>
    %1035 = llvm.mlir.constant(3 : i32) : i32
    %1036 = llvm.getelementptr %1019[%1022, 3] : (!llvm.ptr<struct<".18", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1005, %1036 : !llvm.ptr<ptr>
    %1037 = llvm.getelementptr %1021[%1035] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1038 = llvm.bitcast %1036 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1038, %1037 : !llvm.ptr<ptr<i8>>
    %1039 = llvm.mlir.constant(4 : i32) : i32
    %1040 = llvm.getelementptr %1019[%1022, 4] : (!llvm.ptr<struct<".18", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1012, %1040 : !llvm.ptr<ptr>
    %1041 = llvm.getelementptr %1021[%1039] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1042 = llvm.bitcast %1040 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1042, %1041 : !llvm.ptr<ptr<i8>>
    %1043 = llvm.mlir.constant(0 : i32) : i32
    %1044 = llvm.mlir.constant(5 : i32) : i32
    %1045 = llvm.inttoptr %1043 : i32 to !llvm.ptr<i8>
    %1046 = llvm.mlir.constant(0 : i32) : i32
    %1047 = llvm.mlir.constant(1 : i32) : i32
    %1048 = llvm.alloca %1047 x !llvm.struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %1049 = llvm.mlir.constant(14 : i32) : i32
    %1050 = llvm.alloca %1049 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %1051 = llvm.mlir.constant(0 : i32) : i32
    %1052 = llvm.getelementptr %1048[%1046, 0] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %1052 : !llvm.ptr<ptr<i8>>
    %1053 = llvm.getelementptr %1050[%1051] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1054 = llvm.bitcast %1052 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %1054, %1053 : !llvm.ptr<ptr<i8>>
    %1055 = llvm.mlir.constant(1 : i32) : i32
    %1056 = llvm.getelementptr %1048[%1046, 1] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %988, %1056 : !llvm.ptr<ptr<ptr<i8>>>
    %1057 = llvm.getelementptr %1050[%1055] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1058 = llvm.bitcast %1056 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %1058, %1057 : !llvm.ptr<ptr<i8>>
    %1059 = llvm.mlir.constant(2 : i32) : i32
    %1060 = llvm.getelementptr %1048[%1046, 2] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %995, %1060 : !llvm.ptr<i64>
    %1061 = llvm.getelementptr %1050[%1059] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1062 = llvm.bitcast %1060 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1062, %1061 : !llvm.ptr<ptr<i8>>
    %1063 = llvm.mlir.constant(3 : i32) : i32
    %1064 = llvm.getelementptr %1048[%1046, 3] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %998, %1064 : !llvm.ptr<ptr<i8>>
    %1065 = llvm.getelementptr %1050[%1063] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1066 = llvm.bitcast %1064 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %1066, %1065 : !llvm.ptr<ptr<i8>>
    %1067 = llvm.mlir.constant(4 : i32) : i32
    %1068 = llvm.getelementptr %1048[%1046, 4] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %977, %1068 : !llvm.ptr<i64>
    %1069 = llvm.getelementptr %1050[%1067] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1070 = llvm.bitcast %1068 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1070, %1069 : !llvm.ptr<ptr<i8>>
    %1071 = llvm.mlir.constant(5 : i32) : i32
    %1072 = llvm.getelementptr %1048[%1046, 5] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %1072 : !llvm.ptr<i64>
    %1073 = llvm.getelementptr %1050[%1071] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1074 = llvm.bitcast %1072 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1074, %1073 : !llvm.ptr<ptr<i8>>
    %1075 = llvm.mlir.constant(6 : i32) : i32
    %1076 = llvm.getelementptr %1048[%1046, 6] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %1076 : !llvm.ptr<i64>
    %1077 = llvm.getelementptr %1050[%1075] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1078 = llvm.bitcast %1076 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1078, %1077 : !llvm.ptr<ptr<i8>>
    %1079 = llvm.mlir.constant(7 : i32) : i32
    %1080 = llvm.getelementptr %1048[%1046, 7] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %1080 : !llvm.ptr<i64>
    %1081 = llvm.getelementptr %1050[%1079] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1082 = llvm.bitcast %1080 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1082, %1081 : !llvm.ptr<ptr<i8>>
    %1083 = llvm.mlir.constant(8 : i32) : i32
    %1084 = llvm.getelementptr %1048[%1046, 8] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %1084 : !llvm.ptr<i64>
    %1085 = llvm.getelementptr %1050[%1083] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1086 = llvm.bitcast %1084 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1086, %1085 : !llvm.ptr<ptr<i8>>
    %1087 = llvm.mlir.constant(9 : i32) : i32
    %1088 = llvm.getelementptr %1048[%1046, 9] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %1088 : !llvm.ptr<i64>
    %1089 = llvm.getelementptr %1050[%1087] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1090 = llvm.bitcast %1088 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1090, %1089 : !llvm.ptr<ptr<i8>>
    %1091 = llvm.mlir.constant(10 : i32) : i32
    %1092 = llvm.getelementptr %1048[%1046, 10] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %1043, %1092 : !llvm.ptr<i32>
    %1093 = llvm.getelementptr %1050[%1091] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1094 = llvm.bitcast %1092 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %1094, %1093 : !llvm.ptr<ptr<i8>>
    %1095 = llvm.mlir.constant(11 : i32) : i32
    %1096 = llvm.getelementptr %1048[%1046, 11] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %1045, %1096 : !llvm.ptr<ptr<i8>>
    %1097 = llvm.getelementptr %1050[%1095] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1098 = llvm.bitcast %1096 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %1098, %1097 : !llvm.ptr<ptr<i8>>
    %1099 = llvm.mlir.constant(12 : i32) : i32
    %1100 = llvm.getelementptr %1048[%1046, 12] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %1044, %1100 : !llvm.ptr<i32>
    %1101 = llvm.getelementptr %1050[%1099] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1102 = llvm.bitcast %1100 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %1102, %1101 : !llvm.ptr<ptr<i8>>
    %1103 = llvm.mlir.constant(13 : i32) : i32
    %1104 = llvm.getelementptr %1048[%1046, 13] : (!llvm.ptr<struct<".19", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %1021, %1104 : !llvm.ptr<ptr<ptr<i8>>>
    %1105 = llvm.getelementptr %1050[%1103] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1106 = llvm.bitcast %1104 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %1106, %1105 : !llvm.ptr<ptr<i8>>
    %1107 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %1108 = llvm.mlir.constant(0 : index) : i64
    %1109 = llvm.getelementptr %1107[%1108, %1108] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %1109, %1050) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.br ^bb6
  ^bb5:  // pred: ^bb3
    %1110 = llvm.icmp "sle" %363, %11 : i64
    %1111 = llvm.sub %11, %363  : i64
    %1112 = llvm.sub %363, %8  : i64
    %1113 = llvm.select %1110, %1111, %1112 : i1, i64
    %1114 = llvm.sdiv %1113, %0  : i64
    %1115 = llvm.sub %11, %1114  : i64
    %1116 = llvm.add %1114, %8  : i64
    %1117 = llvm.select %1110, %1115, %1116 : i1, i64
    %1118 = llvm.mlir.addressof @main_kernel_2_blob_gpu.binary_compute_60 : !llvm.ptr<array<688 x i8>>
    %1119 = llvm.mlir.constant(0 : index) : i64
    %1120 = llvm.getelementptr %1118[%1119, %1119] : (!llvm.ptr<array<688 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %1121 = llvm.mlir.addressof @main_kernel_2_blob_gpu.binary_sm_70 : !llvm.ptr<array<1216 x i8>>
    %1122 = llvm.mlir.constant(0 : index) : i64
    %1123 = llvm.getelementptr %1121[%1122, %1122] : (!llvm.ptr<array<1216 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %1124 = llvm.mlir.addressof @main_kernel_2_blob_gpu.binary_sm_75 : !llvm.ptr<array<1200 x i8>>
    %1125 = llvm.mlir.constant(0 : index) : i64
    %1126 = llvm.getelementptr %1124[%1125, %1125] : (!llvm.ptr<array<1200 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %1127 = llvm.mlir.constant(3 : i32) : i32
    %1128 = llvm.alloca %1127 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %1129 = llvm.mlir.constant(0 : i32) : i32
    %1130 = llvm.getelementptr %1128[%1129] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %1120, %1130 : !llvm.ptr<ptr<i8>>
    %1131 = llvm.mlir.constant(1 : i32) : i32
    %1132 = llvm.getelementptr %1128[%1131] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %1123, %1132 : !llvm.ptr<ptr<i8>>
    %1133 = llvm.mlir.constant(2 : i32) : i32
    %1134 = llvm.getelementptr %1128[%1133] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %1126, %1134 : !llvm.ptr<ptr<i8>>
    %1135 = llvm.mlir.constant(3 : i64) : i64
    %1136 = llvm.mlir.addressof @main_kernel_2_main_kLoop_maximum__5_1_1_kernel_name : !llvm.ptr<array<26 x i8>>
    %1137 = llvm.mlir.constant(0 : index) : i64
    %1138 = llvm.getelementptr %1136[%1137, %1137] : (!llvm.ptr<array<26 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %1139 = llvm.extractvalue %760[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1140 = llvm.extractvalue %760[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1141 = llvm.extractvalue %760[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1142 = llvm.extractvalue %760[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1143 = llvm.extractvalue %760[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1144 = llvm.extractvalue %760[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1145 = llvm.extractvalue %760[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1146 = llvm.extractvalue %158[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1147 = llvm.extractvalue %158[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1148 = llvm.extractvalue %158[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1149 = llvm.extractvalue %158[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1150 = llvm.extractvalue %158[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1151 = llvm.extractvalue %968[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1152 = llvm.extractvalue %968[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1153 = llvm.extractvalue %968[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1154 = llvm.extractvalue %968[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1155 = llvm.extractvalue %968[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1156 = llvm.extractvalue %968[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1157 = llvm.extractvalue %968[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1158 = llvm.mlir.constant(1 : i32) : i32
    %1159 = llvm.alloca %1158 x !llvm.struct<".23", (i64, i64, ptr, ptr, ptr)> : (i32) -> !llvm.ptr<struct<".23", (i64, i64, ptr, ptr, ptr)>>
    %1160 = llvm.mlir.constant(5 : i32) : i32
    %1161 = llvm.alloca %1160 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %1162 = llvm.mlir.constant(0 : i32) : i32
    %1163 = llvm.mlir.constant(0 : i32) : i32
    %1164 = llvm.getelementptr %1159[%1162, 0] : (!llvm.ptr<struct<".23", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %1164 : !llvm.ptr<i64>
    %1165 = llvm.getelementptr %1161[%1163] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1166 = llvm.bitcast %1164 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1166, %1165 : !llvm.ptr<ptr<i8>>
    %1167 = llvm.mlir.constant(1 : i32) : i32
    %1168 = llvm.getelementptr %1159[%1162, 1] : (!llvm.ptr<struct<".23", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<i64>
    llvm.store %363, %1168 : !llvm.ptr<i64>
    %1169 = llvm.getelementptr %1161[%1167] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1170 = llvm.bitcast %1168 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1170, %1169 : !llvm.ptr<ptr<i8>>
    %1171 = llvm.mlir.constant(2 : i32) : i32
    %1172 = llvm.getelementptr %1159[%1162, 2] : (!llvm.ptr<struct<".23", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1140, %1172 : !llvm.ptr<ptr>
    %1173 = llvm.getelementptr %1161[%1171] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1174 = llvm.bitcast %1172 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1174, %1173 : !llvm.ptr<ptr<i8>>
    %1175 = llvm.mlir.constant(3 : i32) : i32
    %1176 = llvm.getelementptr %1159[%1162, 3] : (!llvm.ptr<struct<".23", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1147, %1176 : !llvm.ptr<ptr>
    %1177 = llvm.getelementptr %1161[%1175] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1178 = llvm.bitcast %1176 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1178, %1177 : !llvm.ptr<ptr<i8>>
    %1179 = llvm.mlir.constant(4 : i32) : i32
    %1180 = llvm.getelementptr %1159[%1162, 4] : (!llvm.ptr<struct<".23", (i64, i64, ptr, ptr, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1152, %1180 : !llvm.ptr<ptr>
    %1181 = llvm.getelementptr %1161[%1179] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1182 = llvm.bitcast %1180 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1182, %1181 : !llvm.ptr<ptr<i8>>
    %1183 = llvm.mlir.constant(0 : i32) : i32
    %1184 = llvm.mlir.constant(5 : i32) : i32
    %1185 = llvm.inttoptr %1183 : i32 to !llvm.ptr<i8>
    %1186 = llvm.mlir.constant(0 : i32) : i32
    %1187 = llvm.mlir.constant(1 : i32) : i32
    %1188 = llvm.alloca %1187 x !llvm.struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %1189 = llvm.mlir.constant(14 : i32) : i32
    %1190 = llvm.alloca %1189 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %1191 = llvm.mlir.constant(0 : i32) : i32
    %1192 = llvm.getelementptr %1188[%1186, 0] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %1192 : !llvm.ptr<ptr<i8>>
    %1193 = llvm.getelementptr %1190[%1191] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1194 = llvm.bitcast %1192 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %1194, %1193 : !llvm.ptr<ptr<i8>>
    %1195 = llvm.mlir.constant(1 : i32) : i32
    %1196 = llvm.getelementptr %1188[%1186, 1] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %1128, %1196 : !llvm.ptr<ptr<ptr<i8>>>
    %1197 = llvm.getelementptr %1190[%1195] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1198 = llvm.bitcast %1196 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %1198, %1197 : !llvm.ptr<ptr<i8>>
    %1199 = llvm.mlir.constant(2 : i32) : i32
    %1200 = llvm.getelementptr %1188[%1186, 2] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1135, %1200 : !llvm.ptr<i64>
    %1201 = llvm.getelementptr %1190[%1199] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1202 = llvm.bitcast %1200 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1202, %1201 : !llvm.ptr<ptr<i8>>
    %1203 = llvm.mlir.constant(3 : i32) : i32
    %1204 = llvm.getelementptr %1188[%1186, 3] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %1138, %1204 : !llvm.ptr<ptr<i8>>
    %1205 = llvm.getelementptr %1190[%1203] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1206 = llvm.bitcast %1204 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %1206, %1205 : !llvm.ptr<ptr<i8>>
    %1207 = llvm.mlir.constant(4 : i32) : i32
    %1208 = llvm.getelementptr %1188[%1186, 4] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1117, %1208 : !llvm.ptr<i64>
    %1209 = llvm.getelementptr %1190[%1207] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1210 = llvm.bitcast %1208 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1210, %1209 : !llvm.ptr<ptr<i8>>
    %1211 = llvm.mlir.constant(5 : i32) : i32
    %1212 = llvm.getelementptr %1188[%1186, 5] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %1212 : !llvm.ptr<i64>
    %1213 = llvm.getelementptr %1190[%1211] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1214 = llvm.bitcast %1212 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1214, %1213 : !llvm.ptr<ptr<i8>>
    %1215 = llvm.mlir.constant(6 : i32) : i32
    %1216 = llvm.getelementptr %1188[%1186, 6] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %1216 : !llvm.ptr<i64>
    %1217 = llvm.getelementptr %1190[%1215] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1218 = llvm.bitcast %1216 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1218, %1217 : !llvm.ptr<ptr<i8>>
    %1219 = llvm.mlir.constant(7 : i32) : i32
    %1220 = llvm.getelementptr %1188[%1186, 7] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %1220 : !llvm.ptr<i64>
    %1221 = llvm.getelementptr %1190[%1219] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1222 = llvm.bitcast %1220 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1222, %1221 : !llvm.ptr<ptr<i8>>
    %1223 = llvm.mlir.constant(8 : i32) : i32
    %1224 = llvm.getelementptr %1188[%1186, 8] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %1224 : !llvm.ptr<i64>
    %1225 = llvm.getelementptr %1190[%1223] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1226 = llvm.bitcast %1224 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1226, %1225 : !llvm.ptr<ptr<i8>>
    %1227 = llvm.mlir.constant(9 : i32) : i32
    %1228 = llvm.getelementptr %1188[%1186, 9] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %8, %1228 : !llvm.ptr<i64>
    %1229 = llvm.getelementptr %1190[%1227] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1230 = llvm.bitcast %1228 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1230, %1229 : !llvm.ptr<ptr<i8>>
    %1231 = llvm.mlir.constant(10 : i32) : i32
    %1232 = llvm.getelementptr %1188[%1186, 10] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %1183, %1232 : !llvm.ptr<i32>
    %1233 = llvm.getelementptr %1190[%1231] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1234 = llvm.bitcast %1232 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %1234, %1233 : !llvm.ptr<ptr<i8>>
    %1235 = llvm.mlir.constant(11 : i32) : i32
    %1236 = llvm.getelementptr %1188[%1186, 11] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %1185, %1236 : !llvm.ptr<ptr<i8>>
    %1237 = llvm.getelementptr %1190[%1235] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1238 = llvm.bitcast %1236 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %1238, %1237 : !llvm.ptr<ptr<i8>>
    %1239 = llvm.mlir.constant(12 : i32) : i32
    %1240 = llvm.getelementptr %1188[%1186, 12] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %1184, %1240 : !llvm.ptr<i32>
    %1241 = llvm.getelementptr %1190[%1239] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1242 = llvm.bitcast %1240 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %1242, %1241 : !llvm.ptr<ptr<i8>>
    %1243 = llvm.mlir.constant(13 : i32) : i32
    %1244 = llvm.getelementptr %1188[%1186, 13] : (!llvm.ptr<struct<".24", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %1161, %1244 : !llvm.ptr<ptr<ptr<i8>>>
    %1245 = llvm.getelementptr %1190[%1243] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1246 = llvm.bitcast %1244 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %1246, %1245 : !llvm.ptr<ptr<i8>>
    %1247 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %1248 = llvm.mlir.constant(0 : index) : i64
    %1249 = llvm.getelementptr %1247[%1248, %1248] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %1249, %1190) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %1250 = llvm.extractvalue %760[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1251 = llvm.bitcast %1250 : !llvm.ptr to !llvm.ptr
    %1252 = llvm.mlir.constant(0 : i32) : i32
    %1253 = llvm.mlir.constant(1 : i32) : i32
    %1254 = llvm.alloca %1253 x !llvm.struct<".20", (ptr<i8>, ptr)> : (i32) -> !llvm.ptr<struct<".20", (ptr<i8>, ptr)>>
    %1255 = llvm.mlir.constant(2 : i32) : i32
    %1256 = llvm.alloca %1255 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %1257 = llvm.mlir.constant(0 : i32) : i32
    %1258 = llvm.getelementptr %1254[%1252, 0] : (!llvm.ptr<struct<".20", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %1258 : !llvm.ptr<ptr<i8>>
    %1259 = llvm.getelementptr %1256[%1257] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1260 = llvm.bitcast %1258 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %1260, %1259 : !llvm.ptr<ptr<i8>>
    %1261 = llvm.mlir.constant(1 : i32) : i32
    %1262 = llvm.getelementptr %1254[%1252, 1] : (!llvm.ptr<struct<".20", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1251, %1262 : !llvm.ptr<ptr>
    %1263 = llvm.getelementptr %1256[%1261] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1264 = llvm.bitcast %1262 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1264, %1263 : !llvm.ptr<ptr<i8>>
    %1265 = llvm.mlir.addressof @dealloc___gpu___pvoid_pvoid___void : !llvm.ptr<array<35 x i8>>
    %1266 = llvm.mlir.constant(0 : index) : i64
    %1267 = llvm.getelementptr %1265[%1266, %1266] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %1267, %1256) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %1268 = llvm.extractvalue %158[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %1269 = llvm.bitcast %1268 : !llvm.ptr to !llvm.ptr
    %1270 = llvm.mlir.constant(0 : i32) : i32
    %1271 = llvm.mlir.constant(1 : i32) : i32
    %1272 = llvm.alloca %1271 x !llvm.struct<".21", (ptr<i8>, ptr)> : (i32) -> !llvm.ptr<struct<".21", (ptr<i8>, ptr)>>
    %1273 = llvm.mlir.constant(2 : i32) : i32
    %1274 = llvm.alloca %1273 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %1275 = llvm.mlir.constant(0 : i32) : i32
    %1276 = llvm.getelementptr %1272[%1270, 0] : (!llvm.ptr<struct<".21", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %1276 : !llvm.ptr<ptr<i8>>
    %1277 = llvm.getelementptr %1274[%1275] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1278 = llvm.bitcast %1276 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %1278, %1277 : !llvm.ptr<ptr<i8>>
    %1279 = llvm.mlir.constant(1 : i32) : i32
    %1280 = llvm.getelementptr %1272[%1270, 1] : (!llvm.ptr<struct<".21", (ptr<i8>, ptr)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1269, %1280 : !llvm.ptr<ptr>
    %1281 = llvm.getelementptr %1274[%1279] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1282 = llvm.bitcast %1280 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1282, %1281 : !llvm.ptr<ptr<i8>>
    %1283 = llvm.mlir.addressof @dealloc___gpu___pvoid_pvoid___void : !llvm.ptr<array<35 x i8>>
    %1284 = llvm.mlir.constant(0 : index) : i64
    %1285 = llvm.getelementptr %1283[%1284, %1284] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %1285, %1274) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %1286 = llvm.mlir.constant(0 : i32) : i32
    %1287 = llvm.mlir.constant(1 : i32) : i32
    %1288 = llvm.extractvalue %968[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1289 = llvm.extractvalue %968[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1290 = llvm.extractvalue %968[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1291 = llvm.extractvalue %968[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1292 = llvm.extractvalue %968[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1293 = llvm.extractvalue %968[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1294 = llvm.extractvalue %968[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %1295 = llvm.alloca %1287 x !llvm.struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)> : (i32) -> !llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>
    %1296 = llvm.mlir.constant(9 : i32) : i32
    %1297 = llvm.alloca %1296 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %1298 = llvm.mlir.constant(0 : i32) : i32
    %1299 = llvm.getelementptr %1295[%1286, 0] : (!llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %1299 : !llvm.ptr<ptr<i8>>
    %1300 = llvm.getelementptr %1297[%1298] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1301 = llvm.bitcast %1299 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %1301, %1300 : !llvm.ptr<ptr<i8>>
    %1302 = llvm.mlir.constant(1 : i32) : i32
    %1303 = llvm.getelementptr %1295[%1286, 1] : (!llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %11, %1303 : !llvm.ptr<i64>
    %1304 = llvm.getelementptr %1297[%1302] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1305 = llvm.bitcast %1303 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1305, %1304 : !llvm.ptr<ptr<i8>>
    %1306 = llvm.mlir.constant(2 : i32) : i32
    %1307 = llvm.getelementptr %1295[%1286, 2] : (!llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1288, %1307 : !llvm.ptr<ptr>
    %1308 = llvm.getelementptr %1297[%1306] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1309 = llvm.bitcast %1307 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1309, %1308 : !llvm.ptr<ptr<i8>>
    %1310 = llvm.mlir.constant(3 : i32) : i32
    %1311 = llvm.getelementptr %1295[%1286, 3] : (!llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr>
    llvm.store %1289, %1311 : !llvm.ptr<ptr>
    %1312 = llvm.getelementptr %1297[%1310] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1313 = llvm.bitcast %1311 : !llvm.ptr<ptr> to !llvm.ptr<i8>
    llvm.store %1313, %1312 : !llvm.ptr<ptr<i8>>
    %1314 = llvm.mlir.constant(4 : i32) : i32
    %1315 = llvm.getelementptr %1295[%1286, 4] : (!llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1290, %1315 : !llvm.ptr<i64>
    %1316 = llvm.getelementptr %1297[%1314] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1317 = llvm.bitcast %1315 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1317, %1316 : !llvm.ptr<ptr<i8>>
    %1318 = llvm.mlir.constant(5 : i32) : i32
    %1319 = llvm.getelementptr %1295[%1286, 5] : (!llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1291, %1319 : !llvm.ptr<i64>
    %1320 = llvm.getelementptr %1297[%1318] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1321 = llvm.bitcast %1319 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1321, %1320 : !llvm.ptr<ptr<i8>>
    %1322 = llvm.mlir.constant(6 : i32) : i32
    %1323 = llvm.getelementptr %1295[%1286, 6] : (!llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1292, %1323 : !llvm.ptr<i64>
    %1324 = llvm.getelementptr %1297[%1322] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1325 = llvm.bitcast %1323 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1325, %1324 : !llvm.ptr<ptr<i8>>
    %1326 = llvm.mlir.constant(7 : i32) : i32
    %1327 = llvm.getelementptr %1295[%1286, 7] : (!llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1293, %1327 : !llvm.ptr<i64>
    %1328 = llvm.getelementptr %1297[%1326] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1329 = llvm.bitcast %1327 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1329, %1328 : !llvm.ptr<ptr<i8>>
    %1330 = llvm.mlir.constant(8 : i32) : i32
    %1331 = llvm.getelementptr %1295[%1286, 8] : (!llvm.ptr<struct<".22", (ptr<i8>, i64, ptr, ptr, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1294, %1331 : !llvm.ptr<i64>
    %1332 = llvm.getelementptr %1297[%1330] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %1333 = llvm.bitcast %1331 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %1333, %1332 : !llvm.ptr<ptr<i8>>
    %1334 = llvm.mlir.addressof @ral_send_output___cpu___pvoid_i64_m2df32___void : !llvm.ptr<array<48 x i8>>
    %1335 = llvm.mlir.constant(0 : index) : i64
    %1336 = llvm.getelementptr %1334[%1335, %1335] : (!llvm.ptr<array<48 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %1336, %1297) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.return
  }
}


===-------------------------------------------------------------------------===
                         ... Execution time report ...
===-------------------------------------------------------------------------===
  Total Execution Time: 1.3470 seconds

  ----Wall Time----  ----Name----
    0.0002 (  0.0%)  'func.func' Pipeline
    0.0002 (  0.0%)    DiscAlgebraicSimplifierPass
    0.0000 (  0.0%)  DiscInputOutputAliasPass
    0.0000 (  0.0%)  DiscShapePropagatePass
    0.0006 (  0.0%)  Inliner
    0.0000 (  0.0%)    (A) CallGraph
    0.0002 (  0.0%)  'func.func' Pipeline
    0.0002 (  0.0%)    Canonicalizer
    0.0030 (  0.2%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscCollectiveOpsRewriterPass
    0.0001 (  0.0%)    MhloDecompositionRewriterPass
    0.0001 (  0.0%)    RemoveShapeConstraintsPass
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)    DiscTranformWeightDataLayoutForWeightOnlyQuantPass
    0.0001 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)    DiscCustomCallRewriterPass
    0.0001 (  0.0%)    DiscConvertFakeQuantOpPass
    0.0001 (  0.0%)    DiscLowerGpuQuantizeAndDequantizePass
    0.0022 (  0.2%)    ConvertShapeToStandardPass
    0.0064 (  0.5%)  DiscShapeOptimizationPass
    0.0032 (  0.2%)  'builtin.func' Pipeline
    0.0031 (  0.2%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0027 (  0.2%)  'func.func' Pipeline
    0.0001 (  0.0%)    ConvertTensorToStandardPass
    0.0000 (  0.0%)    ConvertHloToStandardPass
    0.0002 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0010 (  0.1%)    DiscAlgebraicSimplifierPass
    0.0001 (  0.0%)    SplitLargeOpsPass
    0.0011 (  0.1%)    DotRewriterPass
    0.0026 (  0.2%)  DiscShapeOptimizationPass
    0.0001 (  0.0%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscDotMergePass
    0.0026 (  0.2%)  DiscShapeOptimizationPass
    0.0000 (  0.0%)  'func.func' Pipeline
    0.0000 (  0.0%)    HloCanonicalizeReductionPass
    0.0025 (  0.2%)  DiscShapeOptimizationPass
    0.0012 (  0.1%)  DiscMarkShapeCalculationPass
    0.0013 (  0.1%)  PlaceOpsPass
    0.0006 (  0.0%)  'func.func' Pipeline
    0.0002 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)    ElementTypeConverterPass
    0.0027 (  0.2%)  DiscShapeOptimizationPass
    0.0002 (  0.0%)  'func.func' Pipeline
    0.0001 (  0.0%)    ReductionRewriterPass
    0.0001 (  0.0%)    ConvRewriterPass
    0.0000 (  0.0%)    ConvRewriterPass
    0.0000 (  0.0%)    QuantizedDotRewriterPass
    0.0027 (  0.2%)  DiscShapeOptimizationPass
    0.0017 (  0.1%)  'func.func' Pipeline
    0.0002 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0012 (  0.1%)    TransposeSimplifierPass
    0.0000 (  0.0%)    GpuConvPaddingLegalizationPass
    0.0027 (  0.2%)  DiscShapeOptimizationPass
    0.0001 (  0.0%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscAlgebraicSimplifierPass
    0.0035 (  0.3%)  DiscShapeOptimizationPass
    0.0025 (  0.2%)  'func.func' Pipeline
    0.0021 (  0.2%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0004 (  0.0%)    Canonicalizer
    0.0022 (  0.2%)  FuncBufferize
    0.0030 (  0.2%)  DiscHloLegalizeToLhloPass
    0.0053 (  0.4%)  HloLegalizeToLhloPass
    0.0029 (  0.2%)  'func.func' Pipeline
    0.0029 (  0.2%)    Canonicalizer
    0.0001 (  0.0%)  DiscLhloRewriterPass
    0.0062 (  0.5%)  'func.func' Pipeline
    0.0002 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)    ConvertShapeToStandardPass
    0.0002 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0026 (  0.2%)    LegalizeToTensorOpPass
    0.0027 (  0.2%)    Canonicalizer
    0.0001 (  0.0%)    StdBufferizePass
    0.0001 (  0.0%)  ArithBufferize
    0.0076 (  0.6%)  'func.func' Pipeline
    0.0025 (  0.2%)    TensorBufferize
    0.0001 (  0.0%)    FinalizingBufferize
    0.0028 (  0.2%)    Canonicalizer
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0019 (  0.1%)    DiscMemrefCanonicalizer
    0.0024 (  0.2%)  DiscAssignMemorySpacePass
    0.0208 (  1.5%)  'func.func' Pipeline
    0.0025 (  0.2%)    DiscDuplicateComputationForFusionPass
    0.0025 (  0.2%)    PromoteBuffersToStack
    0.0001 (  0.0%)    DiscMemRefLoadStoreSimplifierPass
    0.0030 (  0.2%)    DiscFusionPass
    0.0001 (  0.0%)    DiscFuseSplatConstPass
    0.0043 (  0.3%)    DiscSpecializeFusionWithSpeculationPass
    0.0041 (  0.3%)    Canonicalizer
    0.0038 (  0.3%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0004 (  0.0%)    Canonicalizer
    0.0002 (  0.0%)  DiscOptimizationBarrierExpandPass
    0.0006 (  0.0%)  'func.func' Pipeline
    0.0002 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)  DiscOpSchedulePass
    0.0080 (  0.6%)  'func.func' Pipeline
    0.0037 (  0.3%)    DiscReduceBufferLiveRangePass
    0.0041 (  0.3%)    BufferDeallocation
    0.0001 (  0.0%)    DiscBufferDeallocationPass
    0.0044 (  0.3%)  RalInjectExecutionContextPass
    0.0049 (  0.4%)  'func.func' Pipeline
    0.0049 (  0.4%)    DiscLowerToLibraryCallPass
    0.0059 (  0.4%)  DiscConstToRALPass
    0.1211 (  9.0%)  'func.func' Pipeline
    0.0050 (  0.4%)    DiscMemRefLoadStoreSimplifierPass
    0.0068 (  0.5%)    DiscLhloLegalizeRootsToParallelLoopsPass
    0.0003 (  0.0%)    ExpandOps
    0.0003 (  0.0%)    UnhandledAtomicRMWConverterPass
    0.0051 (  0.4%)    InputInlineFusionPass
    0.0075 (  0.6%)    ForLoopUnrollInterleave
    0.0074 (  0.5%)    DiscBF16ExpansionPass
    0.0077 (  0.6%)    ArithExpandOps
    0.0077 (  0.6%)    FoldMemRefAliasOps
    0.0160 (  1.2%)    DiscFlattenMemrefAccessPass
    0.0113 (  0.8%)    Canonicalizer
    0.0080 (  0.6%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0006 (  0.0%)    Canonicalizer
    0.0008 (  0.1%)    DiscMemRefCSEPass
    0.0067 (  0.5%)    ConvertShapeToStandardPass
    0.0068 (  0.5%)    Canonicalizer
    0.0002 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0006 (  0.0%)    Canonicalizer
    0.0002 (  0.0%)    ParallelLoopCollapsing
    0.0069 (  0.5%)    SCFParallelLoopTiling
    0.0072 (  0.5%)    GpuMapParallelLoopsPass
    0.0080 (  0.6%)    ConvertParallelLoopToGpu
    0.0005 (  0.0%)  'func' Pipeline
    0.0005 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0087 (  0.6%)  GpuLaunchSinkIndexComputations
    0.0100 (  0.7%)  GpuKernelOutlining
    0.0098 (  0.7%)  AssignKernelNamePass
    0.0031 (  0.2%)  'func.func' Pipeline
    0.0031 (  0.2%)    LhloFusionInlinerPass
    0.0090 (  0.7%)  DiscArgsMutationExpandPass
    0.0004 (  0.0%)  DiscCompIntensFusionToCUDASourcePass
    0.0003 (  0.0%)  ReviseGpuKernelOutliningPass
    0.7462 ( 55.4%)  'gpu.module' Pipeline
    0.0010 (  0.1%)    LoopInvariantCodeMotion
    0.0013 (  0.1%)    'gpu.func' Pipeline
    0.0012 (  0.1%)      SideEffectLoopInvariantCodeMotionPass
    0.0005 (  0.0%)    LoopInvariantCodeMotion
    0.0111 (  0.8%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0016 (  0.1%)    'gpu.func' Pipeline
    0.0005 (  0.0%)      DiscEraseBufferDeallocationPass
    0.0010 (  0.1%)      ExpandStridedMetadata
    0.0111 (  0.8%)    SCFToControlFlow
    0.0100 (  0.7%)    ConvertAffineToStandard
    0.0093 (  0.7%)    StripDebugInfo
    0.0318 (  2.4%)    DiscLowerGpuOpsToNVVMOpsPass
    0.0128 (  1.0%)    'llvm.func' Pipeline
    0.0128 (  1.0%)      LLVMInsertValueSimplifierPass
    0.0118 (  0.9%)    FunctionDeadArgumentEliminationPass
    0.6434 ( 47.8%)    GpuKernelToBlobPass
    0.0017 (  0.1%)  DiscGPUSourceToLibPass
    0.0114 (  0.8%)  'func.func' Pipeline
    0.0096 (  0.7%)    Canonicalizer
    0.0003 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0008 (  0.1%)    Canonicalizer
    0.0002 (  0.0%)    RemoveDeadBufferPass
    0.0005 (  0.0%)    LinalgLowerToLoops
    0.0710 (  5.3%)  SCFToControlFlow
    0.0042 (  0.3%)  'func.func' Pipeline
    0.0004 (  0.0%)    ExpandStridedMetadata
    0.0034 (  0.2%)    Canonicalizer
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0003 (  0.0%)    Canonicalizer
    0.0475 (  3.5%)  ConvertAffineToStandard
    0.0456 (  3.4%)  StripDebugInfo
    0.0451 (  3.4%)  DiscStripShapeConstraintOpsPass
    0.0848 (  6.3%)  DiscToLLVMPass
    0.0078 (  0.6%)  Rest
    1.3470 (100.0%)  Total
[DISC] LowerHLOToLLVM takes: 1.348147e+00 s.
before optimize llvm module:
; ModuleID = 'LLVMDialectModule'
source_filename = "LLVMDialectModule"

%0 = type { ptr, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.1 = type { ptr, ptr, ptr, i32, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.2 = type { ptr, ptr, ptr, i32, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.3 = type { ptr, ptr, ptr, i32, { ptr, ptr, i64, [1 x i64], [1 x i64] } }
%.4 = type { ptr, ptr, ptr, i32, { ptr, ptr, i64, [1 x i64], [1 x i64] } }
%.5 = type { ptr, i64, ptr }
%.6 = type { ptr, ptr, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1 }
%.7 = type { ptr, ptr }
%.8 = type { ptr, i64, ptr }
%.9 = type { i64, i64, ptr, ptr, ptr }
%.10 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.25 = type { i64, i64, ptr, ptr, ptr }
%.26 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.11 = type { ptr, ptr }
%.12 = type { ptr, ptr }
%.13 = type { ptr, i64, ptr }
%.14 = type { ptr, ptr, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1 }
%.15 = type { ptr, ptr }
%.16 = type { ptr, ptr }
%.17 = type { ptr, i64, ptr }
%.18 = type { i64, i64, ptr, ptr, ptr }
%.19 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.23 = type { i64, i64, ptr, ptr, ptr }
%.24 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.20 = type { ptr, ptr }
%.21 = type { ptr, ptr }
%.22 = type { ptr, i64, ptr, ptr, i64, i64, i64, i64, i64 }

@main_kernel_0_main_kLoop_maximum__5_1_0_kernel_name = internal constant [26 x i8] c"main_kLoop_maximum__5_1_0\00"
@main_kernel_0_blob_gpu.binary_sm_75 = internal constant [1200 x i8] c"P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"
@main_kernel_0_blob_gpu.binary_sm_70 = internal constant [1216 x i8] c"P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"
@main_kernel_0_blob_gpu.binary_compute_60 = internal constant [688 x i8] c"P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_0(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00"
@main_kernel_2_main_kLoop_maximum__5_1_1_kernel_name = internal constant [26 x i8] c"main_kLoop_maximum__5_1_1\00"
@main_kernel_2_blob_gpu.binary_sm_75 = internal constant [1200 x i8] c"P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"
@main_kernel_2_blob_gpu.binary_sm_70 = internal constant [1216 x i8] c"P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"
@main_kernel_2_blob_gpu.binary_compute_60 = internal constant [688 x i8] c"P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_1(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00"
@ral_send_output___cpu___pvoid_i64_m2df32___void = internal constant [48 x i8] c"ral_send_output___cpu___pvoid_i64_m2df32___void\00"
@main_kernel_1_main_kLoop_maximum__5_1_1___Vec4_kernel_name = internal constant [33 x i8] c"main_kLoop_maximum__5_1_1___Vec4\00"
@main_kernel_1_blob_gpu.binary_sm_75 = internal constant [1472 x i8] c"P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00Z\00\00\13p\00\10\C8\10\00\84\02\00\00\\\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"
@main_kernel_1_blob_gpu.binary_sm_70 = internal constant [1512 x i8] c"P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00Zp\03\03\E0\00Sv\04\00\00\\p\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00"
@main_kernel_1_blob_gpu.binary_compute_60 = internal constant [1048 x i8] c"P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BD\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_1___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,\9F\02\00\22\00\01y\02\91global.v4\1A\040{%f\C4\00\10f\22\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\C5\02\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00\02\B6\02\03S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\01\C4\01\04U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00"
@ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void = internal constant [101 x i8] c"ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00"
@main_kernel_main_kLoop_maximum__5_1_0___Vec4_kernel_name = internal constant [33 x i8] c"main_kLoop_maximum__5_1_0___Vec4\00"
@main_kernel_blob_gpu.binary_sm_75 = internal constant [1472 x i8] c"P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00\\\00\00\13p\00\10\C8\10\00\84\02\00\00Z\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"
@main_kernel_blob_gpu.binary_sm_70 = internal constant [1512 x i8] c"P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00\\p\03\03\E0\00Sv\04\00\00Zp\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00"
@main_kernel_blob_gpu.binary_compute_60 = internal constant [1048 x i8] c"P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BA\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_0___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,`\02\00\22\00\01y\02\91global.v4\1A\040{%f\1D\00\10f\AD\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\04\03\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00'11S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\183U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00\00\00\00"
@dealloc___gpu___pvoid_pvoid___void = internal constant [35 x i8] c"dealloc___gpu___pvoid_pvoid___void\00"
@ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void = internal constant [66 x i8] c"ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void\00"
@alloc___gpu___pvoid_i64___pvoid = internal constant [32 x i8] c"alloc___gpu___pvoid_i64___pvoid\00"
@ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32 = internal constant [49 x i8] c"ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32\00"
@ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32 = internal constant [49 x i8] c"ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32\00"
@ral_recv_input___cpu___pvoid_i64___m2df32 = internal constant [42 x i8] c"ral_recv_input___cpu___pvoid_i64___m2df32\00"
@__global_const_3 = internal constant [40 x i8] c"3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00"
@__global_const_2 = internal constant [40 x i8] c"21438FB9F9F436186309DCC96AB50683_f32_10\00"
@__global_const_1 = internal constant [43 x i8] c"857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00"
@__global_const_0 = internal constant [43 x i8] c"08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00"

declare ptr @malloc(i64)

declare void @free(ptr)

declare void @disc_ral_call(ptr, ptr, ptr)

define void @main(ptr %0) {
  %2 = alloca %0, align 8
  %3 = alloca ptr, i32 3, align 8
  %4 = getelementptr %0, ptr %2, i32 0, i32 0
  store ptr %0, ptr %4, align 8
  %5 = getelementptr ptr, ptr %3, i32 0
  store ptr %4, ptr %5, align 8
  %6 = getelementptr %0, ptr %2, i32 0, i32 1
  store i64 0, ptr %6, align 4
  %7 = getelementptr ptr, ptr %3, i32 1
  store ptr %6, ptr %7, align 8
  %8 = getelementptr %0, ptr %2, i32 0, i32 2
  %9 = getelementptr ptr, ptr %3, i32 2
  store ptr %8, ptr %9, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_recv_input___cpu___pvoid_i64___m2df32, ptr %3)
  %10 = load { ptr, ptr, i64, [2 x i64], [2 x i64] }, ptr %8, align 8
  %11 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 3, 0
  %12 = alloca %.1, align 8
  %13 = alloca ptr, i32 5, align 8
  %14 = getelementptr %.1, ptr %12, i32 0, i32 0
  store ptr %0, ptr %14, align 8
  %15 = getelementptr ptr, ptr %13, i32 0
  store ptr %14, ptr %15, align 8
  %16 = getelementptr %.1, ptr %12, i32 0, i32 1
  store ptr null, ptr %16, align 8
  %17 = getelementptr ptr, ptr %13, i32 1
  store ptr %16, ptr %17, align 8
  %18 = getelementptr %.1, ptr %12, i32 0, i32 2
  store ptr @__global_const_0, ptr %18, align 8
  %19 = getelementptr ptr, ptr %13, i32 2
  store ptr %18, ptr %19, align 8
  %20 = getelementptr %.1, ptr %12, i32 0, i32 3
  store i32 0, ptr %20, align 4
  %21 = getelementptr ptr, ptr %13, i32 3
  store ptr %20, ptr %21, align 8
  %22 = getelementptr %.1, ptr %12, i32 0, i32 4
  %23 = getelementptr ptr, ptr %13, i32 4
  store ptr %22, ptr %23, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32, ptr %13)
  %24 = load { ptr, ptr, i64, [2 x i64], [2 x i64] }, ptr %22, align 8
  %25 = alloca %.2, align 8
  %26 = alloca ptr, i32 5, align 8
  %27 = getelementptr %.2, ptr %25, i32 0, i32 0
  store ptr %0, ptr %27, align 8
  %28 = getelementptr ptr, ptr %26, i32 0
  store ptr %27, ptr %28, align 8
  %29 = getelementptr %.2, ptr %25, i32 0, i32 1
  store ptr null, ptr %29, align 8
  %30 = getelementptr ptr, ptr %26, i32 1
  store ptr %29, ptr %30, align 8
  %31 = getelementptr %.2, ptr %25, i32 0, i32 2
  store ptr @__global_const_1, ptr %31, align 8
  %32 = getelementptr ptr, ptr %26, i32 2
  store ptr %31, ptr %32, align 8
  %33 = getelementptr %.2, ptr %25, i32 0, i32 3
  store i32 1, ptr %33, align 4
  %34 = getelementptr ptr, ptr %26, i32 3
  store ptr %33, ptr %34, align 8
  %35 = getelementptr %.2, ptr %25, i32 0, i32 4
  %36 = getelementptr ptr, ptr %26, i32 4
  store ptr %35, ptr %36, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32, ptr %26)
  %37 = load { ptr, ptr, i64, [2 x i64], [2 x i64] }, ptr %35, align 8
  %38 = alloca %.3, align 8
  %39 = alloca ptr, i32 5, align 8
  %40 = getelementptr %.3, ptr %38, i32 0, i32 0
  store ptr %0, ptr %40, align 8
  %41 = getelementptr ptr, ptr %39, i32 0
  store ptr %40, ptr %41, align 8
  %42 = getelementptr %.3, ptr %38, i32 0, i32 1
  store ptr null, ptr %42, align 8
  %43 = getelementptr ptr, ptr %39, i32 1
  store ptr %42, ptr %43, align 8
  %44 = getelementptr %.3, ptr %38, i32 0, i32 2
  store ptr @__global_const_2, ptr %44, align 8
  %45 = getelementptr ptr, ptr %39, i32 2
  store ptr %44, ptr %45, align 8
  %46 = getelementptr %.3, ptr %38, i32 0, i32 3
  store i32 2, ptr %46, align 4
  %47 = getelementptr ptr, ptr %39, i32 3
  store ptr %46, ptr %47, align 8
  %48 = getelementptr %.3, ptr %38, i32 0, i32 4
  %49 = getelementptr ptr, ptr %39, i32 4
  store ptr %48, ptr %49, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32, ptr %39)
  %50 = load { ptr, ptr, i64, [1 x i64], [1 x i64] }, ptr %48, align 8
  %51 = alloca %.4, align 8
  %52 = alloca ptr, i32 5, align 8
  %53 = getelementptr %.4, ptr %51, i32 0, i32 0
  store ptr %0, ptr %53, align 8
  %54 = getelementptr ptr, ptr %52, i32 0
  store ptr %53, ptr %54, align 8
  %55 = getelementptr %.4, ptr %51, i32 0, i32 1
  store ptr null, ptr %55, align 8
  %56 = getelementptr ptr, ptr %52, i32 1
  store ptr %55, ptr %56, align 8
  %57 = getelementptr %.4, ptr %51, i32 0, i32 2
  store ptr @__global_const_3, ptr %57, align 8
  %58 = getelementptr ptr, ptr %52, i32 2
  store ptr %57, ptr %58, align 8
  %59 = getelementptr %.4, ptr %51, i32 0, i32 3
  store i32 3, ptr %59, align 4
  %60 = getelementptr ptr, ptr %52, i32 3
  store ptr %59, ptr %60, align 8
  %61 = getelementptr %.4, ptr %51, i32 0, i32 4
  %62 = getelementptr ptr, ptr %52, i32 4
  store ptr %61, ptr %62, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32, ptr %52)
  %63 = load { ptr, ptr, i64, [1 x i64], [1 x i64] }, ptr %61, align 8
  %64 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 0
  %65 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 1
  %66 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } undef, ptr %64, 0
  %67 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %66, ptr %65, 1
  %68 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %67, i64 0, 2
  %69 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %68, i64 %11, 3, 0
  %70 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %69, i64 10, 4, 0
  %71 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %70, i64 10, 3, 1
  %72 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %71, i64 1, 4, 1
  %73 = mul i64 10, %11
  %74 = getelementptr float, ptr null, i64 %73
  %75 = ptrtoint ptr %74 to i64
  %76 = alloca %.5, align 8
  %77 = alloca ptr, i32 3, align 8
  %78 = getelementptr %.5, ptr %76, i32 0, i32 0
  store ptr %0, ptr %78, align 8
  %79 = getelementptr ptr, ptr %77, i32 0
  store ptr %78, ptr %79, align 8
  %80 = getelementptr %.5, ptr %76, i32 0, i32 1
  store i64 %75, ptr %80, align 4
  %81 = getelementptr ptr, ptr %77, i32 1
  store ptr %80, ptr %81, align 8
  %82 = getelementptr %.5, ptr %76, i32 0, i32 2
  %83 = getelementptr ptr, ptr %77, i32 2
  store ptr %82, ptr %83, align 8
  call void @disc_ral_call(ptr %0, ptr @alloc___gpu___pvoid_i64___pvoid, ptr %77)
  %84 = load ptr, ptr %82, align 8
  %85 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } undef, ptr %84, 0
  %86 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %85, ptr %84, 1
  %87 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %86, i64 0, 2
  %88 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %87, i64 10, 3, 1
  %89 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %88, i64 1, 4, 1
  %90 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %89, i64 %11, 3, 0
  %91 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %90, i64 10, 4, 0
  %92 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %72, 0
  %93 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %72, 1
  %94 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %72, 2
  %95 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %72, 3, 0
  %96 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %72, 3, 1
  %97 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %72, 4, 0
  %98 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %72, 4, 1
  %99 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %37, 0
  %100 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %37, 1
  %101 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %37, 2
  %102 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %37, 3, 0
  %103 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %37, 3, 1
  %104 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %37, 4, 0
  %105 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %37, 4, 1
  %106 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 0
  %107 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 1
  %108 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 2
  %109 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 3, 0
  %110 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 3, 1
  %111 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 4, 0
  %112 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 4, 1
  %113 = alloca %.6, align 8
  %114 = alloca ptr, i32 26, align 8
  %115 = getelementptr %.6, ptr %113, i32 0, i32 0
  store ptr %0, ptr %115, align 8
  %116 = getelementptr ptr, ptr %114, i32 0
  store ptr %115, ptr %116, align 8
  %117 = getelementptr %.6, ptr %113, i32 0, i32 1
  store ptr null, ptr %117, align 8
  %118 = getelementptr ptr, ptr %114, i32 1
  store ptr %117, ptr %118, align 8
  %119 = getelementptr %.6, ptr %113, i32 0, i32 2
  store ptr %92, ptr %119, align 8
  %120 = getelementptr ptr, ptr %114, i32 2
  store ptr %119, ptr %120, align 8
  %121 = getelementptr %.6, ptr %113, i32 0, i32 3
  store ptr %93, ptr %121, align 8
  %122 = getelementptr ptr, ptr %114, i32 3
  store ptr %121, ptr %122, align 8
  %123 = getelementptr %.6, ptr %113, i32 0, i32 4
  store i64 %94, ptr %123, align 4
  %124 = getelementptr ptr, ptr %114, i32 4
  store ptr %123, ptr %124, align 8
  %125 = getelementptr %.6, ptr %113, i32 0, i32 5
  store i64 %95, ptr %125, align 4
  %126 = getelementptr ptr, ptr %114, i32 5
  store ptr %125, ptr %126, align 8
  %127 = getelementptr %.6, ptr %113, i32 0, i32 6
  store i64 %96, ptr %127, align 4
  %128 = getelementptr ptr, ptr %114, i32 6
  store ptr %127, ptr %128, align 8
  %129 = getelementptr %.6, ptr %113, i32 0, i32 7
  store i64 %97, ptr %129, align 4
  %130 = getelementptr ptr, ptr %114, i32 7
  store ptr %129, ptr %130, align 8
  %131 = getelementptr %.6, ptr %113, i32 0, i32 8
  store i64 %98, ptr %131, align 4
  %132 = getelementptr ptr, ptr %114, i32 8
  store ptr %131, ptr %132, align 8
  %133 = getelementptr %.6, ptr %113, i32 0, i32 9
  store ptr %99, ptr %133, align 8
  %134 = getelementptr ptr, ptr %114, i32 9
  store ptr %133, ptr %134, align 8
  %135 = getelementptr %.6, ptr %113, i32 0, i32 10
  store ptr %100, ptr %135, align 8
  %136 = getelementptr ptr, ptr %114, i32 10
  store ptr %135, ptr %136, align 8
  %137 = getelementptr %.6, ptr %113, i32 0, i32 11
  store i64 %101, ptr %137, align 4
  %138 = getelementptr ptr, ptr %114, i32 11
  store ptr %137, ptr %138, align 8
  %139 = getelementptr %.6, ptr %113, i32 0, i32 12
  store i64 %102, ptr %139, align 4
  %140 = getelementptr ptr, ptr %114, i32 12
  store ptr %139, ptr %140, align 8
  %141 = getelementptr %.6, ptr %113, i32 0, i32 13
  store i64 %103, ptr %141, align 4
  %142 = getelementptr ptr, ptr %114, i32 13
  store ptr %141, ptr %142, align 8
  %143 = getelementptr %.6, ptr %113, i32 0, i32 14
  store i64 %104, ptr %143, align 4
  %144 = getelementptr ptr, ptr %114, i32 14
  store ptr %143, ptr %144, align 8
  %145 = getelementptr %.6, ptr %113, i32 0, i32 15
  store i64 %105, ptr %145, align 4
  %146 = getelementptr ptr, ptr %114, i32 15
  store ptr %145, ptr %146, align 8
  %147 = getelementptr %.6, ptr %113, i32 0, i32 16
  store ptr %106, ptr %147, align 8
  %148 = getelementptr ptr, ptr %114, i32 16
  store ptr %147, ptr %148, align 8
  %149 = getelementptr %.6, ptr %113, i32 0, i32 17
  store ptr %107, ptr %149, align 8
  %150 = getelementptr ptr, ptr %114, i32 17
  store ptr %149, ptr %150, align 8
  %151 = getelementptr %.6, ptr %113, i32 0, i32 18
  store i64 %108, ptr %151, align 4
  %152 = getelementptr ptr, ptr %114, i32 18
  store ptr %151, ptr %152, align 8
  %153 = getelementptr %.6, ptr %113, i32 0, i32 19
  store i64 %109, ptr %153, align 4
  %154 = getelementptr ptr, ptr %114, i32 19
  store ptr %153, ptr %154, align 8
  %155 = getelementptr %.6, ptr %113, i32 0, i32 20
  store i64 %110, ptr %155, align 4
  %156 = getelementptr ptr, ptr %114, i32 20
  store ptr %155, ptr %156, align 8
  %157 = getelementptr %.6, ptr %113, i32 0, i32 21
  store i64 %111, ptr %157, align 4
  %158 = getelementptr ptr, ptr %114, i32 21
  store ptr %157, ptr %158, align 8
  %159 = getelementptr %.6, ptr %113, i32 0, i32 22
  store i64 %112, ptr %159, align 4
  %160 = getelementptr ptr, ptr %114, i32 22
  store ptr %159, ptr %160, align 8
  %161 = getelementptr %.6, ptr %113, i32 0, i32 23
  store i1 false, ptr %161, align 1
  %162 = getelementptr ptr, ptr %114, i32 23
  store ptr %161, ptr %162, align 8
  %163 = getelementptr %.6, ptr %113, i32 0, i32 24
  store i1 false, ptr %163, align 1
  %164 = getelementptr ptr, ptr %114, i32 24
  store ptr %163, ptr %164, align 8
  %165 = getelementptr %.6, ptr %113, i32 0, i32 25
  store i1 true, ptr %165, align 1
  %166 = getelementptr ptr, ptr %114, i32 25
  store ptr %165, ptr %166, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void, ptr %114)
  %167 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %37, 0
  %168 = alloca %.7, align 8
  %169 = alloca ptr, i32 2, align 8
  %170 = getelementptr %.7, ptr %168, i32 0, i32 0
  store ptr %0, ptr %170, align 8
  %171 = getelementptr ptr, ptr %169, i32 0
  store ptr %170, ptr %171, align 8
  %172 = getelementptr %.7, ptr %168, i32 0, i32 1
  store ptr %167, ptr %172, align 8
  %173 = getelementptr ptr, ptr %169, i32 1
  store ptr %172, ptr %173, align 8
  call void @disc_ral_call(ptr %0, ptr @dealloc___gpu___pvoid_pvoid___void, ptr %169)
  %174 = mul i64 %11, 10
  %175 = urem i64 %174, 4
  %176 = icmp eq i64 %175, 0
  %177 = mul i64 10, %11
  %178 = getelementptr float, ptr null, i64 %177
  %179 = ptrtoint ptr %178 to i64
  %180 = alloca %.8, align 8
  %181 = alloca ptr, i32 3, align 8
  %182 = getelementptr %.8, ptr %180, i32 0, i32 0
  store ptr %0, ptr %182, align 8
  %183 = getelementptr ptr, ptr %181, i32 0
  store ptr %182, ptr %183, align 8
  %184 = getelementptr %.8, ptr %180, i32 0, i32 1
  store i64 %179, ptr %184, align 4
  %185 = getelementptr ptr, ptr %181, i32 1
  store ptr %184, ptr %185, align 8
  %186 = getelementptr %.8, ptr %180, i32 0, i32 2
  %187 = getelementptr ptr, ptr %181, i32 2
  store ptr %186, ptr %187, align 8
  call void @disc_ral_call(ptr %0, ptr @alloc___gpu___pvoid_i64___pvoid, ptr %181)
  %188 = load ptr, ptr %186, align 8
  %189 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } undef, ptr %188, 0
  %190 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %189, ptr %188, 1
  %191 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %190, i64 0, 2
  %192 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %191, i64 10, 3, 1
  %193 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %192, i64 1, 4, 1
  %194 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %193, i64 %11, 3, 0
  %195 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %194, i64 10, 4, 0
  br i1 %176, label %196, label %271

196:                                              ; preds = %1
  %197 = udiv i64 %174, 4
  %198 = icmp sle i64 %197, 0
  %199 = sub i64 0, %197
  %200 = sub i64 %197, 1
  %201 = select i1 %198, i64 %199, i64 %200
  %202 = sdiv i64 %201, 256
  %203 = sub i64 0, %202
  %204 = add i64 %202, 1
  %205 = select i1 %198, i64 %203, i64 %204
  %206 = alloca ptr, i32 3, align 8
  %207 = getelementptr ptr, ptr %206, i32 0
  store ptr @main_kernel_blob_gpu.binary_compute_60, ptr %207, align 8
  %208 = getelementptr ptr, ptr %206, i32 1
  store ptr @main_kernel_blob_gpu.binary_sm_70, ptr %208, align 8
  %209 = getelementptr ptr, ptr %206, i32 2
  store ptr @main_kernel_blob_gpu.binary_sm_75, ptr %209, align 8
  %210 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 0
  %211 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 1
  %212 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 2
  %213 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 3, 0
  %214 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 3, 1
  %215 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 4, 0
  %216 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 4, 1
  %217 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 0
  %218 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 1
  %219 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 2
  %220 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 3, 0
  %221 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 4, 0
  %222 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 0
  %223 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 1
  %224 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 2
  %225 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 3, 0
  %226 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 3, 1
  %227 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 4, 0
  %228 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 4, 1
  %229 = alloca %.9, align 8
  %230 = alloca ptr, i32 5, align 8
  %231 = getelementptr %.9, ptr %229, i32 0, i32 0
  store i64 256, ptr %231, align 4
  %232 = getelementptr ptr, ptr %230, i32 0
  store ptr %231, ptr %232, align 8
  %233 = getelementptr %.9, ptr %229, i32 0, i32 1
  store i64 %197, ptr %233, align 4
  %234 = getelementptr ptr, ptr %230, i32 1
  store ptr %233, ptr %234, align 8
  %235 = getelementptr %.9, ptr %229, i32 0, i32 2
  store ptr %211, ptr %235, align 8
  %236 = getelementptr ptr, ptr %230, i32 2
  store ptr %235, ptr %236, align 8
  %237 = getelementptr %.9, ptr %229, i32 0, i32 3
  store ptr %218, ptr %237, align 8
  %238 = getelementptr ptr, ptr %230, i32 3
  store ptr %237, ptr %238, align 8
  %239 = getelementptr %.9, ptr %229, i32 0, i32 4
  store ptr %223, ptr %239, align 8
  %240 = getelementptr ptr, ptr %230, i32 4
  store ptr %239, ptr %240, align 8
  %241 = alloca %.10, align 8
  %242 = alloca ptr, i32 14, align 8
  %243 = getelementptr %.10, ptr %241, i32 0, i32 0
  store ptr %0, ptr %243, align 8
  %244 = getelementptr ptr, ptr %242, i32 0
  store ptr %243, ptr %244, align 8
  %245 = getelementptr %.10, ptr %241, i32 0, i32 1
  store ptr %206, ptr %245, align 8
  %246 = getelementptr ptr, ptr %242, i32 1
  store ptr %245, ptr %246, align 8
  %247 = getelementptr %.10, ptr %241, i32 0, i32 2
  store i64 3, ptr %247, align 4
  %248 = getelementptr ptr, ptr %242, i32 2
  store ptr %247, ptr %248, align 8
  %249 = getelementptr %.10, ptr %241, i32 0, i32 3
  store ptr @main_kernel_main_kLoop_maximum__5_1_0___Vec4_kernel_name, ptr %249, align 8
  %250 = getelementptr ptr, ptr %242, i32 3
  store ptr %249, ptr %250, align 8
  %251 = getelementptr %.10, ptr %241, i32 0, i32 4
  store i64 %205, ptr %251, align 4
  %252 = getelementptr ptr, ptr %242, i32 4
  store ptr %251, ptr %252, align 8
  %253 = getelementptr %.10, ptr %241, i32 0, i32 5
  store i64 1, ptr %253, align 4
  %254 = getelementptr ptr, ptr %242, i32 5
  store ptr %253, ptr %254, align 8
  %255 = getelementptr %.10, ptr %241, i32 0, i32 6
  store i64 1, ptr %255, align 4
  %256 = getelementptr ptr, ptr %242, i32 6
  store ptr %255, ptr %256, align 8
  %257 = getelementptr %.10, ptr %241, i32 0, i32 7
  store i64 256, ptr %257, align 4
  %258 = getelementptr ptr, ptr %242, i32 7
  store ptr %257, ptr %258, align 8
  %259 = getelementptr %.10, ptr %241, i32 0, i32 8
  store i64 1, ptr %259, align 4
  %260 = getelementptr ptr, ptr %242, i32 8
  store ptr %259, ptr %260, align 8
  %261 = getelementptr %.10, ptr %241, i32 0, i32 9
  store i64 1, ptr %261, align 4
  %262 = getelementptr ptr, ptr %242, i32 9
  store ptr %261, ptr %262, align 8
  %263 = getelementptr %.10, ptr %241, i32 0, i32 10
  store i32 0, ptr %263, align 4
  %264 = getelementptr ptr, ptr %242, i32 10
  store ptr %263, ptr %264, align 8
  %265 = getelementptr %.10, ptr %241, i32 0, i32 11
  store ptr null, ptr %265, align 8
  %266 = getelementptr ptr, ptr %242, i32 11
  store ptr %265, ptr %266, align 8
  %267 = getelementptr %.10, ptr %241, i32 0, i32 12
  store i32 5, ptr %267, align 4
  %268 = getelementptr ptr, ptr %242, i32 12
  store ptr %267, ptr %268, align 8
  %269 = getelementptr %.10, ptr %241, i32 0, i32 13
  store ptr %230, ptr %269, align 8
  %270 = getelementptr ptr, ptr %242, i32 13
  store ptr %269, ptr %270, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %242)
  br label %345

271:                                              ; preds = %1
  %272 = icmp sle i64 %174, 0
  %273 = sub i64 0, %174
  %274 = sub i64 %174, 1
  %275 = select i1 %272, i64 %273, i64 %274
  %276 = sdiv i64 %275, 256
  %277 = sub i64 0, %276
  %278 = add i64 %276, 1
  %279 = select i1 %272, i64 %277, i64 %278
  %280 = alloca ptr, i32 3, align 8
  %281 = getelementptr ptr, ptr %280, i32 0
  store ptr @main_kernel_0_blob_gpu.binary_compute_60, ptr %281, align 8
  %282 = getelementptr ptr, ptr %280, i32 1
  store ptr @main_kernel_0_blob_gpu.binary_sm_70, ptr %282, align 8
  %283 = getelementptr ptr, ptr %280, i32 2
  store ptr @main_kernel_0_blob_gpu.binary_sm_75, ptr %283, align 8
  %284 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 0
  %285 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 1
  %286 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 2
  %287 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 3, 0
  %288 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 3, 1
  %289 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 4, 0
  %290 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 4, 1
  %291 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 0
  %292 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 1
  %293 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 2
  %294 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 3, 0
  %295 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 4, 0
  %296 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 0
  %297 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 1
  %298 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 2
  %299 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 3, 0
  %300 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 3, 1
  %301 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 4, 0
  %302 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 4, 1
  %303 = alloca %.25, align 8
  %304 = alloca ptr, i32 5, align 8
  %305 = getelementptr %.25, ptr %303, i32 0, i32 0
  store i64 256, ptr %305, align 4
  %306 = getelementptr ptr, ptr %304, i32 0
  store ptr %305, ptr %306, align 8
  %307 = getelementptr %.25, ptr %303, i32 0, i32 1
  store i64 %174, ptr %307, align 4
  %308 = getelementptr ptr, ptr %304, i32 1
  store ptr %307, ptr %308, align 8
  %309 = getelementptr %.25, ptr %303, i32 0, i32 2
  store ptr %285, ptr %309, align 8
  %310 = getelementptr ptr, ptr %304, i32 2
  store ptr %309, ptr %310, align 8
  %311 = getelementptr %.25, ptr %303, i32 0, i32 3
  store ptr %292, ptr %311, align 8
  %312 = getelementptr ptr, ptr %304, i32 3
  store ptr %311, ptr %312, align 8
  %313 = getelementptr %.25, ptr %303, i32 0, i32 4
  store ptr %297, ptr %313, align 8
  %314 = getelementptr ptr, ptr %304, i32 4
  store ptr %313, ptr %314, align 8
  %315 = alloca %.26, align 8
  %316 = alloca ptr, i32 14, align 8
  %317 = getelementptr %.26, ptr %315, i32 0, i32 0
  store ptr %0, ptr %317, align 8
  %318 = getelementptr ptr, ptr %316, i32 0
  store ptr %317, ptr %318, align 8
  %319 = getelementptr %.26, ptr %315, i32 0, i32 1
  store ptr %280, ptr %319, align 8
  %320 = getelementptr ptr, ptr %316, i32 1
  store ptr %319, ptr %320, align 8
  %321 = getelementptr %.26, ptr %315, i32 0, i32 2
  store i64 3, ptr %321, align 4
  %322 = getelementptr ptr, ptr %316, i32 2
  store ptr %321, ptr %322, align 8
  %323 = getelementptr %.26, ptr %315, i32 0, i32 3
  store ptr @main_kernel_0_main_kLoop_maximum__5_1_0_kernel_name, ptr %323, align 8
  %324 = getelementptr ptr, ptr %316, i32 3
  store ptr %323, ptr %324, align 8
  %325 = getelementptr %.26, ptr %315, i32 0, i32 4
  store i64 %279, ptr %325, align 4
  %326 = getelementptr ptr, ptr %316, i32 4
  store ptr %325, ptr %326, align 8
  %327 = getelementptr %.26, ptr %315, i32 0, i32 5
  store i64 1, ptr %327, align 4
  %328 = getelementptr ptr, ptr %316, i32 5
  store ptr %327, ptr %328, align 8
  %329 = getelementptr %.26, ptr %315, i32 0, i32 6
  store i64 1, ptr %329, align 4
  %330 = getelementptr ptr, ptr %316, i32 6
  store ptr %329, ptr %330, align 8
  %331 = getelementptr %.26, ptr %315, i32 0, i32 7
  store i64 256, ptr %331, align 4
  %332 = getelementptr ptr, ptr %316, i32 7
  store ptr %331, ptr %332, align 8
  %333 = getelementptr %.26, ptr %315, i32 0, i32 8
  store i64 1, ptr %333, align 4
  %334 = getelementptr ptr, ptr %316, i32 8
  store ptr %333, ptr %334, align 8
  %335 = getelementptr %.26, ptr %315, i32 0, i32 9
  store i64 1, ptr %335, align 4
  %336 = getelementptr ptr, ptr %316, i32 9
  store ptr %335, ptr %336, align 8
  %337 = getelementptr %.26, ptr %315, i32 0, i32 10
  store i32 0, ptr %337, align 4
  %338 = getelementptr ptr, ptr %316, i32 10
  store ptr %337, ptr %338, align 8
  %339 = getelementptr %.26, ptr %315, i32 0, i32 11
  store ptr null, ptr %339, align 8
  %340 = getelementptr ptr, ptr %316, i32 11
  store ptr %339, ptr %340, align 8
  %341 = getelementptr %.26, ptr %315, i32 0, i32 12
  store i32 5, ptr %341, align 4
  %342 = getelementptr ptr, ptr %316, i32 12
  store ptr %341, ptr %342, align 8
  %343 = getelementptr %.26, ptr %315, i32 0, i32 13
  store ptr %304, ptr %343, align 8
  %344 = getelementptr ptr, ptr %316, i32 13
  store ptr %343, ptr %344, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %316)
  br label %345

345:                                              ; preds = %196, %271
  %346 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %91, 0
  %347 = alloca %.11, align 8
  %348 = alloca ptr, i32 2, align 8
  %349 = getelementptr %.11, ptr %347, i32 0, i32 0
  store ptr %0, ptr %349, align 8
  %350 = getelementptr ptr, ptr %348, i32 0
  store ptr %349, ptr %350, align 8
  %351 = getelementptr %.11, ptr %347, i32 0, i32 1
  store ptr %346, ptr %351, align 8
  %352 = getelementptr ptr, ptr %348, i32 1
  store ptr %351, ptr %352, align 8
  call void @disc_ral_call(ptr %0, ptr @dealloc___gpu___pvoid_pvoid___void, ptr %348)
  %353 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %50, 0
  %354 = alloca %.12, align 8
  %355 = alloca ptr, i32 2, align 8
  %356 = getelementptr %.12, ptr %354, i32 0, i32 0
  store ptr %0, ptr %356, align 8
  %357 = getelementptr ptr, ptr %355, i32 0
  store ptr %356, ptr %357, align 8
  %358 = getelementptr %.12, ptr %354, i32 0, i32 1
  store ptr %353, ptr %358, align 8
  %359 = getelementptr ptr, ptr %355, i32 1
  store ptr %358, ptr %359, align 8
  call void @disc_ral_call(ptr %0, ptr @dealloc___gpu___pvoid_pvoid___void, ptr %355)
  %360 = mul i64 10, %11
  %361 = getelementptr float, ptr null, i64 %360
  %362 = ptrtoint ptr %361 to i64
  %363 = alloca %.13, align 8
  %364 = alloca ptr, i32 3, align 8
  %365 = getelementptr %.13, ptr %363, i32 0, i32 0
  store ptr %0, ptr %365, align 8
  %366 = getelementptr ptr, ptr %364, i32 0
  store ptr %365, ptr %366, align 8
  %367 = getelementptr %.13, ptr %363, i32 0, i32 1
  store i64 %362, ptr %367, align 4
  %368 = getelementptr ptr, ptr %364, i32 1
  store ptr %367, ptr %368, align 8
  %369 = getelementptr %.13, ptr %363, i32 0, i32 2
  %370 = getelementptr ptr, ptr %364, i32 2
  store ptr %369, ptr %370, align 8
  call void @disc_ral_call(ptr %0, ptr @alloc___gpu___pvoid_i64___pvoid, ptr %364)
  %371 = load ptr, ptr %369, align 8
  %372 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } undef, ptr %371, 0
  %373 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %372, ptr %371, 1
  %374 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %373, i64 0, 2
  %375 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %374, i64 10, 3, 1
  %376 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %375, i64 1, 4, 1
  %377 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %376, i64 %11, 3, 0
  %378 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %377, i64 10, 4, 0
  %379 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 0
  %380 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 1
  %381 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 2
  %382 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 3, 0
  %383 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 3, 1
  %384 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 4, 0
  %385 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 4, 1
  %386 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %24, 0
  %387 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %24, 1
  %388 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %24, 2
  %389 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %24, 3, 0
  %390 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %24, 3, 1
  %391 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %24, 4, 0
  %392 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %24, 4, 1
  %393 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 0
  %394 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 1
  %395 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 2
  %396 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 3, 0
  %397 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 3, 1
  %398 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 4, 0
  %399 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 4, 1
  %400 = alloca %.14, align 8
  %401 = alloca ptr, i32 26, align 8
  %402 = getelementptr %.14, ptr %400, i32 0, i32 0
  store ptr %0, ptr %402, align 8
  %403 = getelementptr ptr, ptr %401, i32 0
  store ptr %402, ptr %403, align 8
  %404 = getelementptr %.14, ptr %400, i32 0, i32 1
  store ptr null, ptr %404, align 8
  %405 = getelementptr ptr, ptr %401, i32 1
  store ptr %404, ptr %405, align 8
  %406 = getelementptr %.14, ptr %400, i32 0, i32 2
  store ptr %379, ptr %406, align 8
  %407 = getelementptr ptr, ptr %401, i32 2
  store ptr %406, ptr %407, align 8
  %408 = getelementptr %.14, ptr %400, i32 0, i32 3
  store ptr %380, ptr %408, align 8
  %409 = getelementptr ptr, ptr %401, i32 3
  store ptr %408, ptr %409, align 8
  %410 = getelementptr %.14, ptr %400, i32 0, i32 4
  store i64 %381, ptr %410, align 4
  %411 = getelementptr ptr, ptr %401, i32 4
  store ptr %410, ptr %411, align 8
  %412 = getelementptr %.14, ptr %400, i32 0, i32 5
  store i64 %382, ptr %412, align 4
  %413 = getelementptr ptr, ptr %401, i32 5
  store ptr %412, ptr %413, align 8
  %414 = getelementptr %.14, ptr %400, i32 0, i32 6
  store i64 %383, ptr %414, align 4
  %415 = getelementptr ptr, ptr %401, i32 6
  store ptr %414, ptr %415, align 8
  %416 = getelementptr %.14, ptr %400, i32 0, i32 7
  store i64 %384, ptr %416, align 4
  %417 = getelementptr ptr, ptr %401, i32 7
  store ptr %416, ptr %417, align 8
  %418 = getelementptr %.14, ptr %400, i32 0, i32 8
  store i64 %385, ptr %418, align 4
  %419 = getelementptr ptr, ptr %401, i32 8
  store ptr %418, ptr %419, align 8
  %420 = getelementptr %.14, ptr %400, i32 0, i32 9
  store ptr %386, ptr %420, align 8
  %421 = getelementptr ptr, ptr %401, i32 9
  store ptr %420, ptr %421, align 8
  %422 = getelementptr %.14, ptr %400, i32 0, i32 10
  store ptr %387, ptr %422, align 8
  %423 = getelementptr ptr, ptr %401, i32 10
  store ptr %422, ptr %423, align 8
  %424 = getelementptr %.14, ptr %400, i32 0, i32 11
  store i64 %388, ptr %424, align 4
  %425 = getelementptr ptr, ptr %401, i32 11
  store ptr %424, ptr %425, align 8
  %426 = getelementptr %.14, ptr %400, i32 0, i32 12
  store i64 %389, ptr %426, align 4
  %427 = getelementptr ptr, ptr %401, i32 12
  store ptr %426, ptr %427, align 8
  %428 = getelementptr %.14, ptr %400, i32 0, i32 13
  store i64 %390, ptr %428, align 4
  %429 = getelementptr ptr, ptr %401, i32 13
  store ptr %428, ptr %429, align 8
  %430 = getelementptr %.14, ptr %400, i32 0, i32 14
  store i64 %391, ptr %430, align 4
  %431 = getelementptr ptr, ptr %401, i32 14
  store ptr %430, ptr %431, align 8
  %432 = getelementptr %.14, ptr %400, i32 0, i32 15
  store i64 %392, ptr %432, align 4
  %433 = getelementptr ptr, ptr %401, i32 15
  store ptr %432, ptr %433, align 8
  %434 = getelementptr %.14, ptr %400, i32 0, i32 16
  store ptr %393, ptr %434, align 8
  %435 = getelementptr ptr, ptr %401, i32 16
  store ptr %434, ptr %435, align 8
  %436 = getelementptr %.14, ptr %400, i32 0, i32 17
  store ptr %394, ptr %436, align 8
  %437 = getelementptr ptr, ptr %401, i32 17
  store ptr %436, ptr %437, align 8
  %438 = getelementptr %.14, ptr %400, i32 0, i32 18
  store i64 %395, ptr %438, align 4
  %439 = getelementptr ptr, ptr %401, i32 18
  store ptr %438, ptr %439, align 8
  %440 = getelementptr %.14, ptr %400, i32 0, i32 19
  store i64 %396, ptr %440, align 4
  %441 = getelementptr ptr, ptr %401, i32 19
  store ptr %440, ptr %441, align 8
  %442 = getelementptr %.14, ptr %400, i32 0, i32 20
  store i64 %397, ptr %442, align 4
  %443 = getelementptr ptr, ptr %401, i32 20
  store ptr %442, ptr %443, align 8
  %444 = getelementptr %.14, ptr %400, i32 0, i32 21
  store i64 %398, ptr %444, align 4
  %445 = getelementptr ptr, ptr %401, i32 21
  store ptr %444, ptr %445, align 8
  %446 = getelementptr %.14, ptr %400, i32 0, i32 22
  store i64 %399, ptr %446, align 4
  %447 = getelementptr ptr, ptr %401, i32 22
  store ptr %446, ptr %447, align 8
  %448 = getelementptr %.14, ptr %400, i32 0, i32 23
  store i1 false, ptr %448, align 1
  %449 = getelementptr ptr, ptr %401, i32 23
  store ptr %448, ptr %449, align 8
  %450 = getelementptr %.14, ptr %400, i32 0, i32 24
  store i1 false, ptr %450, align 1
  %451 = getelementptr ptr, ptr %401, i32 24
  store ptr %450, ptr %451, align 8
  %452 = getelementptr %.14, ptr %400, i32 0, i32 25
  store i1 true, ptr %452, align 1
  %453 = getelementptr ptr, ptr %401, i32 25
  store ptr %452, ptr %453, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void, ptr %401)
  %454 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %195, 0
  %455 = alloca %.15, align 8
  %456 = alloca ptr, i32 2, align 8
  %457 = getelementptr %.15, ptr %455, i32 0, i32 0
  store ptr %0, ptr %457, align 8
  %458 = getelementptr ptr, ptr %456, i32 0
  store ptr %457, ptr %458, align 8
  %459 = getelementptr %.15, ptr %455, i32 0, i32 1
  store ptr %454, ptr %459, align 8
  %460 = getelementptr ptr, ptr %456, i32 1
  store ptr %459, ptr %460, align 8
  call void @disc_ral_call(ptr %0, ptr @dealloc___gpu___pvoid_pvoid___void, ptr %456)
  %461 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %24, 0
  %462 = alloca %.16, align 8
  %463 = alloca ptr, i32 2, align 8
  %464 = getelementptr %.16, ptr %462, i32 0, i32 0
  store ptr %0, ptr %464, align 8
  %465 = getelementptr ptr, ptr %463, i32 0
  store ptr %464, ptr %465, align 8
  %466 = getelementptr %.16, ptr %462, i32 0, i32 1
  store ptr %461, ptr %466, align 8
  %467 = getelementptr ptr, ptr %463, i32 1
  store ptr %466, ptr %467, align 8
  call void @disc_ral_call(ptr %0, ptr @dealloc___gpu___pvoid_pvoid___void, ptr %463)
  %468 = mul i64 10, %11
  %469 = getelementptr float, ptr null, i64 %468
  %470 = ptrtoint ptr %469 to i64
  %471 = alloca %.17, align 8
  %472 = alloca ptr, i32 3, align 8
  %473 = getelementptr %.17, ptr %471, i32 0, i32 0
  store ptr %0, ptr %473, align 8
  %474 = getelementptr ptr, ptr %472, i32 0
  store ptr %473, ptr %474, align 8
  %475 = getelementptr %.17, ptr %471, i32 0, i32 1
  store i64 %470, ptr %475, align 4
  %476 = getelementptr ptr, ptr %472, i32 1
  store ptr %475, ptr %476, align 8
  %477 = getelementptr %.17, ptr %471, i32 0, i32 2
  %478 = getelementptr ptr, ptr %472, i32 2
  store ptr %477, ptr %478, align 8
  call void @disc_ral_call(ptr %0, ptr @alloc___gpu___pvoid_i64___pvoid, ptr %472)
  %479 = load ptr, ptr %477, align 8
  %480 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } undef, ptr %479, 0
  %481 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %480, ptr %479, 1
  %482 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %481, i64 0, 2
  %483 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %482, i64 10, 3, 1
  %484 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %483, i64 1, 4, 1
  %485 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %484, i64 %11, 3, 0
  %486 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %485, i64 10, 4, 0
  br i1 %176, label %487, label %562

487:                                              ; preds = %345
  %488 = udiv i64 %174, 4
  %489 = icmp sle i64 %488, 0
  %490 = sub i64 0, %488
  %491 = sub i64 %488, 1
  %492 = select i1 %489, i64 %490, i64 %491
  %493 = sdiv i64 %492, 256
  %494 = sub i64 0, %493
  %495 = add i64 %493, 1
  %496 = select i1 %489, i64 %494, i64 %495
  %497 = alloca ptr, i32 3, align 8
  %498 = getelementptr ptr, ptr %497, i32 0
  store ptr @main_kernel_1_blob_gpu.binary_compute_60, ptr %498, align 8
  %499 = getelementptr ptr, ptr %497, i32 1
  store ptr @main_kernel_1_blob_gpu.binary_sm_70, ptr %499, align 8
  %500 = getelementptr ptr, ptr %497, i32 2
  store ptr @main_kernel_1_blob_gpu.binary_sm_75, ptr %500, align 8
  %501 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 0
  %502 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 1
  %503 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 2
  %504 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 3, 0
  %505 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 4, 0
  %506 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 0
  %507 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 1
  %508 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 2
  %509 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 3, 0
  %510 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 3, 1
  %511 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 4, 0
  %512 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 4, 1
  %513 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 0
  %514 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 1
  %515 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 2
  %516 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 3, 0
  %517 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 3, 1
  %518 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 4, 0
  %519 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 4, 1
  %520 = alloca %.18, align 8
  %521 = alloca ptr, i32 5, align 8
  %522 = getelementptr %.18, ptr %520, i32 0, i32 0
  store i64 256, ptr %522, align 4
  %523 = getelementptr ptr, ptr %521, i32 0
  store ptr %522, ptr %523, align 8
  %524 = getelementptr %.18, ptr %520, i32 0, i32 1
  store i64 %488, ptr %524, align 4
  %525 = getelementptr ptr, ptr %521, i32 1
  store ptr %524, ptr %525, align 8
  %526 = getelementptr %.18, ptr %520, i32 0, i32 2
  store ptr %502, ptr %526, align 8
  %527 = getelementptr ptr, ptr %521, i32 2
  store ptr %526, ptr %527, align 8
  %528 = getelementptr %.18, ptr %520, i32 0, i32 3
  store ptr %507, ptr %528, align 8
  %529 = getelementptr ptr, ptr %521, i32 3
  store ptr %528, ptr %529, align 8
  %530 = getelementptr %.18, ptr %520, i32 0, i32 4
  store ptr %514, ptr %530, align 8
  %531 = getelementptr ptr, ptr %521, i32 4
  store ptr %530, ptr %531, align 8
  %532 = alloca %.19, align 8
  %533 = alloca ptr, i32 14, align 8
  %534 = getelementptr %.19, ptr %532, i32 0, i32 0
  store ptr %0, ptr %534, align 8
  %535 = getelementptr ptr, ptr %533, i32 0
  store ptr %534, ptr %535, align 8
  %536 = getelementptr %.19, ptr %532, i32 0, i32 1
  store ptr %497, ptr %536, align 8
  %537 = getelementptr ptr, ptr %533, i32 1
  store ptr %536, ptr %537, align 8
  %538 = getelementptr %.19, ptr %532, i32 0, i32 2
  store i64 3, ptr %538, align 4
  %539 = getelementptr ptr, ptr %533, i32 2
  store ptr %538, ptr %539, align 8
  %540 = getelementptr %.19, ptr %532, i32 0, i32 3
  store ptr @main_kernel_1_main_kLoop_maximum__5_1_1___Vec4_kernel_name, ptr %540, align 8
  %541 = getelementptr ptr, ptr %533, i32 3
  store ptr %540, ptr %541, align 8
  %542 = getelementptr %.19, ptr %532, i32 0, i32 4
  store i64 %496, ptr %542, align 4
  %543 = getelementptr ptr, ptr %533, i32 4
  store ptr %542, ptr %543, align 8
  %544 = getelementptr %.19, ptr %532, i32 0, i32 5
  store i64 1, ptr %544, align 4
  %545 = getelementptr ptr, ptr %533, i32 5
  store ptr %544, ptr %545, align 8
  %546 = getelementptr %.19, ptr %532, i32 0, i32 6
  store i64 1, ptr %546, align 4
  %547 = getelementptr ptr, ptr %533, i32 6
  store ptr %546, ptr %547, align 8
  %548 = getelementptr %.19, ptr %532, i32 0, i32 7
  store i64 256, ptr %548, align 4
  %549 = getelementptr ptr, ptr %533, i32 7
  store ptr %548, ptr %549, align 8
  %550 = getelementptr %.19, ptr %532, i32 0, i32 8
  store i64 1, ptr %550, align 4
  %551 = getelementptr ptr, ptr %533, i32 8
  store ptr %550, ptr %551, align 8
  %552 = getelementptr %.19, ptr %532, i32 0, i32 9
  store i64 1, ptr %552, align 4
  %553 = getelementptr ptr, ptr %533, i32 9
  store ptr %552, ptr %553, align 8
  %554 = getelementptr %.19, ptr %532, i32 0, i32 10
  store i32 0, ptr %554, align 4
  %555 = getelementptr ptr, ptr %533, i32 10
  store ptr %554, ptr %555, align 8
  %556 = getelementptr %.19, ptr %532, i32 0, i32 11
  store ptr null, ptr %556, align 8
  %557 = getelementptr ptr, ptr %533, i32 11
  store ptr %556, ptr %557, align 8
  %558 = getelementptr %.19, ptr %532, i32 0, i32 12
  store i32 5, ptr %558, align 4
  %559 = getelementptr ptr, ptr %533, i32 12
  store ptr %558, ptr %559, align 8
  %560 = getelementptr %.19, ptr %532, i32 0, i32 13
  store ptr %521, ptr %560, align 8
  %561 = getelementptr ptr, ptr %533, i32 13
  store ptr %560, ptr %561, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %533)
  br label %636

562:                                              ; preds = %345
  %563 = icmp sle i64 %174, 0
  %564 = sub i64 0, %174
  %565 = sub i64 %174, 1
  %566 = select i1 %563, i64 %564, i64 %565
  %567 = sdiv i64 %566, 256
  %568 = sub i64 0, %567
  %569 = add i64 %567, 1
  %570 = select i1 %563, i64 %568, i64 %569
  %571 = alloca ptr, i32 3, align 8
  %572 = getelementptr ptr, ptr %571, i32 0
  store ptr @main_kernel_2_blob_gpu.binary_compute_60, ptr %572, align 8
  %573 = getelementptr ptr, ptr %571, i32 1
  store ptr @main_kernel_2_blob_gpu.binary_sm_70, ptr %573, align 8
  %574 = getelementptr ptr, ptr %571, i32 2
  store ptr @main_kernel_2_blob_gpu.binary_sm_75, ptr %574, align 8
  %575 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 0
  %576 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 1
  %577 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 2
  %578 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 3, 0
  %579 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 3, 1
  %580 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 4, 0
  %581 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 4, 1
  %582 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 0
  %583 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 1
  %584 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 2
  %585 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 3, 0
  %586 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 4, 0
  %587 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 0
  %588 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 1
  %589 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 2
  %590 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 3, 0
  %591 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 3, 1
  %592 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 4, 0
  %593 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 4, 1
  %594 = alloca %.23, align 8
  %595 = alloca ptr, i32 5, align 8
  %596 = getelementptr %.23, ptr %594, i32 0, i32 0
  store i64 256, ptr %596, align 4
  %597 = getelementptr ptr, ptr %595, i32 0
  store ptr %596, ptr %597, align 8
  %598 = getelementptr %.23, ptr %594, i32 0, i32 1
  store i64 %174, ptr %598, align 4
  %599 = getelementptr ptr, ptr %595, i32 1
  store ptr %598, ptr %599, align 8
  %600 = getelementptr %.23, ptr %594, i32 0, i32 2
  store ptr %576, ptr %600, align 8
  %601 = getelementptr ptr, ptr %595, i32 2
  store ptr %600, ptr %601, align 8
  %602 = getelementptr %.23, ptr %594, i32 0, i32 3
  store ptr %583, ptr %602, align 8
  %603 = getelementptr ptr, ptr %595, i32 3
  store ptr %602, ptr %603, align 8
  %604 = getelementptr %.23, ptr %594, i32 0, i32 4
  store ptr %588, ptr %604, align 8
  %605 = getelementptr ptr, ptr %595, i32 4
  store ptr %604, ptr %605, align 8
  %606 = alloca %.24, align 8
  %607 = alloca ptr, i32 14, align 8
  %608 = getelementptr %.24, ptr %606, i32 0, i32 0
  store ptr %0, ptr %608, align 8
  %609 = getelementptr ptr, ptr %607, i32 0
  store ptr %608, ptr %609, align 8
  %610 = getelementptr %.24, ptr %606, i32 0, i32 1
  store ptr %571, ptr %610, align 8
  %611 = getelementptr ptr, ptr %607, i32 1
  store ptr %610, ptr %611, align 8
  %612 = getelementptr %.24, ptr %606, i32 0, i32 2
  store i64 3, ptr %612, align 4
  %613 = getelementptr ptr, ptr %607, i32 2
  store ptr %612, ptr %613, align 8
  %614 = getelementptr %.24, ptr %606, i32 0, i32 3
  store ptr @main_kernel_2_main_kLoop_maximum__5_1_1_kernel_name, ptr %614, align 8
  %615 = getelementptr ptr, ptr %607, i32 3
  store ptr %614, ptr %615, align 8
  %616 = getelementptr %.24, ptr %606, i32 0, i32 4
  store i64 %570, ptr %616, align 4
  %617 = getelementptr ptr, ptr %607, i32 4
  store ptr %616, ptr %617, align 8
  %618 = getelementptr %.24, ptr %606, i32 0, i32 5
  store i64 1, ptr %618, align 4
  %619 = getelementptr ptr, ptr %607, i32 5
  store ptr %618, ptr %619, align 8
  %620 = getelementptr %.24, ptr %606, i32 0, i32 6
  store i64 1, ptr %620, align 4
  %621 = getelementptr ptr, ptr %607, i32 6
  store ptr %620, ptr %621, align 8
  %622 = getelementptr %.24, ptr %606, i32 0, i32 7
  store i64 256, ptr %622, align 4
  %623 = getelementptr ptr, ptr %607, i32 7
  store ptr %622, ptr %623, align 8
  %624 = getelementptr %.24, ptr %606, i32 0, i32 8
  store i64 1, ptr %624, align 4
  %625 = getelementptr ptr, ptr %607, i32 8
  store ptr %624, ptr %625, align 8
  %626 = getelementptr %.24, ptr %606, i32 0, i32 9
  store i64 1, ptr %626, align 4
  %627 = getelementptr ptr, ptr %607, i32 9
  store ptr %626, ptr %627, align 8
  %628 = getelementptr %.24, ptr %606, i32 0, i32 10
  store i32 0, ptr %628, align 4
  %629 = getelementptr ptr, ptr %607, i32 10
  store ptr %628, ptr %629, align 8
  %630 = getelementptr %.24, ptr %606, i32 0, i32 11
  store ptr null, ptr %630, align 8
  %631 = getelementptr ptr, ptr %607, i32 11
  store ptr %630, ptr %631, align 8
  %632 = getelementptr %.24, ptr %606, i32 0, i32 12
  store i32 5, ptr %632, align 4
  %633 = getelementptr ptr, ptr %607, i32 12
  store ptr %632, ptr %633, align 8
  %634 = getelementptr %.24, ptr %606, i32 0, i32 13
  store ptr %595, ptr %634, align 8
  %635 = getelementptr ptr, ptr %607, i32 13
  store ptr %634, ptr %635, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %607)
  br label %636

636:                                              ; preds = %487, %562
  %637 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %378, 0
  %638 = alloca %.20, align 8
  %639 = alloca ptr, i32 2, align 8
  %640 = getelementptr %.20, ptr %638, i32 0, i32 0
  store ptr %0, ptr %640, align 8
  %641 = getelementptr ptr, ptr %639, i32 0
  store ptr %640, ptr %641, align 8
  %642 = getelementptr %.20, ptr %638, i32 0, i32 1
  store ptr %637, ptr %642, align 8
  %643 = getelementptr ptr, ptr %639, i32 1
  store ptr %642, ptr %643, align 8
  call void @disc_ral_call(ptr %0, ptr @dealloc___gpu___pvoid_pvoid___void, ptr %639)
  %644 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %63, 0
  %645 = alloca %.21, align 8
  %646 = alloca ptr, i32 2, align 8
  %647 = getelementptr %.21, ptr %645, i32 0, i32 0
  store ptr %0, ptr %647, align 8
  %648 = getelementptr ptr, ptr %646, i32 0
  store ptr %647, ptr %648, align 8
  %649 = getelementptr %.21, ptr %645, i32 0, i32 1
  store ptr %644, ptr %649, align 8
  %650 = getelementptr ptr, ptr %646, i32 1
  store ptr %649, ptr %650, align 8
  call void @disc_ral_call(ptr %0, ptr @dealloc___gpu___pvoid_pvoid___void, ptr %646)
  %651 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 0
  %652 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 1
  %653 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 2
  %654 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 3, 0
  %655 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 3, 1
  %656 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 4, 0
  %657 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %486, 4, 1
  %658 = alloca %.22, align 8
  %659 = alloca ptr, i32 9, align 8
  %660 = getelementptr %.22, ptr %658, i32 0, i32 0
  store ptr %0, ptr %660, align 8
  %661 = getelementptr ptr, ptr %659, i32 0
  store ptr %660, ptr %661, align 8
  %662 = getelementptr %.22, ptr %658, i32 0, i32 1
  store i64 0, ptr %662, align 4
  %663 = getelementptr ptr, ptr %659, i32 1
  store ptr %662, ptr %663, align 8
  %664 = getelementptr %.22, ptr %658, i32 0, i32 2
  store ptr %651, ptr %664, align 8
  %665 = getelementptr ptr, ptr %659, i32 2
  store ptr %664, ptr %665, align 8
  %666 = getelementptr %.22, ptr %658, i32 0, i32 3
  store ptr %652, ptr %666, align 8
  %667 = getelementptr ptr, ptr %659, i32 3
  store ptr %666, ptr %667, align 8
  %668 = getelementptr %.22, ptr %658, i32 0, i32 4
  store i64 %653, ptr %668, align 4
  %669 = getelementptr ptr, ptr %659, i32 4
  store ptr %668, ptr %669, align 8
  %670 = getelementptr %.22, ptr %658, i32 0, i32 5
  store i64 %654, ptr %670, align 4
  %671 = getelementptr ptr, ptr %659, i32 5
  store ptr %670, ptr %671, align 8
  %672 = getelementptr %.22, ptr %658, i32 0, i32 6
  store i64 %655, ptr %672, align 4
  %673 = getelementptr ptr, ptr %659, i32 6
  store ptr %672, ptr %673, align 8
  %674 = getelementptr %.22, ptr %658, i32 0, i32 7
  store i64 %656, ptr %674, align 4
  %675 = getelementptr ptr, ptr %659, i32 7
  store ptr %674, ptr %675, align 8
  %676 = getelementptr %.22, ptr %658, i32 0, i32 8
  store i64 %657, ptr %676, align 4
  %677 = getelementptr ptr, ptr %659, i32 8
  store ptr %676, ptr %677, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_send_output___cpu___pvoid_i64_m2df32___void, ptr %659)
  ret void
}

host default target triple: x86_64-unknown-linux-gnu
host cpu name: icelake-server
host cpu features: +xsaves,+sse2,-hreset,+avx512cd,+sha,+xsaveopt,-kl,-avxvnni,-mwaitx,-clzero,+sse4.2,+bmi,-cldemote,-widekl,+avx512f,-raoint,+xsavec,+lzcnt,-serialize,-avxvnniint8,+fsgsbase,+aes,+sse,-sse4a,-rdpru,-tbm,-avx512bf16,-rtm,+fma,-waitpkg,-amx-fp16,+avx512ifma,-avx512vp2intersect,+popcnt,+vaes,-prefetchi,+f16c,+avx2,+sahf,+xsave,-uintr,+fxsr,+sgx,+pconfig,-avx512er,-avx512fp16,+gfni,+rdseed,+bmi2,-movdir64b,+avx512vl,+pku,-xop,+avx512bw,+avx512vbmi,+prfchw,+rdpid,+sse3,+cx16,+vpclmulqdq,+avx512vbmi2,-enqcmd,-amx-bf16,+64bit,-amx-int8,-avx512pf,-ptwrite,-amx-tile,-lwp,+avx512vpopcntdq,+avx512dq,-avxneconvert,+mmx,-fma4,+avx512vnni,-avxifma,+avx,+cmov,+sse4.1,+movbe,+invpcid,+adx,+clwb,-prefetchwt1,-cmpccxadd,+ssse3,+cx8,+clflushopt,-tsxldtrk,+pclmul,+crc32,+rdrnd,+avx512bitalg,-shstk,-movdiri,+wbnoinvd
after optimize llvm module:
; ModuleID = 'LLVMDialectModule'
source_filename = "LLVMDialectModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%0 = type { ptr, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.1 = type { ptr, ptr, ptr, i32, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.2 = type { ptr, ptr, ptr, i32, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.3 = type { ptr, ptr, ptr, i32, { ptr, ptr, i64, [1 x i64], [1 x i64] } }
%.4 = type { ptr, ptr, ptr, i32, { ptr, ptr, i64, [1 x i64], [1 x i64] } }
%.5 = type { ptr, i64, ptr }
%.6 = type { ptr, ptr, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1 }
%.7 = type { ptr, ptr }
%.8 = type { ptr, i64, ptr }
%.9 = type { i64, i64, ptr, ptr, ptr }
%.10 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.25 = type { i64, i64, ptr, ptr, ptr }
%.26 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.11 = type { ptr, ptr }
%.12 = type { ptr, ptr }
%.13 = type { ptr, i64, ptr }
%.14 = type { ptr, ptr, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, i1, i1, i1 }
%.15 = type { ptr, ptr }
%.16 = type { ptr, ptr }
%.17 = type { ptr, i64, ptr }
%.18 = type { i64, i64, ptr, ptr, ptr }
%.19 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.23 = type { i64, i64, ptr, ptr, ptr }
%.24 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.20 = type { ptr, ptr }
%.21 = type { ptr, ptr }
%.22 = type { ptr, i64, ptr, ptr, i64, i64, i64, i64, i64 }

@main_kernel_0_main_kLoop_maximum__5_1_0_kernel_name = internal constant [26 x i8] c"main_kLoop_maximum__5_1_0\00"
@main_kernel_0_blob_gpu.binary_sm_75 = internal constant [1200 x i8] c"P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"
@main_kernel_0_blob_gpu.binary_sm_70 = internal constant [1216 x i8] c"P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"
@main_kernel_0_blob_gpu.binary_compute_60 = internal constant [688 x i8] c"P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_0(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00"
@main_kernel_2_main_kLoop_maximum__5_1_1_kernel_name = internal constant [26 x i8] c"main_kLoop_maximum__5_1_1\00"
@main_kernel_2_blob_gpu.binary_sm_75 = internal constant [1200 x i8] c"P\EDU\BA\01\00\10\00\A0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00`\04\00\00\00\00\00\00_\04\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\F3\06\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\000\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\01\83\012\00D\00\01\00\00T\01/\05\00\01\00\FF\E8A\02z\01\00\7F\04\A1\0F\00\00\00\C4\0F\00\19y\06\18\00 \00%\CB\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\B3\04\F2\0A\80\03\00\EA\0F\00'x\00\06\CD\CC\CC\CC\FF\00\8E\07\00\E2\0F\00\02x\07\BE\04\00p\00q\C8\0F\00\19x\03\FFb\00\F0\01\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\C3\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F0\02\80\CAO\00\0Br\00\00\FF\0C\000\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\000\E9\10\00\C0\009My\00\E0\00PGy\00\00\F0\1D\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\10\0F\01\00-\12\01\D4\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13D\04\0C\01\00\13h\15\00*\90\00h\04\04\8D\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\80\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13\18)\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\003\00\00\F8@\00&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\08\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\C0\01:\0C\80\00\01\00\13\06\D8\01\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009x\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"
@main_kernel_2_blob_gpu.binary_sm_70 = internal constant [1216 x i8] c"P\EDU\BA\01\00\10\00\B0\04\00\00\00\00\00\00\02\00\01\01@\00\00\00p\04\00\00\00\00\00\00o\04\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5 _shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1)\00\0F#\00\0Coshared%\00\0C\9Fconstant0(\00\09\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\01\01 \0F\8B\00\06\0F\1B\01~o_param\22\01.\0F\01\00\09\8CL\00\00\00\03\00\0A\00\01\00\11\B4\18\00,\09\00\01\00\11\E3\18\00,\04\00\01\00 \13\01\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\00\17\041\00P\04/\08\00\05\1A\00\00\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04^\03A\00\047\04\90\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00`\00\04\1C\08\00`\FC\03S\01\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14,(\01\01\8B\012\00D\00\01\00\00\\\01/\05\00\01\00\FF\E0A\02z\01\00\7F\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\F0\03\A1\00\0E\00\00\E2\0F\00\19y\06(\00 \00%\D3\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\06\06\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\06\00Y\00\00p`\F0\03\00\D8\0F\00M\C3\04\F0\03\80\03\00\EA\0F\00%x\02\06\CD\CC\CC\CC\FF\00\8E\07`\002\02x\07\CE\04\00\80\00p\C8\0F\00\19x\03\FFb\00\F0\02\03\16\01\00\00\CA\0F\00$x\04\03\F6\FF\FF\FF\06`\00\C0\E4\0F\00%v\02\06\00Z\00\00\07\10\00\10\C8\10\00\82\04\04\00\\\00\00\07\00\10\000\81s\02\CB\02\D5\00\00\E9\1E\00\00\A8\0E\00\81s\05\04\10\00\96\A2\0E\00%v\06\06\00^@\00E!r\00\02\F8\02P\CAO\00\0Br\FC\00`\00\00\00\C0\F0\03 \002\08r\09\10\00\00\01\00q\D0\0F\00\86s\00\06\D3\00!\E9\10 \019My\00\E0\00PGy\00\00\F0-\05\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\12\01\CC\03\0D\01\00\22@\00\01\00=\01\01\000\00\08\01\00\1F\0B@\00\04\13A)\00\1F\22@\00\0C\13\13<\04\0C\01\00\13h\15\00*\90\00`\04\04\85\04\22\18\00\01\00\1F\C2T\00\00\00\01\00\13\F8@\00/p\00\80\00\0B\1F)'\00\03#\00h\D5\00\110\06\00\06\E4\00*\04\00\01\00\1FR@\00\04\13\981\00&\88\00@\00\1F\0A@\00\00\12\F2D\01\0D@\00\13 )\00*\E0\00\01\00\1B\08\08\00?\CF\00\00\E6\07\00\06\8D\05&\10\00\80\00\17\048\00\04\18\00\13\9A\14\01\0C\84\01*\10\05\9C\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07@\00\12\03\93\00:\0C\80\00\01\00\13\06\AB\00\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009p\03\00\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00"
@main_kernel_2_blob_gpu.binary_compute_60 = internal constant [688 x i8] c"P\EDU\BA\01\00\10\00\A0\02\00\00\00\00\00\00\01\00\01\01H\00\00\00X\02\00\00\00\00\00\00U\02\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\D0\04\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF%isible .entry main_kLoop_maximum__5_1_1(\0A.param .u32'\00\07\11_%\00?_0,/\00\1A\171/\00/64/\00\0E\1F2/\00\1B\1F3/\00\1B\F3\084\0A)\0A{\0A.reg .pred %p<3>;\12\00\95b32 %r<10\12\00\10f\12\006f<5#\00\E264 %rd<9>;\0A\0Ald|\00\01\08\01o%r2, [\81\00\0D<0];7\00\1F37\00\10s1];\0Amov2\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\A2\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B1\00\02\FE\00\0F\B2\00\11.4]8\00\0F!\01\11\1F38\00\00\1F18\00\10\102\22\01Sul.hi\0E\01\136\D6\00\F3\00-858993459;\0Ashr\1E\00\227,#\00\1236\00\05,\01\228,\1D\00s10;\0Asub\16\00\159\22\01\1280\00Cwide\1C\00#d4\1D\00\824;\0Aadd.s\B4\00\00\8D\01\01\BA\00\00\22\00\01\D3\00cglobalS\02\00\D3\00\00&\00\17]P\00\02\9A\00\11d\B9\00\1C9P\00#7,B\01\00\22\00\0EP\00\122P\00\227]5\00\02\15\00\223,j\003%f2\F4\01\22le\1B\002p2, \0030f0\01\00\00\22\00#lp:\00\184\1A\00\03+\009%p2\92\00#8,\0C\02\02\E2\00(st\92\00\00\8D\00 8]:\0054;\0AK\02\B0:\0Aret;\0A\0A}\0A\00\00\00\00"
@ral_send_output___cpu___pvoid_i64_m2df32___void = internal constant [48 x i8] c"ral_send_output___cpu___pvoid_i64_m2df32___void\00"
@main_kernel_1_main_kLoop_maximum__5_1_1___Vec4_kernel_name = internal constant [33 x i8] c"main_kLoop_maximum__5_1_1___Vec4\00"
@main_kernel_1_blob_gpu.binary_sm_75 = internal constant [1472 x i8] c"P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00Z\00\00\13p\00\10\C8\10\00\84\02\00\00\\\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"
@main_kernel_1_blob_gpu.binary_sm_70 = internal constant [1512 x i8] c"P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_1___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00Zp\03\03\E0\00Sv\04\00\00\\p\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00"
@main_kernel_1_blob_gpu.binary_compute_60 = internal constant [1048 x i8] c"P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BD\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_1___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,\9F\02\00\22\00\01y\02\91global.v4\1A\040{%f\C4\00\10f\22\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\C5\02\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00\02\B6\02\03S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\01\C4\01\04U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00"
@ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void = internal constant [101 x i8] c"ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00"
@main_kernel_main_kLoop_maximum__5_1_0___Vec4_kernel_name = internal constant [33 x i8] c"main_kLoop_maximum__5_1_0___Vec4\00"
@main_kernel_blob_gpu.binary_sm_75 = internal constant [1472 x i8] c"P\EDU\BA\01\00\10\00\B0\05\00\00\00\00\00\00\02\00\01\01@\00\00\00p\05\00\00\00\00\00\00k\05\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00K\05K\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\14\00\00\00A\005\04\A4\00\01\00\90\04/\08\00\05\00\00\00\16\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\C0\F0\11\00\03\1B\FF\00\04\1C\08\00P\0F\00S\02\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08x\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00Q\00\00\00\14, \01\11\00\F9\00\22D\00\01\00\00T\01/\05\00\01\00\FF\A8A\02z\01\00?\04\A2\0F\00\00\00\C4\0F\00\19y\00\01\00\10%\8B\02C\0E\00\19y\9D\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\D6\03R\EA\0F\00\19x$\02\B2\FF\06\00\00\00\E4\0F\00\02x\13~\04\12\0F\10\001\10x\02\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04'x\05\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\03\00\02 \00\10\E4\10\006\04\00\030\00W\00'x\06\020\00P\00\19x\05\FF \00`\05\16\01\00\00\C6 \00*\08\03 \00\11\07 \00\15\06 \00*\09\04 \00\11\08 \00\13\08 \00\A4$x\05\05\F6\FF\FF\FF\00\02 \00\11\09 \00\10\09 \00\10\E2 \00 \07\07 \00\10\02 \00\10\E4\10\00 \08\08\10\00\15\03\10\00 \0A\09\10\00\13\04\10\00\90%v\04\05\00\\\00\00\13p\00\10\C8\10\00\84\02\00\00Z\00\00\13\02\10\00%\06\07 \00a\E2\0F\08\81s\05/\01\CA\00\E9\1E\00\00\A6\0E\00%v\08\08 \00!\0C\02 \00\14\ED \00'\0A\0A \00U\00\81s\06\06@\00u\E8\0E\00\81s\09\08\10\00\10( \00%\0A\0A\10\00ub\0F\00!r\10\0C\D0\03\93\C4O\00!r\11\0D\06\00\01\00u\E4\8F\00!r\0E\0E\E3\01\93\E4\0F\01!r\0F\0F\0A\00\01\00\80\E2\0F\02\0Br\00\10\FF\0C\000\C0\F0\03\F0\00B\0Br\00\11\10\00\14\F2\10\00\12\0E\10\00\14\F4\10\00\12\0F\10\00 \F6\03\B0\00c%v\0C\00\00^\10\01b\E2\0F\00\08r\10P\00\12\00\A0\022\08r\11P\00!\00\80@\022\08r\12P\00\00\EB\04\01\10\00#\13\0F \00\A0\01\00\D0\0F\00\86s\00\0C\10\0F\00!\ED\10\B0\01\14M\E0\02\03\A0\02PGy\00\00\F0\9D\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\12\01\94\05\0D\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\13\13\04\06\0C\01\00\13\A8\15\00\11\90\06\00\06(\06\04M\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\044\D8\03\00f\02\05@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13X)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\003\00\008\85\03&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13H@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07&\03\05\80\00j\05\00\00\16\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0F\00\01\05.8\058\00\0Fp\00\1CP\00\00\00\00\00\00\00\00\00\00"
@main_kernel_blob_gpu.binary_sm_70 = internal constant [1512 x i8] c"P\EDU\BA\01\00\10\00\D8\05\00\00\00\00\00\00\02\00\01\01@\00\00\00\98\05\00\00\00\00\00\00\93\05\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00v\00\01\00!@\0D\07\001\00\80\0A\07\00\F5\0E\00F\05F\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F5'_shndx\00.nv.info\00.text.main_kLoop_maximum__5_1_0___Vec40\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00oaction\1D\01 \0F\92\00\0D\0F>\01\9Ao_paramE\01.\0F\01\00\0A\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\116\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\03\07\00v\00\FF\FF\FF\FF$\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\02$\00/4\00\01\00\03\04T\00\10\04\97\00R\04\18\00\00\00A\005\04\AC\00\01\00\90\04/\08\00\05\00\00\00\14\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04\9E\03A\00\047\04\D0\03\F2\04\04\0A\08\00\02\00\00\00`\01 \00\03\19 \00\04\17\0C(\00e\00\18\00\00\F0!\10\009\03\00\10\10\009\02\00\08\10\00\10\01<\01%\F0\11\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00\F3\00\00\04\1C\08\00`\00\00\00 \03\00\00K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00\83\01\11,(\01\11\00\01\01\22D\00\01\00\00\\\01/\05\00\01\00\FF\A0A\02z\01\00?\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\B0\03\A2\00\0E\00\00\E2\0F\00\19y\00\01\00\10%\93\02C\0E\00\19y\AD\03\F0\09!\00\00\00$\0E\00$z\00\00\00X\00\00\03\02\8E\07\00\CA\1F\00\0C\10\00\D7Y\00\00p`\F0\03\00\D8\0F\00M\09\E6\03R\EA\0F\00\19x,\02\B1\FF\06\00\00\00\C8\0F\00\10x\0A\A8\03\F1\04\FF\E0\FF\07\00\E2\0F\04%x\02\00\CD\CC\CC\CC\FF\00\8E\10\00T\10x\0B\00\02 \00\10\E4\10\006\0C\00\030\00U\00%x\04\0A0\00\10\C8\10\00'\06\0B@\00B\00\02r\02\98\02\00\E0\00\10\E4\80\00 \05\FF@\00B\03\16\01\00@\00*\08\0C0\009\04\00\070\00\11\070\00\13\020\00P$x\08\05\F6#\01\12\020\001\19x\04 \003\04\16\010\00\11\09\10\00\15\090\00 \0A\070\00\13\0A0\00#\02x~\05\00`\00\01 \00 \02\04 \00\10\0B \00\10\C4\10\00 \0E\09\10\00\10\0C\10\00\90\E4\0F\00%v\08\08\00\\p\03\03\E0\00Sv\04\00\00Zp\01\01\10\00%\0A\0A \00b\E2\0F\08\81s\09\A8\03\BA\E9\1E\00\00\A6\0E\00%v\0C\02 \00\01f\054\00\00\ED \00*\0E\0E \00%\0A\0A@\00u\E8\0E\00\81s\0D\0C\10\00u(\0F\00\81s\0E\0E\10\00\10b\80\00F\02\00\00^\90\00E!r\10\04\F3\01\93\E4O\00!r\11\05\0A\00\01\00s\E4\8F\00!r\06\06S\09\000\01s\01!r\07\07\0E\00\01\00p\E2\0F\02\0Br\00\10\80\02@\00\C0\F0\03\00\01B\0Br\00\11\10\00\14\F2\10\00\12\06\10\00A\F4\03\00\C4\10\00\12\07\10\00\11\F6 \002\08r\04@\00\02`\00B\00\08r\05@\00#\00\80\10\00\12\06@\00\00\13\05\01\10\00#\07\07 \00\91\01\00\D0\0F\00\86s\00\02!\01!\ED\10\A0\01\14M\00\03\03\C0\02PGy\00\00\F0\CD\06\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00 \0F\01\00-\00<\03.\03\00\01\00\22@\00\01\00=\1D\01\000\00\08\01\00\1F\0B@\00\04\13])\00\1FE@\00\0C\22\13\00\D0\03\0C\01\00\13\A8\15\00\11\90\06\00\06 \06\04E\06\22\18\00\01\00\1F\DET\00\00\00\01\00\138\95\00/p\00\80\00\0B\1F)'\00\03#\00\A8@\00\110\06\00\06\E4\00*\04\00\01\00\1FY@\00\04\13\D81\00&\88\00@\00\1F\0A@\00\00!\0E\01D\01\0D@\00\13`)\00*\E0\00\01\00\1B\08\08\00?\EB\00\00\A6\09\001\00\00@\B5\04\11\00P\08\04\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01\13P@\00\17\801\01\0F\C0\00\01\132@\00+\06\00\01\00\15\07\F6\02\05\80\00j\05\00\00\14\80\00\01\00\13\06\D8\01\04(\0D\0D\88\01\1A\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\00*0\05\08\00\0C8\00\0Fp\00\18P\00\00\00\00\00\00\00\00\00\00"
@main_kernel_blob_gpu.binary_compute_60 = internal constant [1048 x i8] c"P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\01\00\01\01H\00\00\00\C0\03\00\00\00\00\00\00\BA\03\00\00@\00\00\00\01\00\07\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\0C\09\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 7.1\0A.target sm_60\0A.address_size 64/\00\FF,isible .entry main_kLoop_maximum__5_1_0___Vec4(\0A.param .u32.\00\0E\11_,\00?_0,6\00!\1716\00/646\00\15\1F26\00\22\1F36\00\22\F3\084\0A)\0A{\0A.reg .pred %p<6>;\12\00\86b32 %r<2\12\00\10f\12\00Ff<17$\00\F2\0064 %rd<15>;\0A\0Ald\85\00\01&\01o%r2, [\8A\00\14<0];>\00\1F3>\00\17s1];\0Amov9\00\B84, %ctaid.x\17\00S5, %t\15\00qad.lo.s\18\00#1,4\00\00\B0\00\C2%r5;\0Asetp.ge8\004p1,%\00\F8\063;\0A@%p1 bra $L__BB0_2\B8\00\02\0D\01\0F\B9\00\18.4]?\00\0F6\01\18\1F3?\00\00\1F1?\00\17s2];\0Ashl\E9\01\136\E8\00S2;\0Aor\14\00\227,\19\00\171\14\00\138\14\00\08(\00\139\14\00\933;\0Amul.hit\01#10\19\00\A0-858993459s\00\14r\1F\00\02\\\01\1509\00\06\95\01#2, \00t10;\0Asub\18\00\133Q\00\00#\00\0Cm\00\01\C5\01\1F7m\00\06#5,%\00\0Dm\00\02P\00\1D5m\00$7,\04\01,16m\00\01\07\01\1F8m\00\06#9,%\00\0Cm\00320, \00\0Am\00421,]\01+20m\00\112\0E\01\1F9m\00\05323,%\00\0Dm\00\02\D8\02\1D3m\00$5,\B6\01\22244\00Cwide\1E\00#d4e\01\824;\0Aadd.sZ\02#5,`\02\00\22\00\01y\02\91global.v4\1A\040{%f\1D\00\10f\AD\00\10f\93\00`f4}, [:\00\17]d\00\02\B4\00\12dt\01\1C3e\00#7,\04\03\00#\00\08e\00\02|\04\125Q\00\1F7Q\00\00#8,\B3\01\0AQ\00\179Q\00\1E8Q\00\126Q\00\1F9Q\00\00\02\BD\02\00\98\01\0AR\00'11S\00.10T\00\127T\00/11U\00\01#2,\80\01\0BU\00\183U\00\1E2U\00\138U\00\223]8\00\02\16\00\00\DE\00\02v\01\185\17\00%10\89\01\196\18\00\151\9C\01\197\18\00\01+\00\00\F7\01#f8\00\05\22le\1C\002p2,h\0030f0\01\00\00\22\00$lp;\00\183\1B\00\03,\00<%p2G\00#3,\98\00\0FH\00\05\1C4H\00\01\C5\00,p3I\00#4,\C9\00\0FI\00\05\1D5I\00\00\F6\00,p4I\00#5,\FA\00\0FI\00\05\1D6I\00\00\0C\01*p5\B9\01#4,\F5\05\02\17\03+st\17\03\01\B6\01R4], {-\01\02\EB\00\02\A8\00\00e\005};\0AM\06\B0:\0Aret;\0A\0A}\0A\00\00\00\00\00\00\00"
@dealloc___gpu___pvoid_pvoid___void = internal constant [35 x i8] c"dealloc___gpu___pvoid_pvoid___void\00"
@ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void = internal constant [66 x i8] c"ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void\00"
@alloc___gpu___pvoid_i64___pvoid = internal constant [32 x i8] c"alloc___gpu___pvoid_i64___pvoid\00"
@ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32 = internal constant [49 x i8] c"ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32\00"
@ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32 = internal constant [49 x i8] c"ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32\00"
@ral_recv_input___cpu___pvoid_i64___m2df32 = internal constant [42 x i8] c"ral_recv_input___cpu___pvoid_i64___m2df32\00"
@__global_const_3 = internal constant [40 x i8] c"3360D7D67DEB9D97DFC48E2E8C19A28A_f32_10\00"
@__global_const_2 = internal constant [40 x i8] c"21438FB9F9F436186309DCC96AB50683_f32_10\00"
@__global_const_1 = internal constant [43 x i8] c"857EE11180CC683A53E2CFB20CC601E6_f32_10x10\00"
@__global_const_0 = internal constant [43 x i8] c"08A51305ABB4B614B7C8F1C7EBAF44D7_f32_10x10\00"

define void @disc_ral_call(ptr nocapture readonly %0, ptr %1, ptr %2) local_unnamed_addr {
entry:
  %3 = load ptr, ptr %0, align 8
  %4 = getelementptr ptr, ptr %0, i64 1
  %5 = load ptr, ptr %4, align 8
  %6 = load ptr, ptr %2, align 8
  store ptr %3, ptr %6, align 8
  tail call void %5(ptr %3, ptr %1, ptr nonnull %2)
  ret void
}

define void @main(ptr nocapture readonly %0) local_unnamed_addr {
  %2 = alloca %0, align 8
  %3 = alloca [3 x ptr], align 8
  store ptr %2, ptr %3, align 8
  %4 = getelementptr inbounds %0, ptr %2, i64 0, i32 1
  store i64 0, ptr %4, align 8
  %5 = getelementptr inbounds ptr, ptr %3, i64 1
  store ptr %4, ptr %5, align 8
  %6 = getelementptr inbounds %0, ptr %2, i64 0, i32 2
  %7 = getelementptr inbounds ptr, ptr %3, i64 2
  store ptr %6, ptr %7, align 8
  %8 = load ptr, ptr %0, align 8
  %9 = getelementptr ptr, ptr %0, i64 1
  %10 = load ptr, ptr %9, align 8
  store ptr %8, ptr %2, align 8
  call void %10(ptr %8, ptr nonnull @ral_recv_input___cpu___pvoid_i64___m2df32, ptr nonnull %3)
  %.fca.0.load53 = load ptr, ptr %6, align 8
  %.fca.1.gep55 = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 1
  %.fca.1.load56 = load ptr, ptr %.fca.1.gep55, align 8
  %.fca.3.0.gep61 = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 3
  %.fca.3.0.load62 = load i64, ptr %.fca.3.0.gep61, align 8
  %11 = alloca %.1, align 8
  %12 = alloca [5 x ptr], align 8
  store ptr %11, ptr %12, align 8
  %13 = getelementptr inbounds %.1, ptr %11, i64 0, i32 1
  store ptr null, ptr %13, align 8
  %14 = getelementptr inbounds ptr, ptr %12, i64 1
  store ptr %13, ptr %14, align 8
  %15 = getelementptr inbounds %.1, ptr %11, i64 0, i32 2
  store ptr @__global_const_0, ptr %15, align 8
  %16 = getelementptr inbounds ptr, ptr %12, i64 2
  store ptr %15, ptr %16, align 8
  %17 = getelementptr inbounds %.1, ptr %11, i64 0, i32 3
  store i32 0, ptr %17, align 8
  %18 = getelementptr inbounds ptr, ptr %12, i64 3
  store ptr %17, ptr %18, align 8
  %19 = getelementptr inbounds %.1, ptr %11, i64 0, i32 4
  %20 = getelementptr inbounds ptr, ptr %12, i64 4
  store ptr %19, ptr %20, align 8
  %21 = load ptr, ptr %0, align 8
  %22 = load ptr, ptr %9, align 8
  store ptr %21, ptr %11, align 8
  call void %22(ptr %21, ptr nonnull @ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32, ptr nonnull %12)
  %.fca.0.load32 = load ptr, ptr %19, align 8
  %.fca.1.gep34 = getelementptr inbounds %.1, ptr %11, i64 0, i32 4, i32 1
  %.fca.1.load35 = load ptr, ptr %.fca.1.gep34, align 8
  %.fca.2.gep37 = getelementptr inbounds %.1, ptr %11, i64 0, i32 4, i32 2
  %.fca.2.load38 = load i64, ptr %.fca.2.gep37, align 8
  %.fca.3.0.gep40 = getelementptr inbounds %.1, ptr %11, i64 0, i32 4, i32 3
  %.fca.3.0.load41 = load i64, ptr %.fca.3.0.gep40, align 8
  %.fca.3.1.gep43 = getelementptr inbounds %.1, ptr %11, i64 0, i32 4, i32 3, i64 1
  %.fca.3.1.load44 = load i64, ptr %.fca.3.1.gep43, align 8
  %.fca.4.0.gep46 = getelementptr inbounds %.1, ptr %11, i64 0, i32 4, i32 4
  %.fca.4.0.load47 = load i64, ptr %.fca.4.0.gep46, align 8
  %.fca.4.1.gep49 = getelementptr inbounds %.1, ptr %11, i64 0, i32 4, i32 4, i64 1
  %.fca.4.1.load50 = load i64, ptr %.fca.4.1.gep49, align 8
  %23 = alloca %.2, align 8
  %24 = alloca [5 x ptr], align 8
  store ptr %23, ptr %24, align 8
  %25 = getelementptr inbounds %.2, ptr %23, i64 0, i32 1
  store ptr null, ptr %25, align 8
  %26 = getelementptr inbounds ptr, ptr %24, i64 1
  store ptr %25, ptr %26, align 8
  %27 = getelementptr inbounds %.2, ptr %23, i64 0, i32 2
  store ptr @__global_const_1, ptr %27, align 8
  %28 = getelementptr inbounds ptr, ptr %24, i64 2
  store ptr %27, ptr %28, align 8
  %29 = getelementptr inbounds %.2, ptr %23, i64 0, i32 3
  store i32 1, ptr %29, align 8
  %30 = getelementptr inbounds ptr, ptr %24, i64 3
  store ptr %29, ptr %30, align 8
  %31 = getelementptr inbounds %.2, ptr %23, i64 0, i32 4
  %32 = getelementptr inbounds ptr, ptr %24, i64 4
  store ptr %31, ptr %32, align 8
  %33 = load ptr, ptr %0, align 8
  %34 = load ptr, ptr %9, align 8
  store ptr %33, ptr %23, align 8
  call void %34(ptr %33, ptr nonnull @ral_const___gpu___pvoid_pvoid_pvoid_i32___m2df32, ptr nonnull %24)
  %.fca.0.load17 = load ptr, ptr %31, align 8
  %.fca.1.gep19 = getelementptr inbounds %.2, ptr %23, i64 0, i32 4, i32 1
  %.fca.1.load20 = load ptr, ptr %.fca.1.gep19, align 8
  %.fca.2.gep22 = getelementptr inbounds %.2, ptr %23, i64 0, i32 4, i32 2
  %.fca.2.load23 = load i64, ptr %.fca.2.gep22, align 8
  %.fca.3.0.gep25 = getelementptr inbounds %.2, ptr %23, i64 0, i32 4, i32 3
  %.fca.3.0.load26 = load i64, ptr %.fca.3.0.gep25, align 8
  %.fca.3.1.gep = getelementptr inbounds %.2, ptr %23, i64 0, i32 4, i32 3, i64 1
  %.fca.3.1.load = load i64, ptr %.fca.3.1.gep, align 8
  %.fca.4.0.gep28 = getelementptr inbounds %.2, ptr %23, i64 0, i32 4, i32 4
  %.fca.4.0.load29 = load i64, ptr %.fca.4.0.gep28, align 8
  %.fca.4.1.gep = getelementptr inbounds %.2, ptr %23, i64 0, i32 4, i32 4, i64 1
  %.fca.4.1.load = load i64, ptr %.fca.4.1.gep, align 8
  %35 = alloca %.3, align 8
  %36 = alloca [5 x ptr], align 8
  store ptr %35, ptr %36, align 8
  %37 = getelementptr inbounds %.3, ptr %35, i64 0, i32 1
  store ptr null, ptr %37, align 8
  %38 = getelementptr inbounds ptr, ptr %36, i64 1
  store ptr %37, ptr %38, align 8
  %39 = getelementptr inbounds %.3, ptr %35, i64 0, i32 2
  store ptr @__global_const_2, ptr %39, align 8
  %40 = getelementptr inbounds ptr, ptr %36, i64 2
  store ptr %39, ptr %40, align 8
  %41 = getelementptr inbounds %.3, ptr %35, i64 0, i32 3
  store i32 2, ptr %41, align 8
  %42 = getelementptr inbounds ptr, ptr %36, i64 3
  store ptr %41, ptr %42, align 8
  %43 = getelementptr inbounds %.3, ptr %35, i64 0, i32 4
  %44 = getelementptr inbounds ptr, ptr %36, i64 4
  store ptr %43, ptr %44, align 8
  %45 = load ptr, ptr %0, align 8
  %46 = load ptr, ptr %9, align 8
  store ptr %45, ptr %35, align 8
  call void %46(ptr %45, ptr nonnull @ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32, ptr nonnull %36)
  %.fca.0.load2 = load ptr, ptr %43, align 8
  %.fca.1.gep4 = getelementptr inbounds %.3, ptr %35, i64 0, i32 4, i32 1
  %.fca.1.load5 = load ptr, ptr %.fca.1.gep4, align 8
  %47 = alloca %.4, align 8
  %48 = alloca [5 x ptr], align 8
  store ptr %47, ptr %48, align 8
  %49 = getelementptr inbounds %.4, ptr %47, i64 0, i32 1
  store ptr null, ptr %49, align 8
  %50 = getelementptr inbounds ptr, ptr %48, i64 1
  store ptr %49, ptr %50, align 8
  %51 = getelementptr inbounds %.4, ptr %47, i64 0, i32 2
  store ptr @__global_const_3, ptr %51, align 8
  %52 = getelementptr inbounds ptr, ptr %48, i64 2
  store ptr %51, ptr %52, align 8
  %53 = getelementptr inbounds %.4, ptr %47, i64 0, i32 3
  store i32 3, ptr %53, align 8
  %54 = getelementptr inbounds ptr, ptr %48, i64 3
  store ptr %53, ptr %54, align 8
  %55 = getelementptr inbounds %.4, ptr %47, i64 0, i32 4
  %56 = getelementptr inbounds ptr, ptr %48, i64 4
  store ptr %55, ptr %56, align 8
  %57 = load ptr, ptr %0, align 8
  %58 = load ptr, ptr %9, align 8
  store ptr %57, ptr %47, align 8
  call void %58(ptr %57, ptr nonnull @ral_const___gpu___pvoid_pvoid_pvoid_i32___m1df32, ptr nonnull %48)
  %.fca.0.load = load ptr, ptr %55, align 8
  %.fca.1.gep = getelementptr inbounds %.4, ptr %47, i64 0, i32 4, i32 1
  %.fca.1.load = load ptr, ptr %.fca.1.gep, align 8
  %59 = mul i64 %.fca.3.0.load62, 10
  %.idx = mul i64 %.fca.3.0.load62, 40
  %60 = alloca %.5, align 8
  %61 = alloca [3 x ptr], align 8
  store ptr %60, ptr %61, align 8
  %62 = getelementptr inbounds %.5, ptr %60, i64 0, i32 1
  store i64 %.idx, ptr %62, align 8
  %63 = getelementptr inbounds ptr, ptr %61, i64 1
  store ptr %62, ptr %63, align 8
  %64 = getelementptr inbounds %.5, ptr %60, i64 0, i32 2
  %65 = getelementptr inbounds ptr, ptr %61, i64 2
  store ptr %64, ptr %65, align 8
  %66 = load ptr, ptr %0, align 8
  %67 = load ptr, ptr %9, align 8
  store ptr %66, ptr %60, align 8
  call void %67(ptr %66, ptr nonnull @alloc___gpu___pvoid_i64___pvoid, ptr nonnull %61)
  %68 = load ptr, ptr %64, align 8
  %69 = alloca %.6, align 8
  %70 = alloca [26 x ptr], align 8
  store ptr %69, ptr %70, align 8
  %71 = getelementptr inbounds %.6, ptr %69, i64 0, i32 1
  store ptr null, ptr %71, align 8
  %72 = getelementptr inbounds ptr, ptr %70, i64 1
  store ptr %71, ptr %72, align 8
  %73 = getelementptr inbounds %.6, ptr %69, i64 0, i32 2
  store ptr %.fca.0.load53, ptr %73, align 8
  %74 = getelementptr inbounds ptr, ptr %70, i64 2
  store ptr %73, ptr %74, align 8
  %75 = getelementptr inbounds %.6, ptr %69, i64 0, i32 3
  store ptr %.fca.1.load56, ptr %75, align 8
  %76 = getelementptr inbounds ptr, ptr %70, i64 3
  store ptr %75, ptr %76, align 8
  %77 = getelementptr inbounds %.6, ptr %69, i64 0, i32 4
  store i64 0, ptr %77, align 8
  %78 = getelementptr inbounds ptr, ptr %70, i64 4
  store ptr %77, ptr %78, align 8
  %79 = getelementptr inbounds %.6, ptr %69, i64 0, i32 5
  store i64 %.fca.3.0.load62, ptr %79, align 8
  %80 = getelementptr inbounds ptr, ptr %70, i64 5
  store ptr %79, ptr %80, align 8
  %81 = getelementptr inbounds %.6, ptr %69, i64 0, i32 6
  store i64 10, ptr %81, align 8
  %82 = getelementptr inbounds ptr, ptr %70, i64 6
  store ptr %81, ptr %82, align 8
  %83 = getelementptr inbounds %.6, ptr %69, i64 0, i32 7
  store i64 10, ptr %83, align 8
  %84 = getelementptr inbounds ptr, ptr %70, i64 7
  store ptr %83, ptr %84, align 8
  %85 = getelementptr inbounds %.6, ptr %69, i64 0, i32 8
  store i64 1, ptr %85, align 8
  %86 = getelementptr inbounds ptr, ptr %70, i64 8
  store ptr %85, ptr %86, align 8
  %87 = getelementptr inbounds %.6, ptr %69, i64 0, i32 9
  store ptr %.fca.0.load17, ptr %87, align 8
  %88 = getelementptr inbounds ptr, ptr %70, i64 9
  store ptr %87, ptr %88, align 8
  %89 = getelementptr inbounds %.6, ptr %69, i64 0, i32 10
  store ptr %.fca.1.load20, ptr %89, align 8
  %90 = getelementptr inbounds ptr, ptr %70, i64 10
  store ptr %89, ptr %90, align 8
  %91 = getelementptr inbounds %.6, ptr %69, i64 0, i32 11
  store i64 %.fca.2.load23, ptr %91, align 8
  %92 = getelementptr inbounds ptr, ptr %70, i64 11
  store ptr %91, ptr %92, align 8
  %93 = getelementptr inbounds %.6, ptr %69, i64 0, i32 12
  store i64 %.fca.3.0.load26, ptr %93, align 8
  %94 = getelementptr inbounds ptr, ptr %70, i64 12
  store ptr %93, ptr %94, align 8
  %95 = getelementptr inbounds %.6, ptr %69, i64 0, i32 13
  store i64 %.fca.3.1.load, ptr %95, align 8
  %96 = getelementptr inbounds ptr, ptr %70, i64 13
  store ptr %95, ptr %96, align 8
  %97 = getelementptr inbounds %.6, ptr %69, i64 0, i32 14
  store i64 %.fca.4.0.load29, ptr %97, align 8
  %98 = getelementptr inbounds ptr, ptr %70, i64 14
  store ptr %97, ptr %98, align 8
  %99 = getelementptr inbounds %.6, ptr %69, i64 0, i32 15
  store i64 %.fca.4.1.load, ptr %99, align 8
  %100 = getelementptr inbounds ptr, ptr %70, i64 15
  store ptr %99, ptr %100, align 8
  %101 = getelementptr inbounds %.6, ptr %69, i64 0, i32 16
  store ptr %68, ptr %101, align 8
  %102 = getelementptr inbounds ptr, ptr %70, i64 16
  store ptr %101, ptr %102, align 8
  %103 = getelementptr inbounds %.6, ptr %69, i64 0, i32 17
  store ptr %68, ptr %103, align 8
  %104 = getelementptr inbounds ptr, ptr %70, i64 17
  store ptr %103, ptr %104, align 8
  %105 = getelementptr inbounds %.6, ptr %69, i64 0, i32 18
  store i64 0, ptr %105, align 8
  %106 = getelementptr inbounds ptr, ptr %70, i64 18
  store ptr %105, ptr %106, align 8
  %107 = getelementptr inbounds %.6, ptr %69, i64 0, i32 19
  store i64 %.fca.3.0.load62, ptr %107, align 8
  %108 = getelementptr inbounds ptr, ptr %70, i64 19
  store ptr %107, ptr %108, align 8
  %109 = getelementptr inbounds %.6, ptr %69, i64 0, i32 20
  store i64 10, ptr %109, align 8
  %110 = getelementptr inbounds ptr, ptr %70, i64 20
  store ptr %109, ptr %110, align 8
  %111 = getelementptr inbounds %.6, ptr %69, i64 0, i32 21
  store i64 10, ptr %111, align 8
  %112 = getelementptr inbounds ptr, ptr %70, i64 21
  store ptr %111, ptr %112, align 8
  %113 = getelementptr inbounds %.6, ptr %69, i64 0, i32 22
  store i64 1, ptr %113, align 8
  %114 = getelementptr inbounds ptr, ptr %70, i64 22
  store ptr %113, ptr %114, align 8
  %115 = getelementptr inbounds %.6, ptr %69, i64 0, i32 23
  store i1 false, ptr %115, align 8
  %116 = getelementptr inbounds ptr, ptr %70, i64 23
  store ptr %115, ptr %116, align 8
  %117 = getelementptr inbounds %.6, ptr %69, i64 0, i32 24
  store i1 false, ptr %117, align 1
  %118 = getelementptr inbounds ptr, ptr %70, i64 24
  store ptr %117, ptr %118, align 8
  %119 = getelementptr inbounds %.6, ptr %69, i64 0, i32 25
  store i1 true, ptr %119, align 2
  %120 = getelementptr inbounds ptr, ptr %70, i64 25
  store ptr %119, ptr %120, align 8
  %121 = load ptr, ptr %0, align 8
  %122 = load ptr, ptr %9, align 8
  store ptr %121, ptr %69, align 8
  call void %122(ptr %121, ptr nonnull @ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void, ptr nonnull %70)
  %123 = alloca %.7, align 8
  %124 = alloca [2 x ptr], align 8
  store ptr %123, ptr %124, align 8
  %125 = getelementptr inbounds %.7, ptr %123, i64 0, i32 1
  store ptr %.fca.0.load17, ptr %125, align 8
  %126 = getelementptr inbounds ptr, ptr %124, i64 1
  store ptr %125, ptr %126, align 8
  %127 = load ptr, ptr %0, align 8
  %128 = load ptr, ptr %9, align 8
  store ptr %127, ptr %123, align 8
  call void %128(ptr %127, ptr nonnull @dealloc___gpu___pvoid_pvoid___void, ptr nonnull %124)
  %129 = and i64 %59, 2
  %130 = icmp eq i64 %129, 0
  %131 = alloca %.8, align 8
  %132 = alloca [3 x ptr], align 8
  store ptr %131, ptr %132, align 8
  %133 = getelementptr inbounds %.8, ptr %131, i64 0, i32 1
  store i64 %.idx, ptr %133, align 8
  %134 = getelementptr inbounds ptr, ptr %132, i64 1
  store ptr %133, ptr %134, align 8
  %135 = getelementptr inbounds %.8, ptr %131, i64 0, i32 2
  %136 = getelementptr inbounds ptr, ptr %132, i64 2
  store ptr %135, ptr %136, align 8
  %137 = load ptr, ptr %0, align 8
  %138 = load ptr, ptr %9, align 8
  store ptr %137, ptr %131, align 8
  call void %138(ptr %137, ptr nonnull @alloc___gpu___pvoid_i64___pvoid, ptr nonnull %132)
  %139 = load ptr, ptr %135, align 8
  br i1 %130, label %140, label %193

140:                                              ; preds = %1
  %141 = lshr i64 %59, 2
  %142 = icmp ult i64 %59, 4
  %143 = sub nsw i64 0, %141
  %144 = add nsw i64 %141, -1
  %145 = select i1 %142, i64 %143, i64 %144
  %146 = sdiv i64 %145, 256
  %147 = sub nsw i64 0, %146
  %148 = add nsw i64 %146, 1
  %149 = select i1 %142, i64 %147, i64 %148
  %150 = alloca [3 x ptr], align 8
  store ptr @main_kernel_blob_gpu.binary_compute_60, ptr %150, align 8
  %151 = getelementptr inbounds ptr, ptr %150, i64 1
  store ptr @main_kernel_blob_gpu.binary_sm_70, ptr %151, align 8
  %152 = getelementptr inbounds ptr, ptr %150, i64 2
  store ptr @main_kernel_blob_gpu.binary_sm_75, ptr %152, align 8
  %153 = alloca %.9, align 8
  %154 = alloca [5 x ptr], align 8
  store i64 256, ptr %153, align 8
  store ptr %153, ptr %154, align 8
  %155 = getelementptr inbounds %.9, ptr %153, i64 0, i32 1
  store i64 %141, ptr %155, align 8
  %156 = getelementptr inbounds ptr, ptr %154, i64 1
  store ptr %155, ptr %156, align 8
  %157 = getelementptr inbounds %.9, ptr %153, i64 0, i32 2
  store ptr %68, ptr %157, align 8
  %158 = getelementptr inbounds ptr, ptr %154, i64 2
  store ptr %157, ptr %158, align 8
  %159 = getelementptr inbounds %.9, ptr %153, i64 0, i32 3
  store ptr %.fca.1.load5, ptr %159, align 8
  %160 = getelementptr inbounds ptr, ptr %154, i64 3
  store ptr %159, ptr %160, align 8
  %161 = getelementptr inbounds %.9, ptr %153, i64 0, i32 4
  store ptr %139, ptr %161, align 8
  %162 = getelementptr inbounds ptr, ptr %154, i64 4
  store ptr %161, ptr %162, align 8
  %163 = alloca %.10, align 8
  %164 = alloca [14 x ptr], align 8
  store ptr %163, ptr %164, align 8
  %165 = getelementptr inbounds %.10, ptr %163, i64 0, i32 1
  store ptr %150, ptr %165, align 8
  %166 = getelementptr inbounds ptr, ptr %164, i64 1
  store ptr %165, ptr %166, align 8
  %167 = getelementptr inbounds %.10, ptr %163, i64 0, i32 2
  store i64 3, ptr %167, align 8
  %168 = getelementptr inbounds ptr, ptr %164, i64 2
  store ptr %167, ptr %168, align 8
  %169 = getelementptr inbounds %.10, ptr %163, i64 0, i32 3
  store ptr @main_kernel_main_kLoop_maximum__5_1_0___Vec4_kernel_name, ptr %169, align 8
  %170 = getelementptr inbounds ptr, ptr %164, i64 3
  store ptr %169, ptr %170, align 8
  %171 = getelementptr inbounds %.10, ptr %163, i64 0, i32 4
  store i64 %149, ptr %171, align 8
  %172 = getelementptr inbounds ptr, ptr %164, i64 4
  store ptr %171, ptr %172, align 8
  %173 = getelementptr inbounds %.10, ptr %163, i64 0, i32 5
  store i64 1, ptr %173, align 8
  %174 = getelementptr inbounds ptr, ptr %164, i64 5
  store ptr %173, ptr %174, align 8
  %175 = getelementptr inbounds %.10, ptr %163, i64 0, i32 6
  store i64 1, ptr %175, align 8
  %176 = getelementptr inbounds ptr, ptr %164, i64 6
  store ptr %175, ptr %176, align 8
  %177 = getelementptr inbounds %.10, ptr %163, i64 0, i32 7
  store i64 256, ptr %177, align 8
  %178 = getelementptr inbounds ptr, ptr %164, i64 7
  store ptr %177, ptr %178, align 8
  %179 = getelementptr inbounds %.10, ptr %163, i64 0, i32 8
  store i64 1, ptr %179, align 8
  %180 = getelementptr inbounds ptr, ptr %164, i64 8
  store ptr %179, ptr %180, align 8
  %181 = getelementptr inbounds %.10, ptr %163, i64 0, i32 9
  store i64 1, ptr %181, align 8
  %182 = getelementptr inbounds ptr, ptr %164, i64 9
  store ptr %181, ptr %182, align 8
  %183 = getelementptr inbounds %.10, ptr %163, i64 0, i32 10
  store i32 0, ptr %183, align 8
  %184 = getelementptr inbounds ptr, ptr %164, i64 10
  store ptr %183, ptr %184, align 8
  %185 = getelementptr inbounds %.10, ptr %163, i64 0, i32 11
  store ptr null, ptr %185, align 8
  %186 = getelementptr inbounds ptr, ptr %164, i64 11
  store ptr %185, ptr %186, align 8
  %187 = getelementptr inbounds %.10, ptr %163, i64 0, i32 12
  store i32 5, ptr %187, align 8
  %188 = getelementptr inbounds ptr, ptr %164, i64 12
  store ptr %187, ptr %188, align 8
  %189 = getelementptr inbounds %.10, ptr %163, i64 0, i32 13
  store ptr %154, ptr %189, align 8
  %190 = getelementptr inbounds ptr, ptr %164, i64 13
  store ptr %189, ptr %190, align 8
  %191 = load ptr, ptr %0, align 8
  %192 = load ptr, ptr %9, align 8
  store ptr %191, ptr %163, align 8
  call void %192(ptr %191, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %164)
  br label %245

193:                                              ; preds = %1
  %194 = icmp slt i64 %59, 1
  %195 = sub i64 0, %59
  %196 = add i64 %59, -1
  %197 = select i1 %194, i64 %195, i64 %196
  %198 = sdiv i64 %197, 256
  %199 = sub nsw i64 0, %198
  %200 = add nsw i64 %198, 1
  %201 = select i1 %194, i64 %199, i64 %200
  %202 = alloca [3 x ptr], align 8
  store ptr @main_kernel_0_blob_gpu.binary_compute_60, ptr %202, align 8
  %203 = getelementptr inbounds ptr, ptr %202, i64 1
  store ptr @main_kernel_0_blob_gpu.binary_sm_70, ptr %203, align 8
  %204 = getelementptr inbounds ptr, ptr %202, i64 2
  store ptr @main_kernel_0_blob_gpu.binary_sm_75, ptr %204, align 8
  %205 = alloca %.25, align 8
  %206 = alloca [5 x ptr], align 8
  store i64 256, ptr %205, align 8
  store ptr %205, ptr %206, align 8
  %207 = getelementptr inbounds %.25, ptr %205, i64 0, i32 1
  store i64 %59, ptr %207, align 8
  %208 = getelementptr inbounds ptr, ptr %206, i64 1
  store ptr %207, ptr %208, align 8
  %209 = getelementptr inbounds %.25, ptr %205, i64 0, i32 2
  store ptr %68, ptr %209, align 8
  %210 = getelementptr inbounds ptr, ptr %206, i64 2
  store ptr %209, ptr %210, align 8
  %211 = getelementptr inbounds %.25, ptr %205, i64 0, i32 3
  store ptr %.fca.1.load5, ptr %211, align 8
  %212 = getelementptr inbounds ptr, ptr %206, i64 3
  store ptr %211, ptr %212, align 8
  %213 = getelementptr inbounds %.25, ptr %205, i64 0, i32 4
  store ptr %139, ptr %213, align 8
  %214 = getelementptr inbounds ptr, ptr %206, i64 4
  store ptr %213, ptr %214, align 8
  %215 = alloca %.26, align 8
  %216 = alloca [14 x ptr], align 8
  store ptr %215, ptr %216, align 8
  %217 = getelementptr inbounds %.26, ptr %215, i64 0, i32 1
  store ptr %202, ptr %217, align 8
  %218 = getelementptr inbounds ptr, ptr %216, i64 1
  store ptr %217, ptr %218, align 8
  %219 = getelementptr inbounds %.26, ptr %215, i64 0, i32 2
  store i64 3, ptr %219, align 8
  %220 = getelementptr inbounds ptr, ptr %216, i64 2
  store ptr %219, ptr %220, align 8
  %221 = getelementptr inbounds %.26, ptr %215, i64 0, i32 3
  store ptr @main_kernel_0_main_kLoop_maximum__5_1_0_kernel_name, ptr %221, align 8
  %222 = getelementptr inbounds ptr, ptr %216, i64 3
  store ptr %221, ptr %222, align 8
  %223 = getelementptr inbounds %.26, ptr %215, i64 0, i32 4
  store i64 %201, ptr %223, align 8
  %224 = getelementptr inbounds ptr, ptr %216, i64 4
  store ptr %223, ptr %224, align 8
  %225 = getelementptr inbounds %.26, ptr %215, i64 0, i32 5
  store i64 1, ptr %225, align 8
  %226 = getelementptr inbounds ptr, ptr %216, i64 5
  store ptr %225, ptr %226, align 8
  %227 = getelementptr inbounds %.26, ptr %215, i64 0, i32 6
  store i64 1, ptr %227, align 8
  %228 = getelementptr inbounds ptr, ptr %216, i64 6
  store ptr %227, ptr %228, align 8
  %229 = getelementptr inbounds %.26, ptr %215, i64 0, i32 7
  store i64 256, ptr %229, align 8
  %230 = getelementptr inbounds ptr, ptr %216, i64 7
  store ptr %229, ptr %230, align 8
  %231 = getelementptr inbounds %.26, ptr %215, i64 0, i32 8
  store i64 1, ptr %231, align 8
  %232 = getelementptr inbounds ptr, ptr %216, i64 8
  store ptr %231, ptr %232, align 8
  %233 = getelementptr inbounds %.26, ptr %215, i64 0, i32 9
  store i64 1, ptr %233, align 8
  %234 = getelementptr inbounds ptr, ptr %216, i64 9
  store ptr %233, ptr %234, align 8
  %235 = getelementptr inbounds %.26, ptr %215, i64 0, i32 10
  store i32 0, ptr %235, align 8
  %236 = getelementptr inbounds ptr, ptr %216, i64 10
  store ptr %235, ptr %236, align 8
  %237 = getelementptr inbounds %.26, ptr %215, i64 0, i32 11
  store ptr null, ptr %237, align 8
  %238 = getelementptr inbounds ptr, ptr %216, i64 11
  store ptr %237, ptr %238, align 8
  %239 = getelementptr inbounds %.26, ptr %215, i64 0, i32 12
  store i32 5, ptr %239, align 8
  %240 = getelementptr inbounds ptr, ptr %216, i64 12
  store ptr %239, ptr %240, align 8
  %241 = getelementptr inbounds %.26, ptr %215, i64 0, i32 13
  store ptr %206, ptr %241, align 8
  %242 = getelementptr inbounds ptr, ptr %216, i64 13
  store ptr %241, ptr %242, align 8
  %243 = load ptr, ptr %0, align 8
  %244 = load ptr, ptr %9, align 8
  store ptr %243, ptr %215, align 8
  call void %244(ptr %243, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %216)
  br label %245

245:                                              ; preds = %140, %193
  %246 = alloca %.11, align 8
  %247 = alloca [2 x ptr], align 8
  store ptr %246, ptr %247, align 8
  %248 = getelementptr inbounds %.11, ptr %246, i64 0, i32 1
  store ptr %68, ptr %248, align 8
  %249 = getelementptr inbounds ptr, ptr %247, i64 1
  store ptr %248, ptr %249, align 8
  %250 = load ptr, ptr %0, align 8
  %251 = load ptr, ptr %9, align 8
  store ptr %250, ptr %246, align 8
  call void %251(ptr %250, ptr nonnull @dealloc___gpu___pvoid_pvoid___void, ptr nonnull %247)
  %252 = alloca %.12, align 8
  %253 = alloca [2 x ptr], align 8
  store ptr %252, ptr %253, align 8
  %254 = getelementptr inbounds %.12, ptr %252, i64 0, i32 1
  store ptr %.fca.0.load2, ptr %254, align 8
  %255 = getelementptr inbounds ptr, ptr %253, i64 1
  store ptr %254, ptr %255, align 8
  %256 = load ptr, ptr %0, align 8
  %257 = load ptr, ptr %9, align 8
  store ptr %256, ptr %252, align 8
  call void %257(ptr %256, ptr nonnull @dealloc___gpu___pvoid_pvoid___void, ptr nonnull %253)
  %258 = alloca %.13, align 8
  %259 = alloca [3 x ptr], align 8
  store ptr %258, ptr %259, align 8
  %260 = getelementptr inbounds %.13, ptr %258, i64 0, i32 1
  store i64 %.idx, ptr %260, align 8
  %261 = getelementptr inbounds ptr, ptr %259, i64 1
  store ptr %260, ptr %261, align 8
  %262 = getelementptr inbounds %.13, ptr %258, i64 0, i32 2
  %263 = getelementptr inbounds ptr, ptr %259, i64 2
  store ptr %262, ptr %263, align 8
  %264 = load ptr, ptr %0, align 8
  %265 = load ptr, ptr %9, align 8
  store ptr %264, ptr %258, align 8
  call void %265(ptr %264, ptr nonnull @alloc___gpu___pvoid_i64___pvoid, ptr nonnull %259)
  %266 = load ptr, ptr %262, align 8
  %267 = alloca %.14, align 8
  %268 = alloca [26 x ptr], align 8
  store ptr %267, ptr %268, align 8
  %269 = getelementptr inbounds %.14, ptr %267, i64 0, i32 1
  store ptr null, ptr %269, align 8
  %270 = getelementptr inbounds ptr, ptr %268, i64 1
  store ptr %269, ptr %270, align 8
  %271 = getelementptr inbounds %.14, ptr %267, i64 0, i32 2
  store ptr %139, ptr %271, align 8
  %272 = getelementptr inbounds ptr, ptr %268, i64 2
  store ptr %271, ptr %272, align 8
  %273 = getelementptr inbounds %.14, ptr %267, i64 0, i32 3
  store ptr %139, ptr %273, align 8
  %274 = getelementptr inbounds ptr, ptr %268, i64 3
  store ptr %273, ptr %274, align 8
  %275 = getelementptr inbounds %.14, ptr %267, i64 0, i32 4
  store i64 0, ptr %275, align 8
  %276 = getelementptr inbounds ptr, ptr %268, i64 4
  store ptr %275, ptr %276, align 8
  %277 = getelementptr inbounds %.14, ptr %267, i64 0, i32 5
  store i64 %.fca.3.0.load62, ptr %277, align 8
  %278 = getelementptr inbounds ptr, ptr %268, i64 5
  store ptr %277, ptr %278, align 8
  %279 = getelementptr inbounds %.14, ptr %267, i64 0, i32 6
  store i64 10, ptr %279, align 8
  %280 = getelementptr inbounds ptr, ptr %268, i64 6
  store ptr %279, ptr %280, align 8
  %281 = getelementptr inbounds %.14, ptr %267, i64 0, i32 7
  store i64 10, ptr %281, align 8
  %282 = getelementptr inbounds ptr, ptr %268, i64 7
  store ptr %281, ptr %282, align 8
  %283 = getelementptr inbounds %.14, ptr %267, i64 0, i32 8
  store i64 1, ptr %283, align 8
  %284 = getelementptr inbounds ptr, ptr %268, i64 8
  store ptr %283, ptr %284, align 8
  %285 = getelementptr inbounds %.14, ptr %267, i64 0, i32 9
  store ptr %.fca.0.load32, ptr %285, align 8
  %286 = getelementptr inbounds ptr, ptr %268, i64 9
  store ptr %285, ptr %286, align 8
  %287 = getelementptr inbounds %.14, ptr %267, i64 0, i32 10
  store ptr %.fca.1.load35, ptr %287, align 8
  %288 = getelementptr inbounds ptr, ptr %268, i64 10
  store ptr %287, ptr %288, align 8
  %289 = getelementptr inbounds %.14, ptr %267, i64 0, i32 11
  store i64 %.fca.2.load38, ptr %289, align 8
  %290 = getelementptr inbounds ptr, ptr %268, i64 11
  store ptr %289, ptr %290, align 8
  %291 = getelementptr inbounds %.14, ptr %267, i64 0, i32 12
  store i64 %.fca.3.0.load41, ptr %291, align 8
  %292 = getelementptr inbounds ptr, ptr %268, i64 12
  store ptr %291, ptr %292, align 8
  %293 = getelementptr inbounds %.14, ptr %267, i64 0, i32 13
  store i64 %.fca.3.1.load44, ptr %293, align 8
  %294 = getelementptr inbounds ptr, ptr %268, i64 13
  store ptr %293, ptr %294, align 8
  %295 = getelementptr inbounds %.14, ptr %267, i64 0, i32 14
  store i64 %.fca.4.0.load47, ptr %295, align 8
  %296 = getelementptr inbounds ptr, ptr %268, i64 14
  store ptr %295, ptr %296, align 8
  %297 = getelementptr inbounds %.14, ptr %267, i64 0, i32 15
  store i64 %.fca.4.1.load50, ptr %297, align 8
  %298 = getelementptr inbounds ptr, ptr %268, i64 15
  store ptr %297, ptr %298, align 8
  %299 = getelementptr inbounds %.14, ptr %267, i64 0, i32 16
  store ptr %266, ptr %299, align 8
  %300 = getelementptr inbounds ptr, ptr %268, i64 16
  store ptr %299, ptr %300, align 8
  %301 = getelementptr inbounds %.14, ptr %267, i64 0, i32 17
  store ptr %266, ptr %301, align 8
  %302 = getelementptr inbounds ptr, ptr %268, i64 17
  store ptr %301, ptr %302, align 8
  %303 = getelementptr inbounds %.14, ptr %267, i64 0, i32 18
  store i64 0, ptr %303, align 8
  %304 = getelementptr inbounds ptr, ptr %268, i64 18
  store ptr %303, ptr %304, align 8
  %305 = getelementptr inbounds %.14, ptr %267, i64 0, i32 19
  store i64 %.fca.3.0.load62, ptr %305, align 8
  %306 = getelementptr inbounds ptr, ptr %268, i64 19
  store ptr %305, ptr %306, align 8
  %307 = getelementptr inbounds %.14, ptr %267, i64 0, i32 20
  store i64 10, ptr %307, align 8
  %308 = getelementptr inbounds ptr, ptr %268, i64 20
  store ptr %307, ptr %308, align 8
  %309 = getelementptr inbounds %.14, ptr %267, i64 0, i32 21
  store i64 10, ptr %309, align 8
  %310 = getelementptr inbounds ptr, ptr %268, i64 21
  store ptr %309, ptr %310, align 8
  %311 = getelementptr inbounds %.14, ptr %267, i64 0, i32 22
  store i64 1, ptr %311, align 8
  %312 = getelementptr inbounds ptr, ptr %268, i64 22
  store ptr %311, ptr %312, align 8
  %313 = getelementptr inbounds %.14, ptr %267, i64 0, i32 23
  store i1 false, ptr %313, align 8
  %314 = getelementptr inbounds ptr, ptr %268, i64 23
  store ptr %313, ptr %314, align 8
  %315 = getelementptr inbounds %.14, ptr %267, i64 0, i32 24
  store i1 false, ptr %315, align 1
  %316 = getelementptr inbounds ptr, ptr %268, i64 24
  store ptr %315, ptr %316, align 8
  %317 = getelementptr inbounds %.14, ptr %267, i64 0, i32 25
  store i1 true, ptr %317, align 2
  %318 = getelementptr inbounds ptr, ptr %268, i64 25
  store ptr %317, ptr %318, align 8
  %319 = load ptr, ptr %0, align 8
  %320 = load ptr, ptr %9, align 8
  store ptr %319, ptr %267, align 8
  call void %320(ptr %319, ptr nonnull @ral_gemm___gpu___pvoid_pvoid_m2df32_m2df32_m2df32_i1_i1_i1___void, ptr nonnull %268)
  %321 = alloca %.15, align 8
  %322 = alloca [2 x ptr], align 8
  store ptr %321, ptr %322, align 8
  %323 = getelementptr inbounds %.15, ptr %321, i64 0, i32 1
  store ptr %139, ptr %323, align 8
  %324 = getelementptr inbounds ptr, ptr %322, i64 1
  store ptr %323, ptr %324, align 8
  %325 = load ptr, ptr %0, align 8
  %326 = load ptr, ptr %9, align 8
  store ptr %325, ptr %321, align 8
  call void %326(ptr %325, ptr nonnull @dealloc___gpu___pvoid_pvoid___void, ptr nonnull %322)
  %327 = alloca %.16, align 8
  %328 = alloca [2 x ptr], align 8
  store ptr %327, ptr %328, align 8
  %329 = getelementptr inbounds %.16, ptr %327, i64 0, i32 1
  store ptr %.fca.0.load32, ptr %329, align 8
  %330 = getelementptr inbounds ptr, ptr %328, i64 1
  store ptr %329, ptr %330, align 8
  %331 = load ptr, ptr %0, align 8
  %332 = load ptr, ptr %9, align 8
  store ptr %331, ptr %327, align 8
  call void %332(ptr %331, ptr nonnull @dealloc___gpu___pvoid_pvoid___void, ptr nonnull %328)
  %333 = alloca %.17, align 8
  %334 = alloca [3 x ptr], align 8
  store ptr %333, ptr %334, align 8
  %335 = getelementptr inbounds %.17, ptr %333, i64 0, i32 1
  store i64 %.idx, ptr %335, align 8
  %336 = getelementptr inbounds ptr, ptr %334, i64 1
  store ptr %335, ptr %336, align 8
  %337 = getelementptr inbounds %.17, ptr %333, i64 0, i32 2
  %338 = getelementptr inbounds ptr, ptr %334, i64 2
  store ptr %337, ptr %338, align 8
  %339 = load ptr, ptr %0, align 8
  %340 = load ptr, ptr %9, align 8
  store ptr %339, ptr %333, align 8
  call void %340(ptr %339, ptr nonnull @alloc___gpu___pvoid_i64___pvoid, ptr nonnull %334)
  %341 = load ptr, ptr %337, align 8
  br i1 %130, label %342, label %395

342:                                              ; preds = %245
  %343 = lshr i64 %59, 2
  %344 = icmp ult i64 %59, 4
  %345 = sub nsw i64 0, %343
  %346 = add nsw i64 %343, -1
  %347 = select i1 %344, i64 %345, i64 %346
  %348 = sdiv i64 %347, 256
  %349 = sub nsw i64 0, %348
  %350 = add nsw i64 %348, 1
  %351 = select i1 %344, i64 %349, i64 %350
  %352 = alloca [3 x ptr], align 8
  store ptr @main_kernel_1_blob_gpu.binary_compute_60, ptr %352, align 8
  %353 = getelementptr inbounds ptr, ptr %352, i64 1
  store ptr @main_kernel_1_blob_gpu.binary_sm_70, ptr %353, align 8
  %354 = getelementptr inbounds ptr, ptr %352, i64 2
  store ptr @main_kernel_1_blob_gpu.binary_sm_75, ptr %354, align 8
  %355 = alloca %.18, align 8
  %356 = alloca [5 x ptr], align 8
  store i64 256, ptr %355, align 8
  store ptr %355, ptr %356, align 8
  %357 = getelementptr inbounds %.18, ptr %355, i64 0, i32 1
  store i64 %343, ptr %357, align 8
  %358 = getelementptr inbounds ptr, ptr %356, i64 1
  store ptr %357, ptr %358, align 8
  %359 = getelementptr inbounds %.18, ptr %355, i64 0, i32 2
  store ptr %.fca.1.load, ptr %359, align 8
  %360 = getelementptr inbounds ptr, ptr %356, i64 2
  store ptr %359, ptr %360, align 8
  %361 = getelementptr inbounds %.18, ptr %355, i64 0, i32 3
  store ptr %266, ptr %361, align 8
  %362 = getelementptr inbounds ptr, ptr %356, i64 3
  store ptr %361, ptr %362, align 8
  %363 = getelementptr inbounds %.18, ptr %355, i64 0, i32 4
  store ptr %341, ptr %363, align 8
  %364 = getelementptr inbounds ptr, ptr %356, i64 4
  store ptr %363, ptr %364, align 8
  %365 = alloca %.19, align 8
  %366 = alloca [14 x ptr], align 8
  store ptr %365, ptr %366, align 8
  %367 = getelementptr inbounds %.19, ptr %365, i64 0, i32 1
  store ptr %352, ptr %367, align 8
  %368 = getelementptr inbounds ptr, ptr %366, i64 1
  store ptr %367, ptr %368, align 8
  %369 = getelementptr inbounds %.19, ptr %365, i64 0, i32 2
  store i64 3, ptr %369, align 8
  %370 = getelementptr inbounds ptr, ptr %366, i64 2
  store ptr %369, ptr %370, align 8
  %371 = getelementptr inbounds %.19, ptr %365, i64 0, i32 3
  store ptr @main_kernel_1_main_kLoop_maximum__5_1_1___Vec4_kernel_name, ptr %371, align 8
  %372 = getelementptr inbounds ptr, ptr %366, i64 3
  store ptr %371, ptr %372, align 8
  %373 = getelementptr inbounds %.19, ptr %365, i64 0, i32 4
  store i64 %351, ptr %373, align 8
  %374 = getelementptr inbounds ptr, ptr %366, i64 4
  store ptr %373, ptr %374, align 8
  %375 = getelementptr inbounds %.19, ptr %365, i64 0, i32 5
  store i64 1, ptr %375, align 8
  %376 = getelementptr inbounds ptr, ptr %366, i64 5
  store ptr %375, ptr %376, align 8
  %377 = getelementptr inbounds %.19, ptr %365, i64 0, i32 6
  store i64 1, ptr %377, align 8
  %378 = getelementptr inbounds ptr, ptr %366, i64 6
  store ptr %377, ptr %378, align 8
  %379 = getelementptr inbounds %.19, ptr %365, i64 0, i32 7
  store i64 256, ptr %379, align 8
  %380 = getelementptr inbounds ptr, ptr %366, i64 7
  store ptr %379, ptr %380, align 8
  %381 = getelementptr inbounds %.19, ptr %365, i64 0, i32 8
  store i64 1, ptr %381, align 8
  %382 = getelementptr inbounds ptr, ptr %366, i64 8
  store ptr %381, ptr %382, align 8
  %383 = getelementptr inbounds %.19, ptr %365, i64 0, i32 9
  store i64 1, ptr %383, align 8
  %384 = getelementptr inbounds ptr, ptr %366, i64 9
  store ptr %383, ptr %384, align 8
  %385 = getelementptr inbounds %.19, ptr %365, i64 0, i32 10
  store i32 0, ptr %385, align 8
  %386 = getelementptr inbounds ptr, ptr %366, i64 10
  store ptr %385, ptr %386, align 8
  %387 = getelementptr inbounds %.19, ptr %365, i64 0, i32 11
  store ptr null, ptr %387, align 8
  %388 = getelementptr inbounds ptr, ptr %366, i64 11
  store ptr %387, ptr %388, align 8
  %389 = getelementptr inbounds %.19, ptr %365, i64 0, i32 12
  store i32 5, ptr %389, align 8
  %390 = getelementptr inbounds ptr, ptr %366, i64 12
  store ptr %389, ptr %390, align 8
  %391 = getelementptr inbounds %.19, ptr %365, i64 0, i32 13
  store ptr %356, ptr %391, align 8
  %392 = getelementptr inbounds ptr, ptr %366, i64 13
  store ptr %391, ptr %392, align 8
  %393 = load ptr, ptr %0, align 8
  %394 = load ptr, ptr %9, align 8
  store ptr %393, ptr %365, align 8
  call void %394(ptr %393, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %366)
  br label %447

395:                                              ; preds = %245
  %396 = icmp slt i64 %59, 1
  %397 = sub i64 0, %59
  %398 = add i64 %59, -1
  %399 = select i1 %396, i64 %397, i64 %398
  %400 = sdiv i64 %399, 256
  %401 = sub nsw i64 0, %400
  %402 = add nsw i64 %400, 1
  %403 = select i1 %396, i64 %401, i64 %402
  %404 = alloca [3 x ptr], align 8
  store ptr @main_kernel_2_blob_gpu.binary_compute_60, ptr %404, align 8
  %405 = getelementptr inbounds ptr, ptr %404, i64 1
  store ptr @main_kernel_2_blob_gpu.binary_sm_70, ptr %405, align 8
  %406 = getelementptr inbounds ptr, ptr %404, i64 2
  store ptr @main_kernel_2_blob_gpu.binary_sm_75, ptr %406, align 8
  %407 = alloca %.23, align 8
  %408 = alloca [5 x ptr], align 8
  store i64 256, ptr %407, align 8
  store ptr %407, ptr %408, align 8
  %409 = getelementptr inbounds %.23, ptr %407, i64 0, i32 1
  store i64 %59, ptr %409, align 8
  %410 = getelementptr inbounds ptr, ptr %408, i64 1
  store ptr %409, ptr %410, align 8
  %411 = getelementptr inbounds %.23, ptr %407, i64 0, i32 2
  store ptr %266, ptr %411, align 8
  %412 = getelementptr inbounds ptr, ptr %408, i64 2
  store ptr %411, ptr %412, align 8
  %413 = getelementptr inbounds %.23, ptr %407, i64 0, i32 3
  store ptr %.fca.1.load, ptr %413, align 8
  %414 = getelementptr inbounds ptr, ptr %408, i64 3
  store ptr %413, ptr %414, align 8
  %415 = getelementptr inbounds %.23, ptr %407, i64 0, i32 4
  store ptr %341, ptr %415, align 8
  %416 = getelementptr inbounds ptr, ptr %408, i64 4
  store ptr %415, ptr %416, align 8
  %417 = alloca %.24, align 8
  %418 = alloca [14 x ptr], align 8
  store ptr %417, ptr %418, align 8
  %419 = getelementptr inbounds %.24, ptr %417, i64 0, i32 1
  store ptr %404, ptr %419, align 8
  %420 = getelementptr inbounds ptr, ptr %418, i64 1
  store ptr %419, ptr %420, align 8
  %421 = getelementptr inbounds %.24, ptr %417, i64 0, i32 2
  store i64 3, ptr %421, align 8
  %422 = getelementptr inbounds ptr, ptr %418, i64 2
  store ptr %421, ptr %422, align 8
  %423 = getelementptr inbounds %.24, ptr %417, i64 0, i32 3
  store ptr @main_kernel_2_main_kLoop_maximum__5_1_1_kernel_name, ptr %423, align 8
  %424 = getelementptr inbounds ptr, ptr %418, i64 3
  store ptr %423, ptr %424, align 8
  %425 = getelementptr inbounds %.24, ptr %417, i64 0, i32 4
  store i64 %403, ptr %425, align 8
  %426 = getelementptr inbounds ptr, ptr %418, i64 4
  store ptr %425, ptr %426, align 8
  %427 = getelementptr inbounds %.24, ptr %417, i64 0, i32 5
  store i64 1, ptr %427, align 8
  %428 = getelementptr inbounds ptr, ptr %418, i64 5
  store ptr %427, ptr %428, align 8
  %429 = getelementptr inbounds %.24, ptr %417, i64 0, i32 6
  store i64 1, ptr %429, align 8
  %430 = getelementptr inbounds ptr, ptr %418, i64 6
  store ptr %429, ptr %430, align 8
  %431 = getelementptr inbounds %.24, ptr %417, i64 0, i32 7
  store i64 256, ptr %431, align 8
  %432 = getelementptr inbounds ptr, ptr %418, i64 7
  store ptr %431, ptr %432, align 8
  %433 = getelementptr inbounds %.24, ptr %417, i64 0, i32 8
  store i64 1, ptr %433, align 8
  %434 = getelementptr inbounds ptr, ptr %418, i64 8
  store ptr %433, ptr %434, align 8
  %435 = getelementptr inbounds %.24, ptr %417, i64 0, i32 9
  store i64 1, ptr %435, align 8
  %436 = getelementptr inbounds ptr, ptr %418, i64 9
  store ptr %435, ptr %436, align 8
  %437 = getelementptr inbounds %.24, ptr %417, i64 0, i32 10
  store i32 0, ptr %437, align 8
  %438 = getelementptr inbounds ptr, ptr %418, i64 10
  store ptr %437, ptr %438, align 8
  %439 = getelementptr inbounds %.24, ptr %417, i64 0, i32 11
  store ptr null, ptr %439, align 8
  %440 = getelementptr inbounds ptr, ptr %418, i64 11
  store ptr %439, ptr %440, align 8
  %441 = getelementptr inbounds %.24, ptr %417, i64 0, i32 12
  store i32 5, ptr %441, align 8
  %442 = getelementptr inbounds ptr, ptr %418, i64 12
  store ptr %441, ptr %442, align 8
  %443 = getelementptr inbounds %.24, ptr %417, i64 0, i32 13
  store ptr %408, ptr %443, align 8
  %444 = getelementptr inbounds ptr, ptr %418, i64 13
  store ptr %443, ptr %444, align 8
  %445 = load ptr, ptr %0, align 8
  %446 = load ptr, ptr %9, align 8
  store ptr %445, ptr %417, align 8
  call void %446(ptr %445, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %418)
  br label %447

447:                                              ; preds = %342, %395
  %448 = alloca %.20, align 8
  %449 = alloca [2 x ptr], align 8
  store ptr %448, ptr %449, align 8
  %450 = getelementptr inbounds %.20, ptr %448, i64 0, i32 1
  store ptr %266, ptr %450, align 8
  %451 = getelementptr inbounds ptr, ptr %449, i64 1
  store ptr %450, ptr %451, align 8
  %452 = load ptr, ptr %0, align 8
  %453 = load ptr, ptr %9, align 8
  store ptr %452, ptr %448, align 8
  call void %453(ptr %452, ptr nonnull @dealloc___gpu___pvoid_pvoid___void, ptr nonnull %449)
  %454 = alloca %.21, align 8
  %455 = alloca [2 x ptr], align 8
  store ptr %454, ptr %455, align 8
  %456 = getelementptr inbounds %.21, ptr %454, i64 0, i32 1
  store ptr %.fca.0.load, ptr %456, align 8
  %457 = getelementptr inbounds ptr, ptr %455, i64 1
  store ptr %456, ptr %457, align 8
  %458 = load ptr, ptr %0, align 8
  %459 = load ptr, ptr %9, align 8
  store ptr %458, ptr %454, align 8
  call void %459(ptr %458, ptr nonnull @dealloc___gpu___pvoid_pvoid___void, ptr nonnull %455)
  %460 = alloca %.22, align 8
  %461 = alloca [9 x ptr], align 8
  store ptr %460, ptr %461, align 8
  %462 = getelementptr inbounds %.22, ptr %460, i64 0, i32 1
  store i64 0, ptr %462, align 8
  %463 = getelementptr inbounds ptr, ptr %461, i64 1
  store ptr %462, ptr %463, align 8
  %464 = getelementptr inbounds %.22, ptr %460, i64 0, i32 2
  store ptr %341, ptr %464, align 8
  %465 = getelementptr inbounds ptr, ptr %461, i64 2
  store ptr %464, ptr %465, align 8
  %466 = getelementptr inbounds %.22, ptr %460, i64 0, i32 3
  store ptr %341, ptr %466, align 8
  %467 = getelementptr inbounds ptr, ptr %461, i64 3
  store ptr %466, ptr %467, align 8
  %468 = getelementptr inbounds %.22, ptr %460, i64 0, i32 4
  store i64 0, ptr %468, align 8
  %469 = getelementptr inbounds ptr, ptr %461, i64 4
  store ptr %468, ptr %469, align 8
  %470 = getelementptr inbounds %.22, ptr %460, i64 0, i32 5
  store i64 %.fca.3.0.load62, ptr %470, align 8
  %471 = getelementptr inbounds ptr, ptr %461, i64 5
  store ptr %470, ptr %471, align 8
  %472 = getelementptr inbounds %.22, ptr %460, i64 0, i32 6
  store i64 10, ptr %472, align 8
  %473 = getelementptr inbounds ptr, ptr %461, i64 6
  store ptr %472, ptr %473, align 8
  %474 = getelementptr inbounds %.22, ptr %460, i64 0, i32 7
  store i64 10, ptr %474, align 8
  %475 = getelementptr inbounds ptr, ptr %461, i64 7
  store ptr %474, ptr %475, align 8
  %476 = getelementptr inbounds %.22, ptr %460, i64 0, i32 8
  store i64 1, ptr %476, align 8
  %477 = getelementptr inbounds ptr, ptr %461, i64 8
  store ptr %476, ptr %477, align 8
  %478 = load ptr, ptr %0, align 8
  %479 = load ptr, ptr %9, align 8
  store ptr %478, ptr %460, align 8
  call void %479(ptr %478, ptr nonnull @ral_send_output___cpu___pvoid_i64_m2df32___void, ptr nonnull %461)
  ret void
}

[DISC] LowerLLVMToBinary takes: 5.141000e-02 s.
object file to shared library command: gcc --shared -o /tmp/tmpr1pyb_1n/tmp8ym64dtg.so /tmp/tmpr1pyb_1n/tmp8ym64dtg.so.o
save shared lib file to : /tmp/tmpr1pyb_1n/tmp8ym64dtg.so
[DISC] BinaryStrToSharedLibrary takes: 1.193130e-01 s.
[DISC] LowerHLOToSharedLibrary takes: 1.709506e+00 s.
